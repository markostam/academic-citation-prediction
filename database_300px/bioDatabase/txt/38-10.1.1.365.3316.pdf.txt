The Annals of Statistics
2004, Vol. 32, No. 6, 2616–2641
DOI 10.1214/009053604000000823
© Institute of Mathematical Statistics, 2004
APPROXIMATELY UNBIASED TESTS OF REGIONS USING
MULTISTEP-MULTISCALE BOOTSTRAP RESAMPLING1
BY HIDETOSHI SHIMODAIRA
Tokyo Institute of Technology
Approximately unbiased tests based on bootstrap probabilities are con-
sidered for the exponential family of distributions with unknown expectation
parameter vector, where the null hypothesis is represented as an arbitrary-
shaped region with smooth boundaries. This problem has been discussed pre-
viously in Efron and Tibshirani [Ann. Statist. 26 (1998) 1687–1718], and a
corrected p-value with second-order asymptotic accuracy is calculated by the
two-level bootstrap of Efron, Halloran and Holmes [Proc. Natl. Acad. Sci.
U.S.A. 93 (1996) 13429–13434] based on the ABC bias correction of Efron
[J. Amer. Statist. Assoc. 82 (1987) 171–185]. Our argument is an extension
of their asymptotic theory, where the geometry, such as the signed distance
and the curvature of the boundary, plays an important role. We give another
calculation of the corrected p-value without finding the “nearest point” on the
boundary to the observation, which is required in the two-level bootstrap and
is an implementational burden in complicated problems. The key idea is to al-
ter the sample size of the replicated dataset from that of the observed dataset.
The frequency of the replicates falling in the region is counted for several
sample sizes, and then the p-value is calculated by looking at the change
in the frequencies along the changing sample sizes. This is the multiscale
bootstrap of Shimodaira [Systematic Biology 51 (2002) 492–508], which is
third-order accurate for the multivariate normal model. Here we introduce a
newly devised multistep-multiscale bootstrap, calculating a third-order accu-
rate p-value for the exponential family of distributions. In fact, our p-value
is asymptotically equivalent to those obtained by the double bootstrap of
Hall [The Bootstrap and Edgeworth Expansion (1992) Springer, New York]
and the modified signed likelihood ratio of Barndorff-Nielsen [Biometrika
73 (1986) 307–322] ignoring O(n−3/2) terms, yet the computation is less
demanding and free from model specification. The algorithm is remarkably
simple despite complexity of the theory behind it. The differences of the p-
values are illustrated in simple examples, and the accuracies of the bootstrap
methods are shown in a systematic way.
1. Introduction. We start with a simple example of Efron and Tibshirani
(1998) to illustrate the issue to discuss. Let X1, . . . ,Xn be independent p-dimen-
sional multivariate normal vectors with mean vector µ and covariance matrix
Received November 2000; revised March 2004.
1Supported in part by Grant KAKENHI-14702061 from MEXT of Japan.
AMS 2000 subject classifications. Primary 62G10; secondary 62G09.
Key words and phrases. Problem of regions, approximately unbiased tests, third-order accuracy,
bootstrap probability, curvature, bias correction.
2616
MULTISTEP-MULTISCALE BOOTSTRAP 2617
identity Ip,
X1, . . . ,Xn ∼ Np(µ, Ip).
For given observed values x1, . . . , xn, let us assume that we would like to know
whether ‖µ‖2 = µ21 + · · · + µ2p ≤ 1 or not. The problem is also described in a
transformed variable Y = √nX with mean η = √nµ, where x¯ = (x1 +· · ·+xn)/n
is the sample average. We have observed a p-dimensional multivariate normal
vector y having unknown mean vector η and covariance matrix the identity,
Y ∼ Np(η, Ip).(1.1)
Then the null hypothesis we are going to test is η ∈R, with the spherical region
R= {η :‖η‖ ≤ √n }.(1.2)
This problem is simple enough to give the exact answer. The frequentist
confidence level, namely, the probability value (p-value) for the spherical null
hypothesis is calculated as the probability of ‖Y‖2 being greater than or equal
to the observed ‖y‖2 assuming that η is on the boundary ∂R = {η :‖η‖ = √n }
of R. The exact p-value is easily calculated knowing that ‖Y‖2 is distributed as
the chi-square distribution with degrees of freedom p and noncentrality ‖η‖2.
In this paper we are going to remove two restrictions in the above problem
for generalization. (i) The underlying probability model for Y is the exponential
family of distributions, instead of the multivariate normal model; we denote the
density function with the expectation parameter η as
Y ∼ f (y;η).(1.3)
(ii) The null hypothesis will be represented as an arbitrarily-shaped regionR with
smooth boundaries, instead of the spherical region. The surface of ∂R may be
represented as the Taylor series with coefficients dab, eabc, . . .
ηp = −dabηaηb − eabcηaηbηc + · · ·(1.4)
in the local coordinates (η1, . . . ,ηp) by taking the origin at a point on ∂R
and rotating the axes properly. The summation convention such as dabηaηb =∑p−1
a=1
∑p−1
b=1 dabηaηb will be used, where the indices a, b, . . . may run through
1, . . . , p − 1 and i, j, . . . may run though 1, . . . , p when used as subscripts or
superscripts for p-dimensional vectors. The axes are taken so that η1, . . . ,ηp−1
are for the tangent space of the surface, and ηp is for its orthogonal space
taken positive in the direction pointing away from R. This general setting is the
“problem of regions” discussed previously in Efron and Tibshirani (1998), and our
argument is an extension of their asymptotic theory, where the geometry, such as
the signed distance and the curvature of the boundary, plays an important role.
Since the exact p-value is available only for special cases, we will discuss
several bootstrap methods to calculate approximate p-values from y under the
2618 H. SHIMODAIRA
assumptions (i) and (ii) above. Let α denote a specified significance level, and
αˆ(y) denote an approximate p-value. A large value of αˆ(y) may indicate evidence
to support the null hypothesis η ∈R. On the other hand, if αˆ(y) < α is observed,
then we reject the null hypothesis and conclude that η /∈R. The hypothesis test of
R is said to be unbiased if the rejection probability is equal to α whenever η ∈ ∂R.
The approximate p-value is said to be kth order accurate if the asymptotic bias is
of order O(n−k/2), that is,
Pr{αˆ(Y ) < α;η} = α + O(n−k/2), η ∈ ∂R,(1.5)
holds for 0 < α < 1. For sufficiently large n, approximately unbiased p-values
of higher-order accuracy are considered to be better than those of lower-order
accuracy.
We will not specify the probabilistic model or the shape of the region explicitly
in the calculation of the p-value, but only assume that a mechanism is available to
us for generating the bootstrap replicates and identifying whether the outcomes
are in the region or not. This setting is important for complicated practical
applications, where the exact p-value is not available and, thus, bootstrap methods
are used for approximation. The phylogenetic tree selection discussed in Efron,
Halloran and Holmes (1996) and Shimodaira (2002) is a typical case; the
history of evolution represented as a tree is inferred by a model-based clustering
of the DNA sequences of organisms, where we are given complex computer
software for inferring the tree from a dataset. For calculating p-values of the
hypothetical evolutionary trees, we can easily run bootstrap simulations, although
computationally demanding, by repeatedly applying the software to replicated
datasets.
We confine our attention to the parametric bootstrap of continuous random
vectors for mathematical simplicity. We also assume that the boundary of the
region is a smooth surface. In practical applications, however, it is often the case
that the nonparametric bootstrap is employed, the random vector is discrete and the
boundary is nonsmooth. Regions with nonsmooth boundaries, in particular, may
lead to serious difficulty as discussed in Perlman and Wu (1999, 2003). Further
study is needed to bridge these gaps between the theory and practice.
The frequency of the bootstrap replicates falling in the region, namely, the
bootstrap probability, has been used widely since its application to phylogenetic
tree selection in Felsenstein (1985). This is also named “empirical strength
probability” of R in Liu and Singh (1997), where a modification for nonsmooth
boundary is discussed as well. The bootstrap probability is, however, biased
as an approximation to the exact p-value and, thus, the two-level bootstrap of
Efron, Halloran and Holmes (1996) and Efron and Tibshirani (1998) is developed
to improve the accuracy. Under the assumptions (i) and (ii) above, the two-
level bootstrap calculates a second-order accurate p-value, whereas the bootstrap
probability is only first-order accurate.
MULTISTEP-MULTISCALE BOOTSTRAP 2619
The bias of the bootstrap probability mainly arises from the curvature of ∂R.
The two-level bootstrap estimates the curvature for bias correction, where the
curvature is estimated by generating second-level replicates around ηˆ(y). Here
ηˆ(y) denotes the maximum likelihood estimate for η restricted to ∂R. ηˆ(y) is the
nearest point on ∂R to y for (1.1). For the spherical region, ηˆ(y) = √ny/‖y‖
is easily obtained, but ηˆ(y) must be obtained by numerical search in general,
leading to an implementational burden in complex problems. This motivated our
development of a new method.
The multiscale bootstrap is developed in Shimodaira (2002) to calculate another
bias corrected p-value. It does not require ηˆ(y). Instead, the bootstrap probabilities
are calculated for sets of bootstrap replicates with several sample sizes which may
differ from that of the observed data. This, in effect, alters the scale parameter of
the replicates (Figure 1). The key idea is to estimate the curvature from the change
in the bootstrap probabilities along varying sample sizes. The corrected p-value
is third-order accurate for any arbitrarily-shaped region with smooth boundaries
under the multivariate normal model. The normality assumption is not as restrictive
as it might look at first, because the procedure is transformation-invariant and
should work fine if there exists a transformation from the dataset to the normal
Y and if the null hypothesis is represented as a region of η. We do not have to
know what the transformation is. However, it becomes only first-order accurate if
there is no such transformation to (1.1) but only one to (1.3).
The multiscale bootstrap can be used easily for complex problems. It is as
easy as the usual bootstrap. We only have to change the sample size of the
FIG. 1. Multiscale bootstrap. The three circles with dashed lines indicate the conditional
distributions of the bootstrap replicates with mean y and scales τ = 1/√2,1,√2. In this particular
configuration, the bootstrap probability may increase by halving the sample size to alter τ = 1 to√
2, and may decrease by doubling the sample size to alter τ = 1 to 1/√2.
2620 H. SHIMODAIRA
bootstrap replicates, and apply a regression fit to the bootstrap probabilities.
The bias corrected p-value is calculated from the slope of the regression curve
(Figure 2). This procedure is implemented in computer software [Shimodaira and
Hasegawa (2001)] for phylogenetic tree selection, and is also applied to gene
network estimation from microarray expression profiles [Kamimura et al. (2003)].
In these applications, the multiscale bootstrap can calculate the p-values for many
related hypotheses at the same time; we do not have to run time-consuming
bootstrap simulations separately for these hypotheses. For example, biologists are
interested in the monophyletic hypothesis that some specified species constitute a
cluster in the phylogenetic tree, and there are many such hypotheses for groups of
species. The bootstrap probabilities for these hypotheses are obtained at the same
time from a single run of bootstrap simulation for each scale. We only have to
apply the regression fit separately to the multiscale bootstrap probabilities of each
hypothesis.
In this paper we provide the theoretical foundation of the multiscale bootstrap,
and introduce a newly devised multistep-multiscale bootstrap resampling. This
method calculates an approximately unbiased p-value with third-order asymptotic
accuracy under the assumptions (i) and (ii). The previously developed method of
Shimodaira (2002) corresponds to a special case of the new method, that is, the
one-step multiscale bootstrap.
For explaining the bootstrap methods, a rather intuitive argument is given in
Sections 2 to 6 using simple examples. A more formal argument is given in
Section 7, and the technical details are given in a supporting document [Shimodaira
(2004)]. We introduce a modified signed distance, and give a unified approach to
the asymptotic analysis of the bootstrap methods using Edgeworth series, as well
as the tube formula of Weyl (1939). Third-order accuracy is also shown there for
the p-value computed by the modified signed likelihood ratio [Barndorff-Nielsen
(1986)], which requires the analytic expression of the likelihood function, and for
the p-value computed by the double bootstrap [Hall (1992)], which requires a huge
number of replicates, as well as computation of ηˆ(y). The multistep-multiscale
bootstrap method requires only the bootstrap mechanism for generating replicates
around y, inheriting the simplicity from the one-step multiscale bootstrap. The
price for higher-order accuracy and simpler implementation is a large number
of replicates, which can be as large as that of the double bootstrap. These three
p-values are, in fact, shown to be equivalent ignoring O(n−3/2) terms.
Our argument may not be justified unless the assumptions (i) and (ii) hold.
We are not sure yet how robust the multistep-multiscale bootstrap method is
under misspecifications of the exponential family model. It is shown at the end
of Section 4, however, that the one-step method adjusts the bias halfway, though
not completely, under misspecifications of the normal model. A simulation study
in Shimodaira (2002) shows that the bias of the one-step method under the normal
model is very small even if the boundary is piecewise smooth, but the bias becomes
larger as η moves closer to nonsmooth points on the boundary.
MULTISTEP-MULTISCALE BOOTSTRAP 2621
2. Two-level bootstrap resampling. Although our ultimate goal is to get
rid of the normal assumption, we use normality in this section to illustrate the
bootstrap methods, and besides (1.1), we also assume (1.2). For given observed
value x¯, we consider the parametric bootstrap resampling
X∗1, . . . ,X∗n1 ∼ Np(x¯, Ip).
Typically, the sample size n1 of the replicated dataset should be equal to n, but
we reserve the generality of using any value for n1. The scaling factor of the
bootstrap, τ1 = √n/n1, will be altered later in the multiscale bootstrap. Once
we specify τ1, we may generate B , say 10,000, replicated datasets, and compute
the average X∗ = (X∗1 + · · · + X∗n1)/n1 for each replicate. A large value of the
frequency that ‖X∗‖2 ≤ 1 holds in the replicates may indicate a high chance of
the null hypothesis ‖µ‖2 ≤ 1 being correct. This is also described in a transformed
variable Y ∗ = √nX∗. For given observed value y, we consider the parametric
bootstrap resampling
Y ∗ ∼ Np(y, τ 21 Ip),(2.1)
and the bootstrap probability with scale τ1 is denoted by
α˜1(y, τ1) = Pr{Y ∗ ∈R;y, τ1},
where the index 1 indicates the “one-step” bootstrap in connection with α˜2 and
α˜3 defined later, as shown in Table 1. α˜1 is estimated by the frequency of Y ∗ ∈R
from the B bootstrap replicates with the binomial variance α˜1(1 − α˜1)/B .
Let us consider a numerical example with
p = 4, n = 10, ‖x¯‖2 = 2.680.(2.2)
Although ‖x¯‖2 > 1, we are not sure if ‖µ‖2 ≤ 1 holds or not. The frequentist
confidence level for the null hypothesis is given by the exact p-value, which
TABLE 1
Bootstrap probabilities and corrected p-values
Symbol Section Description
α˜1(y, τ1) 2 Bootstrap probability
αˆ∞(y) 2 Exact p-value∗
αˆ0(y) 2 Bootstrap probability (τ1 = 1)
αˆabc(y) 2 Two-level bootstrap corrected p-value
αˆ1(y) 3 Multiscale bootstrap corrected p-value
α˜2(y, τ1, τ2) 4 Two-step bootstrap probability
αˆ2(y) 4 Two-step multiscale bootstrap corrected p-value
α˜3(y, τ1, τ2, τ3) 5 Three-step bootstrap probability
αˆ3(y) 5 Three-step multiscale bootstrap corrected p-value
∗A third-order accurate p-value in Section 7.
2622 H. SHIMODAIRA
we will denote by αˆ∞(y), or simply αˆ∞ for brevity sake. In this numerical
example, the value of ‖x¯‖2 is, in fact, chosen to make αˆ∞(y) = 0.05. αˆ∞ may
be approximated by the bootstrap probability with τ1 = 1, denoted by
αˆ0(y) = α˜1(y,1).
This turns out to be αˆ0(y) = 0.0085, showing αˆ0 is not a very good approximation
to αˆ∞. Here the problem is so simple that αˆ0(y), as well as αˆ∞(y), can be
computed numerically from the noncentral chi-square distribution function. If the
bootstrap resampling with B = 10,000, say, is used for αˆ0, the standard error
becomes 0.0009.
A modification of αˆ0 is developed based on the geometric theory in Efron,
Halloran and Holmes (1996) and Efron and Tibshirani (1998) to improve the
accuracy of the approximation to αˆ∞. The idea is to compute αˆ0(ηˆ(y)) by
generating the second-level replicates around ηˆ(y) for estimating the curvature
of the surface ∂R. When the surface of ∂R is flat, αˆ0(ηˆ(y)) = 12 . It becomes
smaller/larger than 12 when the surface is curved toward/away from R. Let z
denote a generic symbol for the z-value corresponding to a p-value α with relation
z = −−1(α), where −1(·) is the inverse of the standard normal distribution
function (·). For example, we may write zˆ0(y) = −−1(αˆ0(y)). The ABC
conversion formula of Efron (1987) and DiCiccio and Efron (1992) is
zˆabc(y) = zˆ0(y) − zˆ0(ηˆ(y))1 − aˆ(zˆ0(y) − zˆ0(ηˆ(y)) − zˆ0(ηˆ(y)),(2.3)
where zˆabc(y), zˆ0(y), and zˆ0(ηˆ(y)) are denoted Ẑ, Z˜, and zˆ0, respectively, in
the notation of equation (6.6) of Efron and Tibshirani (1998). The corrected
p-value for the two-level bootstrap is then defined by αˆabc(y) = (−zˆabc(y)).
The acceleration constant aˆ, characterizing the probabilistic model, is known to
be aˆ = 0 for the normal model. aˆ may also be estimated using the second-level
bootstrap for (1.3); for details we refer to Efron, Halloran and Holmes (1996).
Note that the sign in front of aˆ in (2.3) is reversed from that of equation (6.6) of
Efron and Tibshirani (1998), because the ηp-axis is taking the opposite direction
here.
The p-values for the numerical example of (2.2) are
αˆ0(y) = 0.0085, αˆ0(ηˆ(y)) = 0.315,
αˆabc(y) = 0.0775, αˆ∞(y) = 0.05.
We observe that αˆabc shows great improvement over αˆ0 to approximate αˆ∞. This
improvement is also confirmed in the asymptotic argument. It has been shown
in Efron and Tibshirani (1998) that k = 1 for αˆ0, and k = 2 for αˆabc under
(1.3) and (1.4).
MULTISTEP-MULTISCALE BOOTSTRAP 2623
3. Multiscale bootstrap resampling. Here we continue to use the normal
model (1.1) for the argument of the corrected p-value in this section. The bootstrap
probability changes if the replicate sample size changes. When we alter n1 = 10
to n1 = 3 for the numerical example of (2.2), or equivalently alter the scale τ1 = 1
to τ1 = √10/3, we observe that αˆ1(y,1) = 0.0085 changes to αˆ1(y,√10/3 ) =
0.0359. In the multiscale bootstrap, αˆ1(y, τ1) is computed for several values of
τ1 = √n/n1. For example, instead of n = 10, we use the following five n1 values:
n1 = 3,6,10,15,21,(3.1)
and compute the corresponding bootstrap probabilities
α˜1(y, τ1) = 0.0359,0.0205,0.0085,0.0028,0.0008.(3.2)
These values, as well as those for other parameter settings, are shown in Figure 2
by plotting the z-value along the inverse of the scale. The horizontal axis is
1/τ1 = √n1/n = 0.55,0.78,1,1.23,1.45, and the vertical axis is z˜1(y, τ1) =
−−1(α˜1(y, τ1)) = 1.80,2.04,2.39,2.77,3.17.
Figure 2 shows these values along with a regression fit. This is obtained by
fitting a regression model with explanatory variables 1/τ1 and τ1,
z˜1(y, τ1) ≈ vˆ/τ1 + cˆτ1,(3.3)
to the plot, where vˆ and cˆ are the regression coefficients estimated as
vˆ = 2.002, cˆ = 0.385(3.4)
for the plot of (3.2). We observe that the regression fit agrees with the plots very
FIG. 2. Plots of the z-value of the multiscale bootstrap probability along the inverse of the scale τ
for the normal example (p = 4) of Section 2 and the exponential example (p = 1) of Section 4.
Parameter values are chosen so that the exact p-value is either 0.05 (left panel) or 0.95 (right panel).
The curves are drawn by the regression model of equation (3.3).
2624 H. SHIMODAIRA
well for the cases in Figure 2. The regression model (3.3) has been justified in
Shimodaira (2002) under (1.1) and (1.4); we will use “≈” to indicate that equality
holds up to O(n−1) terms with the error of order O(n−3/2). The regression model
with explanatory variables 1/τ1 and τ1 will be justified later, in fact, under (1.3)
and (1.4) as seen in (7.15), although the following interpretation of the coefficients
should be modified accordingly.
A simple geometric interpretation can be given to the regression coefficients
under (1.1) and (1.4). Efron and Tibshirani (1998) have shown a formula equivalent
to
zˆ0(y) ≈ vˆ + cˆ,(3.5)
where vˆ and cˆ correspond to x0 and dˆ1−x0dˆ2, respectively, in their equation (2.19).
vˆ is the signed distance of Efron (1985), defined as the distance from y to
∂R with a positive/negative sign when y is outside/inside of R. Thus, vˆ =
±‖y − ηˆ(y)‖ measures evidence of the null hypothesis being wrong. cˆ is related
to the (p − 1) × (p − 1) matrix dˆab measuring the curvature of ∂R at ηˆ(y);
dˆab is defined as dab in (1.4) by making the local coordinates orthonormal at
ηˆ(y). In our notation, cˆ = dˆ1 − vˆdˆ2, where dˆ1 = dˆaa is the trace of dˆab, and
dˆ2 = (dˆab)2 =∑p−1a=1 ∑p−1b=1 (dˆab)2 is that for the squared matrix. When ∂R is flat at
ηˆ(y), dˆab = 0 and, thus, cˆ = 0. vˆ, dˆ1 and dˆ2 are transformation-invariant functions
of y calculated from the shape of the boundary and the density function of Y ; they
are referred to as geometric quantities here. Under (1.1) and (1.2) these quantities
are
vˆ = ‖y‖ − √n, dˆ1 = p − 12√n , dˆ2 =
p − 1
4n
.(3.6)
This computes directly,
vˆ = 2.015, cˆ = 0.323(3.7)
for (2.2), showing good agreement with those computed indirectly from the
multiscale bootstrap. vˆ and cˆ in (3.4) are actually estimating those in (3.7), thus, it
would be appropriate to denote the former as ˆˆv and ˆˆc, although we do not make the
notational distinction. This estimation is third-order accurate, since the regression
model (3.3) holds for (3.7) with error of O(n−3/2).
Considering that vˆ and cˆ are functions of y, we may define a statistic
zˆ1(y) = vˆ − cˆ.(3.8)
This is equivalent to the pivot statistic of Efron (1985), and Pr{zˆ1(Y ) ≤ x;η} ≈
(x) for η ∈ ∂R under (1.1) and (1.4); see equation (2.16) of Efron and Tibshirani
(1998). Thus, a third-order accurate p-value is defined by αˆ1(y) = (−zˆ1(y)). We
MULTISTEP-MULTISCALE BOOTSTRAP 2625
can compute αˆ1(y) using vˆ and cˆ obtained from the multiscale bootstrap. For the
example of (2.2),
αˆ1(y) = (−2.002 + 0.385) = 0.0529,
showing an improvement over αˆabc(y) = 0.0775 to approximate αˆ∞(y) = 0.05.
The index of αˆ1 indicates the “one-step” bootstrap as similarly for α˜1.
It is interesting to note that we can also read off the values of zˆ1(y) from
Figure 2. The differentiation of (3.3) with respect to 1/τ1 is
∂z˜1(y, τ1)
∂(1/τ1)
≈ vˆ − cˆτ 21 ,
and the slope of the regression curve at 1/τ1 = 1 gives zˆ1(y). The corrected
p-value αˆ1 is essentially obtained from the change of the bootstrap probability
in the multiscale bootstrap.
4. Two-step multiscale bootstrap resampling. The one-step multiscale
bootstrap described in Section 3 calculates a very accurate p-value for the
arbitrarily-shaped region if there exists a transformation from the dataset to the
normal model. However, it can be inaccurate if such a transformation does not
exist even approximately. This restriction essentially comes from the fact that the
covariance matrix of y in (1.1) is constant with respect to η. The acceleration
constant aˆ of the ABC formula measures the rate of change in the covariance
matrix, and aˆ is assumed zero in the derivation of (3.8). Here we introduce the
two-step multiscale bootstrap for estimating aˆ to improve the accuracy of the one-
step multiscale bootstrap.
A breakdown of the one-step multiscale bootstrap method is illustrated in the
following example. Let X1, . . . ,Xn be one-dimensional independent exponential
random variables with mean µ,
X1, . . . ,Xn ∼ exp(−x/µ − logµ),
and let the null hypothesis of interest be µ ≤ 1. The exact p-value is calculated
by knowing that a transformed variable Y = √nX is distributed as Gamma with
shape n and mean η = √nµ. We consider a numerical example with
p = 1, n = 10, x¯ = 1.571,(4.1)
so that αˆ∞(y) = 0.05. The multiscale bootstrap probabilities for the five n1 values
in (3.1) are computed as
α˜1(y, τ1) = 0.2990,0.1875,0.1115,0.0622,0.0322,(4.2)
and the regression coefficients of (3.3) are estimated as vˆ = 1.328, cˆ = −0.110.
Then the corrected p-value is computed as
αˆ1(y) = (−1.328 − 0.110) = 0.0753.(4.3)
2626 H. SHIMODAIRA
Although this is an improvement over αˆ0(y) = 0.112, it is not as good as in the
normal example above. The pivot (3.8) is not justified under (1.3) in general, and
αˆ1(y) is, in fact, only first-order accurate for the exponential example.
The two-step multiscale bootstrap is employed simply to generate a second-step
replicate from every first-step replicate. Let us denote the conditional density of the
first-step bootstrap replicate Y ∗ = √nX∗ as
Y ∗ ∼ f (y∗;y, τ1),(4.4)
given mean y = √nX and scale τ1 under (1.3), which reduces to f (y∗;y,1) =
f (y∗;y) when τ1 = √n/n1 is unity. This becomes (2.1) for (1.1), and Gamma
with shape n1 and mean y for the exponential example. We generate a second-step
replicate Y ∗∗ for each y∗. The conditional density of Y ∗∗ given y∗ takes the same
form as (4.4), but with scale parameter τ2 = √n/n2;
Y ∗∗ ∼ f (y∗∗;y∗, τ2).(4.5)
For the normal example, (4.5) is equivalent to generating
X∗∗1 , . . . ,X∗∗n2 ∼ Np(x¯∗, Ip)
for given x¯∗, and using the transformed variable Y ∗∗ = √nX∗∗. The two-step
bootstrap probability with a pair of scales (τ1, τ2) is then defined by
α˜2(y, τ1, τ2) = Pr{Y ∗∗ ∈R;y, τ1, τ2}
=
∫
α˜1(y
∗, τ2)f (y∗;y, τ1) dy∗,
where the integration is taken over the range of the components. We can write
α˜1(y, τ1) = α˜2(y, τ1,0), because the conditional density of Y ∗∗ converges to the
point mass at y∗ by taking the limit τ2 → 0. The two-step bootstrap might look
similar to the double bootstrap of Hall (1992), but they are very different. We
should generate thousands of Y ∗∗ for given y∗ in the double bootstrap, but only
one Y ∗ in the two-step bootstrap.
Let us consider two n2 values,
n2 = 6,15,(4.6)
for the normal example with parameter values (2.2). The two-step bootstrap
probabilities are, for example,
α˜2
(
y,
√
10
6 ,
√
10
6
)= 0.0359, α˜2(y,√1010 ,
√
10
15
)= 0.0205.
Of course, they give α˜1(y,
√
10
3 ) and α˜1(y,
√
10
6 ), respectively, in (3.2), because
α˜2(y, τ1, τ2) = α˜1(y,√τ 21 + τ 22 )
MULTISTEP-MULTISCALE BOOTSTRAP 2627
for (1.1). For the exponential example with parameter values (4.1), however,
α˜2
(
y,
√
10
6 ,
√
10
6
)= 0.3063, α˜2(y,√1010 ,
√
10
15
)= 0.1866
are different, though very slightly, from α˜1(y,
√
10
3 ) = 0.2990 and α˜1(y,
√
10
6 ) =
0.1875, respectively, in (4.2). The difference of α˜2(y, τ1, τ2) from α˜1(y,
√
τ 21 + τ 22 )
for (1.3) is explained by
z˜2(y, τ1, τ2) − z˜1(y,√τ 21 + τ 22 ) .= aˆτ 21 τ 22 (vˆ2 − (τ 21 + τ 22 ))
(τ 21 + τ 22 )5/2
.(4.7)
We will use “ .=” to indicate that equality holds up to O(n−1/2) terms with error of
order O(n−1). Formula (4.7) and a revised regression model
z˜1(y, τ1)
.= vˆ − 2aˆvˆ
2
τ1
+ (dˆ1 − aˆ)τ1(4.8)
for (1.3) are consequences of a more general argument with third-order accuracy
shown in Section 7.
The key idea in the two-step multiscale bootstrap is to estimate aˆ by looking at
the difference of α˜2(y, τ1, τ2) from α˜1(y,
√
τ 21 + τ 22 ). Once we compute α˜1(y, τ1)
and α˜2(y, τ1, τ2) for several values of (τ1, τ2) by the one-step and two-step
multiscale bootstrap, we can estimate vˆ, dˆ1 and aˆ by fitting (4.7) and (4.8) to the
observed bootstrap probabilities. A second-order accurate p-value, denoted αˆ2(y),
is then computed by using the estimated geometric quantities in the z-value
zˆ2(y)
.= vˆ − dˆ1 + aˆ(1 − vˆ2).(4.9)
This expression is shown to be equivalent to (2.3) up to O(n−1/2) terms by using
(4.8); zˆ0(y) .= vˆ + dˆ1 − aˆ(1 + 2vˆ2) and zˆ0(ηˆ(y)) .= dˆ1 − aˆ. In the next section we
will describe a procedure based on the above idea, as well as its refined version
with third-order accuracy.
It follows from (4.8) that the one-step multiscale bootstrap estimates vˆ − 2aˆvˆ2
and dˆ1 − aˆ for the coefficients vˆ and cˆ, respectively, under (1.3). Thus, zˆ1(y) .=
vˆ − dˆ1 + aˆ(1 − 2vˆ2) .= zˆ2(y)− aˆvˆ2, as well as zˆ0(y) .= zˆ2(y)+ 2dˆ1 − 2aˆ − aˆvˆ2, is
first-order accurate in general. Since the difference zˆ2(y) − zˆ1(y) .= aˆvˆ2 does not
involve dˆ1, the one-step method adjusts the bias resulting from the curvature even
if the normal model is misspecified.
5. Three-step multiscale bootstrap resampling. We may repeat “stepping”
to obtain multistep-multiscale bootstrap probabilities so that we might be able to
compute higher-order accurate p-values. This is the case, in fact, for going one step
further, although the results are not known for yet further stepping. We introduce
the three-step multiscale bootstrap for computing a third-order accurate p-value,
2628 H. SHIMODAIRA
denoted αˆ3(y), under (1.3) and (1.4). In the following argument, we first describe
the procedure to compute αˆ2(y), which helps understand that for αˆ3(y).
The expression for zˆ2(y, τ1, τ2) is obtained from (4.7) by substituting
√
τ 21 + τ 22
for τ1 in (4.8). This is also expressed as
z˜2(y, τ1, τ2)
.= ζ2(γˆ1, γˆ2, γˆ3, τ1, τ2),(5.1)
where the function ζ2 on the right-hand side is defined by
ζ2(γ1, γ2, γ3, τ1, τ2) = s1γ1(1 + s2γ3) − γ2 + s2γ3
s1γ1
.(5.2)
Here s1 = (τ 21 + τ 22 )−1/2 and s2 = τ 21 τ 22 s41 are functions of the scales, and the γˆi’s
are specified as functions of y under (1.3) and (1.4);
γˆ1
.= vˆ − 2aˆvˆ2, γˆ2 .= vˆ(aˆ − dˆ1), γˆ3 .= vˆaˆ.(5.3)
These γˆi’s are also used to express
zˆ2(y) = γˆ1(1 + γˆ3) + γˆ2
γˆ1
,(5.4)
which is equivalent to (4.9) up to O(n−1/2) terms. We calculate α˜2(y, τ1, τ2)
for several values of (τ1, τ2) by the two-step multiscale bootstrap resampling,
and fitting the observed z˜2(y, τ1, τ2) = −−1(α˜2(y, τ1, τ2)) to the nonlinear
regression model (5.1). Then the estimated γˆi’s are used to compute αˆ2(y) =
(−zˆ2(y)) from (5.4).
This procedure is generalized for the three-step multiscale bootstrap resampling.
A third-step replicate Y ∗∗∗ is generated for each y∗∗ by
Y ∗∗∗ ∼ f (y∗∗∗;y∗∗, τ3)
using the scale τ3, and the three-step bootstrap probability is defined by
α˜3(y, τ1, τ2, τ3) = Pr{Y ∗∗∗ ∈R;y, τ1, τ2, τ3}
=
∫
α˜2(y
∗, τ2, τ3)f (y∗;y, τ1) dy∗.
Then, observed z˜3(y, τ1, τ2, τ3) = −−1(α˜3(y, τ1, τ2, τ3)) for several values of
(τ1, τ2, τ3) are fitted to the nonlinear regression model ζ3, defined by
ζ3(γ1, γ2, γ3, γ4, γ5, γ6, τ1, τ2, τ3)
= γ1s1(1 + γ3s2 + 4γ 23 s22 + γ5s3 + γ6s4)(5.5)
− (γ1s1)−1(γ2 + γ3s2 + 7γ 23 s22 + γ4s2 + 3γ5s3 + 3γ6s4),
where s1, . . . , s4 are given by
s1 = (τ 21 + τ 22 + τ 23 )−1/2, s2 = (τ 21 τ 22 + τ 22 τ 23 + τ 23 τ 21 )s41 ,
s3 = (τ 21 τ 22 τ 23 + τ 42 τ 23 + τ 41 (τ 22 + τ 23 ))s61 , s4 = (τ 21 τ 22 τ 23 )s61 .
MULTISTEP-MULTISCALE BOOTSTRAP 2629
The least squares estimates for the six γi ’s are denoted by γˆ1, . . . , γˆ6. We then
compute αˆ3(y) = (−zˆ3(y)) by using the estimated γˆi’s in
zˆ3(y) = γˆ1(1 + γˆ3 + 4γˆ 23 + γˆ6) + γˆ−11 (γˆ2 + γˆ 23 /2 + γˆ4 + γˆ5).(5.6)
Section 7 is mostly devoted to proving the third-order accuracy of αˆ3(y). The
justification for the second-order accuracy of αˆ2(y) then immediately follows by
ignoring O(n−1) terms. As seen in (5.3), γˆ1 is O(1), and γˆ2 and γˆ3 are O(n−1/2).
The rest of the three O(n−1) geometric quantities are defined in Section 7.8. We do
not have to know, however, the expressions of γˆi’s for computing αˆ3(y), because
their values are estimated from the nonlinear regression, and the estimation error
is only O(n−3/2).
It should be noted that there are other asymptotically equivalent expressions
for ζ3 and zˆ3 as functions of coefficients transformed from the six γˆi’s; we have
shown the two different expressions for ζ2 and zˆ2 as functions of either γˆ1, γˆ2, γˆ3
or vˆ, dˆ1, aˆ. The expressions (5.5) and (5.6) are obtained by seeking simple ones.
6. Examples. The two procedures in the previous section are applied to the
exponential example with parameter values (4.1). By the two-step multiscale
bootstrap, the least squares estimates of γˆi ’s are
γˆ1 = 1.328, γˆ2 = 0.144, γˆ3 = 0.137,
and the corrected p-value is computed as
αˆ2(y) = 1 − {1.328(1 + 0.137)+ 0.1441.328}= 0.0528,
which comes closer to the exact p-value αˆ∞(y) = 0.05 than αˆ1(y) = 0.0753
computed in (4.3). By the three-step multiscale bootstrap, the least squares
estimates of the γˆi’s are
γˆ1 = 1.328, γˆ2 = 0.145, γˆ3 = 0.127,
γˆ4 = −0.018, γˆ5 = −0.0004, γˆ6 = −0.036,
and the corrected p-value is
αˆ3(y) = 1 − 
{
1.328(1 + 0.127 + 0.065 − 0.036)
+ 0.145 + 0.008 − 0.018 − 0.0004
1.328
}
= 0.0509,
which is even better than αˆ2(y) = 0.0528.
In Table 2 p-values are computed for several parameter settings. The bootstrap
probabilities are computed numerically (B = ∞), but the standard errors due to the
bootstrap resampling are shown for B = 10,000. The first row corresponds to the
normal model with (2.2), and the fourth row corresponds to the exponential model
with (4.1). The following two rows for each are obtained by changing n = 10 to
2630 H. SHIMODAIRA
TABLE 2
p-values in percent (standard error) for the examples∗
Ridge regression
n αˆ0 αˆabc αˆ1 αˆ2 αˆ3 αˆ2 αˆ3
Normal distribution (αˆ∞ = 5.00)
10 0.85 7.75 5.29 (0.61) 5.85 (1.81) 7.03 (8.04) 5.67 (1.03) 6.04 (1.13)
100 2.73 5.25 5.01 (0.37) 5.05 (1.16) 5.08 (2.93) 5.04 (0.78) 5.06 (0.97)
1000 4.12 5.03 5.00 (0.32) 5.00 (1.05) 5.00 (2.22) 5.00 (0.72) 5.00 (0.89)
Exponential distribution (αˆ∞ = 5.00)
10 11.15 5.00 7.53 (0.31) 5.28 (0.77) 5.09 (0.95) 5.77 (0.60) 5.13 (0.68)
100 6.73 5.00 5.90 (0.30) 5.03 (0.94) 5.01 (1.50) 5.25 (0.67) 5.04 (0.81)
1000 5.52 5.00 5.29 (0.30) 5.00 (0.98) 5.00 (1.82) 5.08 (0.69) 5.01 (0.80)
Normal distribution (αˆ∞ = 95.00)
10 67.84 92.33 95.26 (0.18) 95.20 (0.41) 95.02 (0.51) 95.21 (0.34) 95.07 (0.37)
100 90.65 94.74 95.02 (0.24) 95.07 (0.84) 95.09 (1.28) 95.06 (0.60) 95.07 (0.70)
1000 93.91 94.97 95.00 (0.28) 95.00 (0.95) 95.00 (1.72) 95.00 (0.67) 95.00 (0.81)
Exponential distribution (αˆ∞ = 95.00)
10 98.78 95.00 97.99 (0.24) 94.48 (1.31) 96.12 (7.39) 95.60 (0.81) 96.48 (0.56)
100 96.49 95.00 95.95 (0.28) 94.97 (1.06) 95.01 (2.71) 95.24 (0.72) 95.14 (0.82)
1000 95.50 95.00 95.30 (0.29) 95.00 (1.02) 95.00 (2.19) 95.08 (0.70) 95.02 (0.81)
∗The bootstrap calculation is replaced by integration numerically, and, hence, the number of
bootstrap replicates is regarded as B = ∞. The standard errors in parentheses are calculated for
the case of B = 104 by the local linearization of the nonlinear regression [Draper and Smith (1998)].
All the combinations of τ21 ∈ { 103 , 106 , 1010 , 1015 , 1021 }, τ22 ∈ { 106 , 1015 }, τ23 ∈ { 106 , 1015 } are used for the
scales. The total numbers of bootstrap replicates are 5B , 15B and 35B , respectively, for αˆ1, αˆ2
and αˆ3. For the ridge regression, the penalty weights are ω1 = ω2 = 0 and ω3 = · · · = ω6 = 0.01.
100 and 1000. Similarly, the last six rows are obtained by changing αˆ∞ = 0.05 to
0.95. We observe that all the p-values tend to converge to αˆ∞ as n grows, and the
corrected p-values are faster for convergence than αˆ0.
α˜3(y, τ1, τ2, τ3) is computed for all the combinations of (τ1, τ2, τ3) values,
as noted in the table; five (τ1,0,0)’s, ten (τ1, τ2,0)’s, and twenty (τ1, τ2, τ3)’s.
Therefore, the numbers of bootstrap probabilities are 5, 15 and 35, respectively,
for αˆ1(y), αˆ2(y) and αˆ3(y). The nonlinear regression models are fitted to these
bootstrap probabilities, and the least squares estimates of the geometric quantities
are calculated; each residual term is weighted inversely proportional to the
estimated variance. For stable estimation, ridge regression is also used; a penalty
term
∑6
i=1 ωiγˆ 2i with small ωi values is added to the residual sum of squares for
minimization.
For the exponential distribution, αˆk is kth order accurate (k = 1,2,3), and,
in fact, |αˆk − αˆ∞| becomes smaller as k increases in the table. It turns out that
|αˆabc − αˆ∞| is almost zero here, because αˆabc happens to be third-order accurate
for the one-dimensional exponential distribution, as shown in Section 7.7.
MULTISTEP-MULTISCALE BOOTSTRAP 2631
For the normal distribution, αˆ1, αˆ2 and αˆ3 are third-order accurate, because γˆ3 =
· · · = γˆ6 = 0 under (1.1), as shown in Section 7.8. This may explain why |αˆk − αˆ∞|
becomes larger as k increases in some of the rows. These four geometric quantities
of zero value are estimated from slight differences of bootstrap probabilities,
leading to unstable estimation as seen in the large standard errors. This is alleviated
by ridge regression; even the worst case in the table αˆ3 = 6.04 ± 1.13 may be
allowed in practice. However, the total number of replicates is 350,000 for αˆ3,
almost comparable to that of the double bootstrap for achieving the same degree
of the standard error.
Although αˆ1 is first-order accurate for (1.3), it is reasonably accurate even for
the exponential model in the table. The total number of replicates is 50,000, yet the
standard error is considerably smaller than that of αˆ3. Similar observation holds
for the second-order accurate αˆ2. The one-step, as well as two-step, multiscale
bootstrap may provide a compromise between the number of replicates and the
accuracy in practice.
7. Asymptotic analysis of the bootstrap methods.
7.1. A unified approach. Our approach to assessing the bootstrap methods is
not very elegant but rather elementary and brute-force. We explicitly specify a
curved coordinate system along ∂R, which is convenient to work on the bootstrap
methods. The density function of Y with respect to the curved coordinates is first
defined for τ = 1 in Section 7.2 and extended for τ > 0 in Section 7.3. We define
a modified signed distance by altering vˆ slightly, and its distribution function is
given in Section 7.4.
It turns out that the z-values of the bootstrap probabilities are special cases of
the modified signed distance, and our approach gives an asymptotic analysis of
the bootstrap methods in a systematic way. Using the result of Section 7.4, a third-
order accurate pivot statistic is defined in Section 7.5, and the distribution functions
of the bootstrap z-values are shown in Sections 7.6 to 7.8, proving the main results
of Section 5.
The proofs of lemmas are given in Shimodaira (2004). We have used
the computer software Mathematica for straightforward and tedious symbolic
calculations; the program file is available from the author upon request.
7.2. Tube-coordinates. In our curved coordinate system, a point η is specified
by two parts, a point on ∂R and the signed distance from it. This is an instance
of the coordinate system used for the Weyl tube formula, and we call it tube-
coordinates. Below we will define the coordinate system explicitly, and show the
expression of the density function of Y in terms of the tube-coordinates. We take
an approach similar to that of Kuriki and Takemura (2000).
The density function of the exponential family of distributions is expressed as
exp
(
θiyi − ψ(θ) − h(y)),(7.1)
2632 H. SHIMODAIRA
where θ = (θ1, . . . , θp) is the natural parameter vector. We denote (7.1) by f (y;η)
using the expectation parameter vector η = (η1, . . . , ηp) = E(Y ), the expected
value of Y . The change of variables θ ↔ η is one-to-one, and is given by ηi =
∂ψ/∂θi , θi = ∂φ/∂ηi , i = 1, . . . , p, where the potential function φ(η) is defined
from the cumulant function ψ(θ) by φ(η) = maxθ {θiηi − ψ(θ)}. The metric at η
is denoted as
φij (η) = ∂
2φ(η)
∂ηi ∂ηj
,
and the derivatives of φ at η = 0 are denoted as
φi = ∂φ(η)
∂ηi
∣∣∣∣
0
, φij = ∂
2φ(η)
∂ηi ∂ηj
∣∣∣∣
0
, φijk = ∂
3φ(η)
∂ηi ∂ηj ∂ηk
∣∣∣∣
0
, and so on.
Since the exponential family is not uniquely expressed up to affine transformation,
we assume without loss of generality that φi = 0 and φij = δij , where δij takes
value one when i = j , otherwise zero. In other words, E(Y ) = 0 and cov(Y ), the
covariance matrix of Y , is Ip at θ = 0. We make our asymptotic argument local in
a neighborhood of η = 0 by assuming the local alternatives.
The smooth surface ∂R of the regionR is specified locally around η = 0 by
ηa(u) = ua, a = 1, . . . , p − 1; ηp(u) ≈ −dabuaub − eabcuaubuc,
where u = (u1, . . . , up−1) is the (p − 1)-dimensional parameter vector to specify
a point η(u) on ∂R. R is specified locally by ηp ≤ ηp(u). It follows from
the argument below equation (2.12) of Efron and Tibshirani (1998) that dab =
O(n−1/2) and eabc = O(n−1), and similarly, φijk = O(n−1/2) and φijkl =
O(n−1).
Let Bai (u) = ∂ηi/∂ua , i = 1, . . . , p, be the components of a tangent vector of
the surface for a = 1, . . . , p − 1. They are given explicitly as
Bab (u) = δab, b = 1, . . . , p − 1; Bap(u) ≈ −2dabub − 3eabcubuc,
and the metric in the tangent space is given by
φab(u) = φij (η(u))Bai (u)Bbj (u)
≈ δab + φabcuc(7.2)
+ {4dacdbd − 2dacφbdp − 2dbdφacp − dcdφabp + 12φabcd}ucud,
where φij (η(u)) ≈ δij + φijaua + {−dabφijp + 12φabij }uaub. Let Bpi (u), i = 1,
. . . , p, be the components of the unit length normal vector orthogonal to the
tangent vectors with respect to the metric such that
φij (η(u))Bai (u)B
p
j (u) = 0, a = 1, . . . , p − 1;
φij (η(u))B
p
i (u)B
p
j (u) = 1.
MULTISTEP-MULTISCALE BOOTSTRAP 2633
The components are calculated explicitly as Bpa (u) ≈ (2dab −φabp)ub +{3eabc +
dabφcpp + dbcφapp − 2dbdφacd + φabdφcdp + 12φabpφcpp − 12φabcp}ubuc, and
B
p
p(u) ≈ 1 − 12φappua + {−2dacdbc + 12dabφppp + 12φacpφbcp + 38φappφbpp −
1
4φ
abpp}uaub.
Let v be a scalar, and (u, v) be a p-dimensional vector. We consider
reparameterization defined by
ηi(u, v) = ηi(u)+ Bpi (u)v, i = 1, . . . , p,(7.3)
and assume η ↔ (u, v) is one-to-one at least locally around η = 0. (u, v) gives
the tube-coordinates of the point η. The boundary ∂R is expressed simply by
v = 0, and the region R is v ≤ 0. (u, v) is used for indicating the parameter
value η = η(u, v), or the observation y = η(u, v). When there is a possibility of
confusion, we may write y ↔ (uˆ, vˆ) instead of η ↔ (u, v).
Since the normal vector is orthogonal to the surface, η(u) = η(u,0) ∈ ∂R is
the projection of η(u, v) onto ∂R; uˆ is the maximum likelihood estimate under
the restricted model specified by ∂R. η(uˆ,0) is denoted by ηˆ(y) in Section 1 as a
function of y. vˆ is the signed distance mentioned for (1.1) in Section 3.
vˆ is also related to the signed likelihood ratio R [McCullagh (1984) and Severini
(2000)] by R ≈ vˆ + 16 φˆpppvˆ2 + { 124 φˆpppp − 172 (φˆppp)2}vˆ3, where φˆppp and φˆpppp
are the third and fourth derivatives to the normal direction evaluated at η(uˆ,0),
instead of η = 0. This third derivative is associated with the acceleration constant.
For the acceleration constant aˆ, the formula aˆ = −16 φˆppp is obtained directly from
equation (2.9) of DiCiccio and Efron (1992), or by using equation (6.7) of Efron
(1987) and ∂3ψ/∂θi ∂θj ∂θk = −φijk . The expression for the density function of
(Û , V̂ ) is obtained from f (y;η) by change of variables, as shown in the following
lemma.
LEMMA 1. Let Y ∼ f (y;η) be the exponential family of distributions with
η = E(Y ). Without loss of generality we may assume that cov(Y ) = Ip at η = 0
and that the true parameter value is specified by η = (0, . . . ,0, λ) for some λ, that
is, ηa = 0, a = 1, . . . , p − 1, ηp = λ, or, equivalently, u = 0, v = λ using the tube-
coordinates (u, v) ↔ η. Let f (uˆ, vˆ;λ) be the joint density function of (Û , V̂ ) ↔ Y .
Then, ignoring the error of O(n−3/2), we obtain
logf (uˆ, vˆ;λ) ≈ g(vˆ, λ) + ga(vˆ, λ)uˆa + gab(vˆ, λ)uˆauˆb(7.4)
+ gabc(vˆ, λ)uˆauˆbuˆc + gabcd(vˆ, λ)uˆauˆbuˆcuˆd ,
where the five functions on the right-hand side are defined by g(vˆ, λ) =
−12p log(2π)− 12(vˆ −λ)2 − 18φiijj + 16(φijk)2 − 13φpppλ3 − 18φppppλ4 +{2daa −
1
2φ
aap + 12φppp + 12φpppλ2 + 16φppppλ3}vˆ+{−2(dab)2 +2dabφabp − 34(φabp)2 −
1
2 (φ
app)2 − 14(φppp)2 + 14φpppp + 14φaapp}vˆ2 − 16φpppvˆ3 − 124φppppvˆ4, ga(vˆ, λ) =
1
2φ
abb + 12φappλ2 + 16φapppλ3 + {−12φappλ − dabφbcc + 5dabφbpp + φappdbb −
2634 H. SHIMODAIRA
2φabcdbc + 12φabpφbcc − 32φabpφbpp + 14φappφbbp − 34φappφppp + 12φabcφbcp −
1
2φ
abbp + 12φappp + 6eabb + dabφbppλ2 − 12φabpφbppλ2 − 14φappφpppλ2}vˆ +
{−dabφbpp + 12φabpφbpp + 14φappφppp − 16φappp}vˆ3, gab(vˆ, λ) = −12δab −dabλ−
1
2d
abφccp + 14φabcc − 14φacdφbcd +2dacdbc −2dacφbcp − 12dabφpppλ2 +{−dab +
1
2φ
abp − (2dacdbc − 12dabφppp + 14φabpp − 12φacpφbcp − 38φappφbpp)λ}vˆ,
gabc(vˆ, λ) = −16φabc − eabcλ + {−2eabc + 13φabcp − 32dabφcpp + dadφbcd −
1
2φ
abdφcdp − 14φabpφcpp}vˆ, gabcd(vˆ, λ) = −12dabdcd + 12φabpdcd − 124φabcd .
7.3. Changing the scale. We define a density function f (y;η, τ ) with mean
η and scale τ > 0 by modifying f (y;η). Here τ is regarded as a known constant,
whereas η is a unknown parameter vector. Let φ(η, τ ) be the potential function
of f (y;η, τ ), and φ(η) be that for f (y;η). Since the density function is defined
by specifying the potential function, the following equation gives a definition of
f (y;η, τ ):
φ(η, τ ) = φ(η)/τ 2.(7.5)
This f (y;η, τ ) comes naturally from the multiscale bootstrap resampling. In
fact, the potential function of the replicate Y ∗ is φ(η, τ ) = ‖η‖2/(2τ 2) for the
normal example (2.1) of Section 2, and that is φ(η, τ ) = −n(1 + logη)/τ 2 for the
exponential example of Section 4, and thus both agree with (7.5). The same applies
to the exponential family, in general, as shown below.
LEMMA 2. Let X be a p-dimensional random vector of the exponential
family. We assume that Y is expressed as a sum of m independent X’s such that
Y = √n(X1 + · · · + Xm)/m for m > 0, and that the density function is f (y;η)
when m = n. Then Y ∼ f (y;η, τ ) with τ = √n/m for τ > 0.
We continue to use the tube-coordinates defined by the reparameterization
η ↔ (u, v) of (7.3). By altering the potential φ(η,1) to φ(η, τ ), the metric, as well
as the tube-coordinates, should have changed if we go back to the specification of
η(u) and Bp(u) given in the previous section. However, we continue to use the
specification with τ = 1 for any τ > 0, so that the reparameterization η ↔ (u, v)
does not depend on τ .
LEMMA 3. Let f (uˆ, vˆ;λ) be the joint density function of (Û , V̂ ) ↔ Y given in
Lemma 1, and f (uˆ, vˆ;λ, τ ) be that corresponding to f (y;η, τ ) with scale τ > 0.
Then the expression of logf (uˆ, vˆ;λ, τ ) is obtained from (7.4) by changing (uˆ, vˆ)
to
u˜ = uˆ/τ, v˜ = vˆ/τ,(7.6)
MULTISTEP-MULTISCALE BOOTSTRAP 2635
by adding the logarithm of the Jacobian log(1/τp) to (7.4), and replacing φijk,
φijkl , dab, eabc and λ, respectively, with
φ˜ijk = τφijk, φ˜ijkl = τ 2φijkl,
(7.7)
d˜ab = τdab, e˜abc = τ 2eabc, λ˜ = λ/τ.
7.4. Modified signed distance. We consider yet another transformation of the
coordinates for expressing the bootstrap z-values in modified vˆ values. Let w be a
scalar variable defined formally by the series
w = v +
∞∑
r=0
c¯rv
r + uc
∞∑
r=0
b¯cr v
r ,(7.8)
where vr denotes the r th power. The coefficients are c¯r = O(n−1/2) and b¯cr =
O(n−1), and their expressions are specified later. We assume the transformation
(u, v) ↔ (u,w) is one-to-one at least locally around (u, v) = 0. By inverting the
series in (7.8), we also have
v = w −
∞∑
r=0
crw
r − uc
∞∑
r=0
bcrw
r,(7.9)
where cr = c¯r − ∑rs=0(r − s + 1)c¯r−s+1c¯s , and bcr = b¯cr . The coefficients are
cr = O(n−1/2) and bcr = O(n−1). Let Ŵ be the random variable corresponding to
w; the observed value wˆ is defined by (7.8) but using the observed (uˆ, vˆ) instead
of (u, v).
We call wˆ a modified signed distance characterized by the coefficients bcr , cr ;
wˆ reduces to vˆ when all these coefficients are zero. The z-values of the bootstrap
probabilities are represented as wˆ by appropriately specifying the coefficients. The
following lemma plays a key role in studying the distributional properties of the
bootstrap probabilities.
LEMMA 4. Let us assume that the distribution of Y in the tube-coordinates is
specified by (Û , V̂ ) ∼ f (uˆ, vˆ;λ, τ ), and the coefficients in (7.9) are of order bcr =
O(n−1) for r ≥ 0, c0 = O(n−1/2), c1 = O(n−1), c2 = O(n−1/2), c3 = O(n−1)
and cr = O(n−3/2) for r ≥ 4. We define zc(wˆ;λ, τ ) from the distribution function
of the modified signed distance Ŵ as
Pr{Ŵ ≤ wˆ} = (zc(wˆ;λ, τ )).
Then the zc-formula is, ignoring the error of O(n−3/2), expressed as
zc(wˆ;λ, τ ) ≈ τ−1g−(wˆ, λ) + τg+(wˆ, λ),(7.10)
where g−(wˆ, λ) = (wˆ − λ) − c0 − 13φpppλ2 + 16φpppλwˆ + (16φppp − c2)wˆ2 −
1
6c0φ
pppλ − {c1 + 13c0φppp}wˆ + {18(φapp)2 + 118(φppp)2 − 18φpppp}λ3 +
2636 H. SHIMODAIRA
{−18 (φapp)2 + 124φpppp}λ2wˆ + {− 124 (φppp)2 + 124φpppp − 16c2φppp}λwˆ2 +
{− 172 (φppp)2 + 124φpppp − 13c2φppp − c3}wˆ3, and g+(wˆ, λ) = −(daa + 16φppp)+
{(dab)2 − dabφabp + 16daaφppp + 12 (φabp)2 + 12 (φapp)2 + 1372(φppp)2 − 14φaapp −
1
8φ
pppp}wˆ+{(dab)2 − 16daaφppp + 18 (φapp)2 + 572 (φppp)2 − 124φpppp}λ. Note that
the zc-formula does not involve the coefficients bcr , and that the distribution func-
tion of Ŵ is characterized by the coefficients cr with third-order accuracy. The
index c of zc indicates the coefficients cr .
The true parameter value is assumed to be (0, λ) in the (u, v)-coordinates for
(7.4) and (7.10). If we alter the true parameter value to arbitrary (u, v) with u = 0,
the expression changes as well, and −1(Pr{Ŵ ≤ wˆ}) is denoted as zc(wˆ;u, v, τ ),
which reduces to zc(wˆ;0, λ, τ )= zc(wˆ;λ, τ ) when u = 0 and v = λ.
zc(wˆ;u, v, τ ) is used for representing the bootstrap probabilities in particular.
The simple bootstrap probability is, for example, αˆ0(y) = Pr{V̂ ∗ ≤ 0;y} =
(zc(0; uˆ, vˆ,1)) with all cr = 0. The expression of zc(wˆ∗; uˆ, vˆ, τ ) is obtained
from (7.10) by changing the origin to η(uˆ).
LEMMA 5. Let Y ∗ be a replicate of Y distributed conditionally as Y ∗ ∼
f (y∗;y, τ ) with mean y and scale τ , and Ŵ ∗ be the corresponding modified
signed distance. Let us denote the conditional distribution of Ŵ ∗ given y as
Pr{Ŵ ∗ ≤ wˆ∗;y} = (zc(wˆ∗; uˆ, vˆ, τ )). Then the expression of zc(wˆ∗; uˆ, vˆ, τ )
is obtained from (7.10) by replacing wˆ, λ, φppp and d1 = daa , respectively,
with wˆ∗, vˆ,
φˆppp ≈ φppp + {3φbpp(2dbc − φbcp) − 32φcppφppp + φcppp}uˆc and(7.11)
dˆ1 ≈ daa + {12daaφcpp − dabφabc + 3eaac}uˆc.(7.12)
Note that O(n−1) terms change only O(n−3/2). For example, d2 = (dab)2 would
be replaced with dˆ2, but dˆ2 ≈ d2.
7.5. Pivot statistic. Although the exactly unbiased p-value may not exist in
general, a third-order accurate p-value can be derived under (1.3) and (1.4). Let
Y ∗ ∼ f (y∗; ηˆ(y),1) be a replicate generated with mean ηˆ(y) instead of y, and
αˆ∞(y) be defined as the probability of the corresponding signed distance V̂ ∗ being
greater than or equal to the observed value vˆ;
αˆ∞(y) = Pr{V̂ ∗ ≥ vˆ; ηˆ(y)}.
This is the exact p-value for the normal example of Section 2 and for the
exponential example of Section 4. We will show that αˆ∞(y) is, in fact, third-order
accurate under (1.3) and (1.4).
MULTISTEP-MULTISCALE BOOTSTRAP 2637
First, zˆ∞(y) = −−1(αˆ∞(y)) is expressed by the zc-formula of Lemma 5.
From the definition, zˆ∞(y) = zc(vˆ; uˆ,0,1) with all cr = 0 and, thus,
zˆ∞(y) ≈ vˆ − (dˆ1 + 16 φˆppp)+ 16 φˆpppvˆ2
+ {(dab)2 − dabφabp + 16daaφppp(7.13)
+ 12 (φabp)2 + 12(φapp)2 + 1372 (φppp)2 − 14φaapp − 18φpppp
}
vˆ
+ {− 172(φppp)2 + 124φpppp}vˆ3.
By comparing (7.13) with (7.8), we find that zˆ∞(y) can be expressed as wˆ with
coefficients c¯0 = −daa − 16φppp, c¯1 = (dab)2 −dabφabp+ 16daaφppp+ 12(φabp)2 +
1
2 (φ
app)2 + 1372(φppp)2 − 14φaapp − 18φpppp, c¯2 = 16φppp, c¯3 = − 172 (φppp)2 +
1
24φ
pppp
, b¯c0 = −12daaφcpp + dabφabc − 3eaac and b¯c2 = 12φbpp(2dbc − φbcp) −
1
4φ
cppφppp + 16φcppp. Then the distribution function of zˆ∞(y) is obtained
immediately from Lemma 4 as shown below.
LEMMA 6. Let us consider a statistic
zˆq(y) ≈ zˆ∞(y) + q0 + q1vˆ + q2vˆ2 + q3vˆ3 + uˆcgc(vˆ),
where the coefficients are q0 = O(n−1/2), q1 = O(n−1), q2 = O(n−1/2) and
q3 = O(n−1), and gc(vˆ) = O(n−1), c = 1, . . . , p − 1, representing arbitrary
polynomials of vˆ. The index q of zq indicates the coefficients. Assuming (Û , V̂ ) ∼
f (uˆ, vˆ;λ,1), the distribution function of zˆq (y) is expressed as
Pr{zˆq(Y ) ≤ x;λ}
≈ [x − λ− q0 − 13φpppλ2 + 16φpppλx − q2x2
+ {(dab)2 + 18(φapp)2 + 772 (φppp)2 − 124φpppp − 16φpppq0}λ(7.14)
+ {−q1 − 2q2(daa + 16φppp − q0)}x + {−18 (φapp)2 + 124φpppp}λ2x
+ {13φpppq2 + 2q22 − q3}x3 + {18 (φapp)2 + 118(φppp)2 − 18φpppp}λ3
+ {− 572 (φppp)2 + 124φpppp − 16φpppq2}λx2].
For λ = 0, the distribution function is Pr{zˆq(Y ) ≤ x;0} ≈ [x − q0 − q2x2 +
{−q1 − 2q2(daa + 16φppp − q0)}x + {13φpppq2 + 2q22 − q3}x3]. In particular,
Pr{zˆ∞(Y ) ≤ x;0} ≈ (x) and, thus, zˆ∞(y) is a third-order accurate pivot statistic.
We obtain Pr{αˆ∞(Y ) < α;η} ≈ α for η ∈ ∂R, proving the third-order accuracy
of αˆ∞(y).
The reverse of the above statement also holds. αˆq(y) = (−zˆq(y)) is a third-
order accurate p-value if and only if q0 ≈ q1 ≈ q2 ≈ q3 ≈ 0. If we confine our
attention to αˆq(y) defined only from vˆ and the geometric quantities dab, eabc, φij ,
2638 H. SHIMODAIRA
φijk and φijkl evaluated at ηˆ(y), then uˆcgc(vˆ) in zˆq (y) comes only from qr ’s by the
replacements shown in Lemma 5. Thus, αˆq(y) is a third-order accurate p-value if
and only if αˆq(y) ≈ αˆ∞(y). Similarly, αˆq(y) is second-order accurate if and only
if q0
.= q2 .= 0 and, thus, αˆq(y) .= αˆ∞(y).
zˆ∞(y) is equivalent to other pivots in the literature up to O(n−1) terms. Under
(1.1) and (1.4), φijk = φijkl = 0 and, thus, (7.13) reduces to zˆ∞(y) ≈ vˆ− dˆ1 + dˆ2vˆ,
giving (3.8), the pivot of of Efron (1985). Under (1.3), the modified signed
likelihood ratio [Barndorff-Nielsen (1986) and Barndorff-Nielsen and Cox (1994)]
has been known as a third-order accurate pivot, and it is expressed as R∗ = R +
(1/R) log(U/R) in the notation of Severini [(2000), page 251], where U is defined
using the log-likelihood derivatives. A straightforward calculation shows that
U ≈ vˆ− dˆ1vˆ2 +{12 (daa)2 +dabdab − 14φaapp −dabφabp + 12 (φabp)2 + 12(φapp)2 +
1
8 (φ
ppp)2 − 112φpppp}vˆ3, and that R∗ ≈ zˆ∞(y) in the moderate deviation region.
7.6. Accuracy of the bootstrap probability. Since the event Y ∗ ∈ R is
equivalent to the event V̂ ∗ ≤ 0, the z-value of the bootstrap probability with scale
τ is expressed by the zc-formula of Lemma 5; z˜1(y, τ ) = −zc(0; uˆ, vˆ, τ ) with all
cr = 0. From (7.10), we obtain a refined version of (4.8), erring only O(n−3/2),
z˜1(y, τ ) ≈ τ−1[vˆ + 13 φˆpppvˆ2 − {18(φapp)2 + 118(φppp)2 − 18φpppp}vˆ3]
+ τ [(dˆ1 + 16 φˆppp)(7.15)
− {(dab)2 − 16daaφppp + 18 (φapp)2 + 572(φppp)2 − 124φpppp}vˆ].
It follows from (7.15) that τ z˜1(y, τ ) is expressed as wˆ and, thus, τ z˜1(y, τ ) ≈
zˆq (y) by choosing the coefficients appropriately. They are c0 = (daa + 16φppp)τ 2,
c1 = (−(dab)2 − 12daaφppp − 18(φapp)2 − 1372(φppp)2 + 124φpppp)τ 2, c2 = 13φppp,
and c3 = −18 (φapp)2 − 518(φppp)2 + 18φpppp for wˆ, or, equivalently, q0 = (1 +
τ 2)(daa + 16φppp), q1 = −(1+τ 2)(dab)2 +dabφabp + 14φaapp− 12 (φabp)2 − 18 (4+
τ 2)(φapp)2 + 16(−1 + τ 2)daaφppp − 172 (13 + 5τ 2)(φppp)2 + 124(3 + τ 2)φpppp,
q2 = 16φppp, q3 = −18 (φapp)2 − 124 (φppp)2 + 112φpppp for zˆq(y). The distribution
function of τ z˜(y, τ ) is obtained from (7.10) or (7.14). In particular, the distribution
function of zˆ0(y) = z˜1(y,1) under λ = 0, τ = 1 is
Pr{zˆ0(Y ) ≤ x;0}
≈ [x − (2daa + 13φppp)− 16φpppx2
+ {2(dab)2 − dabφabp + 13daaφppp + 12 (φabp)2(7.16)
+ 58(φapp)2 + 1136(φppp)2 − 14φaapp − 16φpppp
}
x
+ {1172 (φppp)2 + 18(φapp)2 − 112φpppp}x3],
showing the first-order accuracy of αˆ0(y).
MULTISTEP-MULTISCALE BOOTSTRAP 2639
Remark A of Efron and Tibshirani (1998) discusses a calibrated bootstrap
probability, denoted αˆdouble(y) here, using the double bootstrap of Hall (1992).
Similarly to the two-level bootstrap, thousands of Y ∗ are generated around
ηˆ(y). Then αˆ0(y∗) is computed for each y∗. The expression of zˆdouble(y) =
−1[Pr{zˆ0(Y ∗) ≤ zˆ0(y); ηˆ(y)}] is obtained from (7.16) by the replacements of
Lemma 5, and a straightforward calculation shows that zˆdouble(y) ≈ zˆ∞(y),
proving the third-order accuracy of αˆdouble(y).
7.7. Accuracy of the two-level bootstrap. The expression of zˆ0(y) is obtained
from (7.15) by letting τ = 1, and zˆ0(ηˆ(y)) ≈ dˆ1 + 16 φˆppp is obtained from it
by letting vˆ = 0. By substituting these expressions, as well as aˆ = −16 φˆppp for
those in (2.3), we find that zˆabc(y) is expressed as wˆ, or, equivalently, zˆq (y)
with coefficients q0 = q2 = 0, q1 = −2(dab)2 + 14φaapp + dabφabp − 12 (φabp)2 −
5
8 (φ
app)2 − 14(φppp)2 + 16φpppp and q3 = −18 (φapp)2 − 18(φppp)2 + 112φpppp. The
distribution function is then obtained from Lemma 6. For λ = 0, it becomes
Pr{zˆabc(Y ) ≤ x;0} ≈ (x − q1x − q3x3),(7.17)
showing the second-order accuracy of αˆabc(y).
For the exponential example of Section 4, p = 1, φ111 = −2/√n, φ1111 = 6/n
and all the other quantities in q1 and q3 are zero. Therefore, q1 = q3 = 0, and
zˆabc(y) turns out to be third-order accurate, explaining the high accuracy of αˆabc(y)
observed in Table 2.
7.8. Accuracy of the multistep-multiscale bootstrap. Using the expressions
(7.4) and (7.15), the expression of z˜2(y, τ1, τ2) is obtained by the integration
z˜2(y, τ1, τ2) = −1
{∫

(
z˜1(y
∗, τ2)
)
f (y∗;y, τ1) dy∗
}
.(7.18)
By repeating the same integration using z˜2(y∗, τ2, τ3) instead of z˜1(y∗, τ2), we
obtain the expression of z˜3(y, τ1, τ2, τ3) as given below.
LEMMA 7. Let us define the following six geometric quantities using the deriv-
atives evaluated at η = 0: γ1 = λ + 13λ2φppp + λ3{−18 (φapp)2 − 118 (φppp)2 +
1
8φ
pppp}, γ2 = λ{−daa − 16φppp} + λ2{(dab)2 − 12daaφppp + 18(φapp)2 +
1
72(φ
ppp)2 − 124φpppp}, γ3 = −16λφppp + λ2{14(φapp)2 + 19 (φppp)2 − 18φpppp},
γ4 = λ2{−dabφabp + 13daaφppp + 12 (φabp)2 + 12 (φapp)2 + 29 (φppp)2 − 14φaapp −
1
6φ
pppp}, γ5 = λ2{−18 (φapp)2 − 18 (φppp)2 + 112φpppp} and γ6 = λ2{−18(φapp)2 −
1
8 (φ
ppp)2 + 124φpppp}. Those evaluated at ηˆ(y), denoted γˆ1, . . . , γˆ6, are obtained
by replacing λ, φppp and daa , respectively, with vˆ, (7.11) and (7.12) as shown in
Lemma 5. Then we have
z˜3(y, τ1, τ2, τ3) ≈ ζ3(γˆ1, γˆ2, γˆ3, γˆ4, γˆ5, γˆ6, τ1, τ2, τ3)(7.19)
2640 H. SHIMODAIRA
using the ζ3-function of (5.5). Since (7.19) errs only O(n−3/2) for any values of
(τ1, τ2, τ3), the nonlinear regression for three-step multiscale bootstrap probabili-
ties in Section 5 estimates γˆi’s up to O(n−1) terms.
If we define zˆ3(y) of (5.6) using the γˆi’s defined above, we can easily verify
zˆ3(y) ≈ zˆ∞(y)(7.20)
by comparing (5.6) with (7.13). This proves the third-order accuracy of αˆ3(y)
under (1.3) and (1.4).
For the multivariate normal model of (1.1), φ(η) = ‖η‖2/2 and, thus, φijk =
φijkl = 0. This implies γ3 = · · · = γ6 = 0, proving the third-order accuracy of
αˆ1(y) and αˆ2(y) under (1.1) and (1.4).
Acknowledgments. I wish to thank the referees and the Associate Editor who
handled this article for their very helpful constructive suggestions. The earlier
version of the manuscript was prepared during my stay at Stanford University
arranged by Brad Efron.
REFERENCES
BARNDORFF-NIELSEN, O. E. (1986). Inference on full or partial parameters based on the
standardized signed log likelihood ratio. Biometrika 73 307–322.
BARNDORFF-NIELSEN, O. E. and COX, D. R. (1994). Inference and Asymptotics. Chapman and
Hall, London.
DICICCIO, T. and EFRON, B. (1992). More accurate confidence intervals in exponential families.
Biometrika 79 231–245.
DRAPER, N. R. and SMITH, H. (1998). Applied Regression Analysis, 3rd ed. Wiley, New York.
EFRON, B. (1985). Bootstrap confidence intervals for a class of parametric problems. Biometrika 72
45–58.
EFRON, B. (1987). Better bootstrap confidence intervals (with discussion). J. Amer. Statist. Assoc.
82 171–200.
EFRON, B., HALLORAN, E. and HOLMES, S. (1996). Bootstrap confidence levels for phylogenetic
trees. Proc. Natl. Acad. Sci. U.S.A. 93 13429–13434.
EFRON, B. and TIBSHIRANI, R. (1998). The problem of regions. Ann. Statist. 26 1687–1718.
FELSENSTEIN, J. (1985). Confidence limits on phylogenies: An approach using the bootstrap.
Evolution 39 783–791.
HALL, P. (1992). The Bootstrap and Edgeworth Expansion. Springer, New York.
KAMIMURA, T., SHIMODAIRA, H., IMOTO, S., KIM, S., TASHIRO, K., KUHARA, S. and
MIYANO, S. (2003). Multiscale bootstrap analysis of gene networks based on Bayesian
networks and nonparametric regression. In Genome Informatics 2003 (M. Gribskov,
M. Kanehisa, S. Miyano and T. Takagi, eds.) 350–351. Universal Academy Press, Tokyo.
KURIKI, S. and TAKEMURA, A. (2000). Shrinkage estimation towards a closed convex set with a
smooth boundary. J. Multivariate Anal. 75 79–111.
LIU, R. Y. and SINGH, K. (1997). Notions of limiting P values based on data depth and bootstrap.
J. Amer. Statist. Assoc. 92 266–277.
MCCULLAGH, P. (1984). Local sufficiency. Biometrika 71 233–244.
PERLMAN, M. D. and WU, L. (1999). The emperor’s new tests (with discussion). Statist. Sci. 14
355–381.
MULTISTEP-MULTISCALE BOOTSTRAP 2641
PERLMAN, M. D. and WU, L. (2003). On the validity of the likelihood ratio and maximum
likelihood methods. J. Statist. Plann. Inference 117 59–81.
SEVERINI, T. A. (2000). Likelihood Methods in Statistics. Oxford Univ. Press.
SHIMODAIRA, H. (2002). An approximately unbiased test of phylogenetic tree selection. Systematic
Biology 51 492–508.
SHIMODAIRA, H. (2004). Technical details of the multistep-multiscale bootstrap resampling.
Research Report B-403, Dept. Mathematical and Computing Sciences, Tokyo Institute
of Technology, Tokyo.
SHIMODAIRA, H. and HASEGAWA, M. (2001). CONSEL: For assessing the confidence of
phylogenetic tree selection. Bioinformatics 17 1246–1247.
WEYL, H. (1939). On the volume of tubes. Amer. J. Math. 61 461–472.
DEPARTMENT OF MATHEMATICAL
AND COMPUTING SCIENCES
TOKYO INSTITUTE OF TECHNOLOGY
2-12-1 OOKAYAMA, MEGURO-KU
TOKYO 152-8552
JAPAN
E-MAIL: shimo@is.titech.ac.jp
URC: www.is.titech.ac.jp/˜shimo/
