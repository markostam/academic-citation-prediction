Anders, Ende, Unghofer, Kissler & Wildgruber (Eds.)
Progress in Brain Research, Vol. 156
ISSN 0079-6123
Copyright r 2006 Elsevier B.V. All rights reserved
CHAPTER 21
Towards a unifying neural theory of social cognition
Christian Keysers and Valeria GazzolaQA :1
BCN Neuro-Imaging-Centre, University Medical Center Groningen, University of Groningen, A. Deusinglaan 2, 9713AW
Groningen, The Netherlands
Abstract: Humans can effortlessly understand a lot of what is going on in other peoples’ minds. Under-
standing the neural basis of this capacity has proven quite difﬁcult. Since the discovery of mirror neurons, a
number of successful experiments have approached the question of how we understand the actions of others
from the perspective of sharing their actions. Recently we have demonstrated that a similar logic may apply
to understanding the emotions and sensations of others. Here, we therefore review evidence that a single
mechanism (shared circuits) applies to actions, sensations and emotions: witnessing the actions, sensations
and emotions of other individuals activates brain areas normally involved in performing the same actions
and feeling the same sensations and emotions. We propose that these circuits, shared between the ﬁrst (I do,
I feel) and third person perspective (seeing her do, seeing her feel) translate the vision and sound of what
other people do and feel into the language of the observers own actions and feelings. This translation could
help understand the actions and feelings of others by providing intuitive insights into their inner life. We
propose a mechanism for the development of shared circuits on the basis of Hebbian learning, and un-
derline that shared circuits could integrate with more cognitive functions during social cognitions.
Keywords: mirror system; social cognition; emotions; actions; sensations; empathy; theory of mind
Humans are exquisitely social animals. The pro-
gress of our species and technology is based on our
capacity for social learning. Social learning and
skilled social interactions rest upon our capacity to
gain insights into the mind of others. Not surpris-
ingly, humans are indeed excellent at understand-
ing the inner life of others. This is exempliﬁed in
our inner experience of watching a Hollywood
feature ﬁlm: we relax while effortlessly attributing
a vast range of emotions and motivations to the
main character simply by witnessing the actions of
the character, and the events that occur to him.
Not only do we feel that we need very little explicit
thoughts to understand the actors, we actually
share their emotions and motivations: our hands
sweat and our heart beats faster while we see ac-
tors slip off the roof, we shiver if we see an actor
cut himself, we grimace in disgust as the character
has to eat disgusting food. This sharing experience
begs two related questions: How do we manage to
slip into the skin of other people so effortlessly?
Why do we share the experiences we observe in-
stead of simply understanding them?
The goal of this chapter will be to propose that a
single principle — shared circuits — could provide
a unifying perspective on both of these questions.
To foreshadow the main message of our proposal,
we claim that a circuit composed of the temporal
lobe (area STS (superior temporal sulcus) in mon-
keys or MTG (middle temporal gyrus) in humans),
the rostral inferior parietal lobule (PF/IPL) and
the ventral premotor cortex (F5/BA44+6) is in-
volved both in our own actions and those of oth-
ers, thereby forming a shared circuit for
performing and observing actions. We will show
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
3B2v8:06a=w ðDec 5 2003Þ:51c
XML:ver:5:0:1 PBR V156 : 56021
Prod:Type:
pp:3832406ðcol:fig::NILÞ
ED:
PAGN: SCAN:
Corresponding author. Fax: +31-503638875; E-mail: c.keys-
ers@med.umcg.nl
DOI: 10.1016/S0079-6123(06)56021-2 383
that the somatosensory cortices are involved both
in experiencing touch on our own body and in
viewing other human beings or objects being
touched; that the anterior cingulate and insular
cortices are involved in the experience of pain, and
the perception of other people’s pain; and ﬁnally
that the anterior insula is also involved both in the
experience of disgust and in the observation of
disgust in others (for the case of actions, this
model is similar to those put forward by other
authors: Gallese et al. (2004), Rizzolatti and Craig-
hero (2004) and Hurley S.L. [http://www.war-
wick.ac.uk/staff/S.L.Hurley]).
Common to all these cases is that some of the
brain areas involved in the ﬁrst person perspective
(I do or I feel) are also involved in the third person
perspective (she does or she feels). We will argue
that this sharing transforms what we see other
people do or feel into something very well known
to us: what we do and feel ourselves. By doing so it
provides an intuitive grasp of the inner life of oth-
ers.
We will review separately key evidence for
shared circuits for actions, sensations and emo-
tions. We will then show that these systems appear
to generalize beyond the animate world. We will
conclude by suggesting how Hebbian learning
could account for the emergence of these shared
circuits.
Shared circuits for actions
The ﬁrst evidence that certain brain areas might be
involved both in the processing of ﬁrst and third
person perspectives comes from the study of ac-
tions in monkeys. Understanding the actions of
others is a pragmatic need of social life. Surpris-
ingly, some areas involved in the monkey’s own
actions are activated by the sight of someone else’s
actions (Dipellegrino et al., 1992; Gallese et al.,
1996). Today, we start to understand more about
the circuitry that might be responsible for the
emergence of this phenomenon (Keysers and Per-
rett, in press). Imaging studies suggest that a sim-
ilar system exists in humans (see Rizzolatti and
Craighero, 2004 for a review).
Primates
Three brain areas have been shown to contain
neurons that are selectively activated by the sight
of the actions of other individuals: the STS (Bruce
et al., 1981; Perrett et al., 1985, 1989; Oram and
Perrett, 1994, 1996), the anterior inferior parietal
lobule (an area sometimes called 7b and sometimes
PF, but the two names refer to the same area, and
we will use PF in this manuscript; Gallese et al.,
2002) and the ventral premotor cortex (area F5;
Dipellegrino et al., 1992; Gallese et al., 1996; Ri-
zzolatti et al., 1996; Keysers et al., 2003) (Fig. 1).
These three brain areas are anatomically intercon-
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
F5
a
c
s
ip
STS
PF F5BA6/BA44
IPL
MT
G
Fig. 1. (a) Lateral view of the macaque brain with the location of F5, PF and STS together with their anatomical connections (arrows).
The following sulci are shown: a ¼ arcuate, c ¼ central, ip ¼ intraparietal, s ¼ sylvian sulcus. (b) Corresponding view of the human
brain.
384
nected: STS has reciprocal connections with PF
(Seltzer and Pandya, 1978; Selemon and Gold-
manrakic, 1988; Harries and Perrett, 1991; Seltzer
and Pandya, 1994; Rizzolatti and Matelli 2003)
and PF is reciprocally connected with F5 (Matelli
et al., 1986; Luppino et al., 1999; Rizzolatti and
Luppino, 2001; Tanne-Gariepy et al., 2002), while
there are no direct connections between F5 and the
STS (see Keysers and Perrett, in press, for a recent
review). All three areas contain neurons that ap-
pear to selectively respond to the sight of hand–ob-
ject interactions, with particular neurons
responding to the sight of particular actions, such
as grasping, tearing or manipulating (Perrett et al.,
1989; Dipellegrino et al., 1992; Gallese et al., 1996,
2002; Keysers et al., 2003). There is however a
fundamental difference among the three areas.
Virtually all neurons in F5 that respond when the
monkey observes another individual perform a
particular action also respond when the monkey
performs the same action whether he is able to see
his own actions or not (Gallese et al., 1996). These
neurons called mirror neurons therefore constitute
a link between what the monkey sees other people
do and what the monkey does himself. A substan-
tial number of neurons in PF shows a similar be-
haviour (Gallese et al., 2002). While in F5 and PF,
motor information has an excitatory effect on ac-
tivity, the situation in the STS is quite different.
None of the neurons in the STS responding to the
sight of a particular action have been shown to
robustly respond when the monkey performs the
same action with his eyes closed (Keysers and
Perrett, in press). While some neurons in the STS
respond similarly when the monkey sees himself
perform an action and when it sees someone else
perform the same action (Perrett et al., 1989,
1990), many actually cease to respond to the sight
of their preferred movement if the monkey himself
is causing this movement (Hietanen and Perrett,
1993). For these latter neurons, the motor/prop-
rioceptive signal therefore assumes an inhibitory
function, in contrast to the excitatory function
observed in F5 and PF. As a result, half of the cells
in the STS appear to treat self and other in similar
ways, the other half of the STS sharply distin-
guishes other- from self-caused actions.
Considering the STS-PF-F5 circuit as a whole,
we therefore have a system that responds to the
actions of others. Two of its components (PF and
F5) link the actions of others to our own motor
programs, and may therefore give us an intuitive
insight into the actions of others because they
transform the sight of these actions into something
very well known to ourselves: our own actions
(Gallese et al., 2004; Keysers and Perrett, in press).
An essential property of mirror neurons is their
congruent selectivity, namely, the fact that if they
respond more to a particular action (e.g. precision
grip) during execution, they also respond more to
that same action during observation, compared to
other actions (Gallese et al., 1996). Importantly,
not all mirror neurons show the same selectivity:
some are very precisely tuned for a particular ac-
tion (e.g. they respond strongly to a precision grip,
but not to a whole-hand prehension), while others
are much more broadly tuned (responding to all
kinds of grasps, but not to other actions not re-
lated to grasping). This combination of precisely
and broadly tuned neurons is very important: the
precisely tuned neurons can give very detailed in-
sights into the actions of others, but require that
these actions are within the motor vocabulary of
the observing monkey. The more broadly tuned
neurons on the other hand will also respond to the
sight of novel actions that are not within the motor
vocabulary of the monkey, but resemble actions
that are within the monkey’s vocabulary. Exam-
ples of the latter are the neurons responding to
tool use, which have now been found in F5 (Fe-
rrari et al., 2005): the monkeys used in this exper-
iment have never used tools (e.g. a pincer) and yet
the sight of someone using a tool activated some
F5 neurons that responded when the monkey per-
formed similar but different actions (grasping with
its hands).
The STS-PF-F5 circuit also responds in cases
where we recognize the actions of others but are
unable to fully see these actions. In the STS, some
neurons respond strongly to the invisible presence
of a human hiding behind an occluding screen in a
particular location. The same human hiding in a
different location often caused no response (Baker
et al., 2001; Fig. 2a). Although this capacity has
been demonstrated for hidden humans, similar re-
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
385
sponses may exist for hidden objects. In F5, about
half of the mirror neurons responding when the
monkey himself grasps an object also respond to
the sight of a human reaching behind an occluder
but only when the monkey previously saw an ob-
ject being placed behind the occluder (Umilta et
al., 2001; Fig. 2b). This observation begs the ques-
tion of where the information necessary for this
type of F5 responses originates. As shown above,
the STS could provide a representation of the
reaching and a representation of the hidden object.
The STS-PF-F5 circuit may then extrapolate from
these two pieces of information towards a com-
plete representation of the action, causing F5
grasping neurons to ﬁre. The circuit is particularly
well suited for such extrapolations because it is an
inherent function of the premotor cortex to code
movement sequences unfolding in time. The same
hardware could be used to extrapolate the visible
beginning of a grasping into the full action. Many
important actions around us are not fully visible: a
leopard may be approaching a monkey, intermit-
tently disappearing behind trees. In such cases,
understanding the leopards action, although it is
not fully visible, will make the difference between
life and death for the observing monkey.
Both STS and F5 also contain neurons that re-
spond to the sound of actions. Neurons were
found in the STS that respond to the sound and/or
the vision of walking, with much smaller responses
to other actions such as clapping hands (Fig. 3a).
Similar neurons have been found in F5, but re-
sponding to seeing and/or hearing a peanut being
broken (Fig. 3b; Kohler et al. 2002; Keysers et al.,
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
5spks/s
1s
5spk/s
1s
(a) STS (b) F5
Fig. 2. (a) Response of a neuron in STS while the monkey observes a human walk towards, hide behind and then reappear from an
occluding screen. The top and bottom histograms show its activity when hiding behind the left and centre occluder, respectively (see
cartoon on the left). The different experimental phases are shown on top, and coded as a white background when the subject is fully
visible, light grey when partially and dark grey when fully occluded by the screen. The discharge is stronger in the top compared to the
bottom occluded phase although in both cases, there were only three occluders to be seen without any visible individual (Baker et al.,
2001). (b) An F5 neuron while a human demonstrator grasps behind an occluding screen. In the top but not the bottom case, the
monkey previously saw an object being placed on a tray before the occluder was sled in front of the tray. The discharge starting as the
hand begins to be occluded (light and dark grey background) is much stronger in the top case, yet at that moment both visual stimuli
(top and bottom) are equal (Umilta et al., 2001). The scales are different in (a) and (b).
386
2003). The latter neurons in F5 also respond when
the monkey breaks a rubber peanut out of sight
(i.e. without sound or vision of his own action). It
therefore appears as though the entire STS-PF-F5
circuit is multimodal: some of its neurons respond
in similar ways to an action independently of
whether it is seen or heard. Given its connections
to both the auditory and visual cortices, STS ap-
pears to be a likely site for this audiovisual inte-
gration (see Ethofer and Wildgruber, this volume).
In the F5-PF-STS circuit, this audiovisual action
representation then appears to be integrated with
the motor program of the matching action. With
such a multimodal system, the mere sound of
someone knocking on the door would activate a
multimodal, audio-visuo motor representation of
the action, leading to a deep understanding and
sharing of the heard action. Indeed, mirror neu-
rons with audiovisual properties are able to dis-
criminate which of two actions was performed by
an actor with 490% accuracy based either on the
sound or the vision of the action alone (Keysers et
al., 2003).
Humans
A mirror system similar to that found in the mon-
key has now been described in humans. Regarding
the observation of actions, a number of imaging
studies, including fMRI, PET and MEG experi-
ments, have reported the three following areas be-
ing particularly involved in the observation of
actions: the caudal inferior frontal gyrus and ad-
jacent premotor cortex (Broadman areas [BAs] 44
and 6) corresponding to the monkey’s area F5, the
rostral inferior parietal lobule (IPL) corresponding
to the monkey’s area PF, and caudal sectors of the
temporal lobe, in particular the posterior superior
temporal sulcus (pSTS) and the adjacent MTG
corresponding to the monkey’s STS (see Fig. 1;
Grafton et al., 1996; Rizzolatti et al., 1996; Decety
et al., 1997; Grezes et al., 1998; Iacoboni et al.,
1999; Nishitani and Hari, 2000; Buccino et al.,
2001; Grezes et al., 2001; Iacoboni et al., 2001;
Perani et al., 2001; Decety et al., 2002; Nishitani
and Hari, 2002; Grezes et al., 2003; Manthey et al.,
2003; Buccino et al., 2004b; Wheaton et al. 2004).
Two of these three areas, the IPL and BA44/6 are
known to play an important role in motor control.
A smaller number of studies have also measured
brain activity during the execution of actions in the
same individuals in order to check if certain parts
of the brain are involved both during motor ex-
ecution and the observation of similar actions
(Grafton et al., 1996; Iacoboni et al., 1999;
Buccino et al., 2004b). These studies found sec-
tors of the IPL and BA44/6 to be involved both in
the observation and execution of actions, repre-
senting a human equivalent of the monkey’s mir-
ror neurons found in PF and F5.
The situation in the pSTS/MTG is less clear:
Iacoboni et al. (2001) ﬁnd the STS to be active
both during motor execution and observation,
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
V+S
S
1st footstep crack of peanut
1s
a b
STS F5
Fig. 3. (a) response of an STS neuron while the monkey heard
(S ¼ sound), saw (V ¼ vision) or saw and heard (V+S) an ex-
perimenter walk. Note the strong response in all three cases. (b)
response of an F5 neuron in the same three conditions but for
the action of breaking a peanut. This neuron also responded
while the monkey broke a rubber peanut out of sight. The
curves at the bottom are sonographs (ﬁgure adapted from
Keysers and Perrett, in press).
387
while Grafton et al. (1996) and Buccino et al.
(2004b) fail to ﬁnd robust STS activation during
motor execution. Two explanations have been
offered for this STS/MTG activation during the
execution of actions. The ﬁrst holds thatQA :2 a refer-
ence copy of executed actions is sent to congruent
visual neurons in the STS/MTG to create a for-
ward model of what the action should look like
(Iacoboni et al., 2001). The second, based on the
fact that in monkeys the execution of actions re-
duces the spiking activity of STS neurons, holds
that a reference copy is sent in order to cancel the
visual consequences of our own actions (Keysers
and Perrett, in press). Why, though, should a re-
duction in spiking show up as an increase in blood
oxygen level dependent (BOLD) signal? Logo-
thetis (2003) has suggested that the BOLD effect is
dominated by synaptic activity, not spiking activ-
ity; the metabolic demands of inhibitory synaptic
input could thus outweigh a reduction of spiking
activity and thus be measured as an overall in-
crease in BOLD signal (but see Waldvogel et al.,
2000). Either way, the STS/MTG is an important
element of the ‘mirror circuitry’ involved both in
the observation and execution of actions (Keysers
and Perrett, in press).
A key property of the mirror system in monkeys
is its congruent selectivity: mirror neurons re-
sponding for instance to a precision grip more
than to a whole-hand prehension during motor
execution also respond more to the observation of
a precision grip compared to a whole-hand pre-
hension (Gallese et al., 1996). Can the same be
demonstrated for the human mirror system? A
promising alley for providing proof of such selec-
tivity stems from studies looking at somatotopy in
the premotor activations. Buccino et al. (2001) and
Wheaton et al. (2004) showed participants’ foot,
hand and mouth actions, and observed that these
actions activated partially distinct cortical sites.
They interpret these activations as reﬂecting the
mapping of the observation of hand actions onto
the execution of hand actions, and so on for foot
and mouth. Unfortunately, neither of these studies
contained motor execution tasks, and both there-
fore fail to establish the congruence of the so-
matotopical organization during observation and
execution. Leslie et al. (2004) asked participants to
imitate facial and manual actions, and observed
the existence of patches of premotor cortex in-
volved in either manual or facial imitation. Un-
fortunately, they did not separate the vision of
faces/hands from the motor execution, and there-
fore congruent somatotopy cannot be proven by
their study either. It is noteworthy, that during
motor execution in other studies (e.g. Rijntjes et
al., 1999; Hauk et al., 2004), a somatotopy for ac-
tion execution was observed, which apparently re-
sembled the visual one found in the above-cited
studies.
Corroborating evidence for the existence of se-
lective mirror neurons in humans stems from a
number of transcranial magnetic stimulation
(TMS) studies (Fadiga et al., 1995; Gangitano et
al., 2001; see Fadiga et al., 2005 for a review),
which suggests that observing particular hand/arm
movements selectively facilitates the motor execu-
tion of the speciﬁc muscles involved in the obser-
vation.
Evidence that BA44 is essential for recognizing
the actions of others comes from studies that show
that patients with premotor lesions show deﬁcits in
pantomime recognition that cannot be accounted
for by verbal problems alone (Bell, 1994; Halsband
et al., 2001). Also, repetitive TMS induced virtual
lesions of BA44 impair the capacity to imitate ac-
tions, even though they do not impair the capacity
to perform the same actions when cued through
spatial stimuli instead of a demonstrator’s actions
(Heiser et al., 2003).
The mirror system in monkeys was shown to
also respond to the sound of actions (Kohler et al.,
2002; Keysers et al., 2003). In a recent study, we
could demonstrate that a similar system also exists
in humans (Gazzola et al., 2005). In this study, the
same participants were scanned during execution
of hand and mouth actions and when they listened
to the sound of similar actions. The entire circuit
composed of MTG-IPL-BA44/6 responded both
during the execution and the sound of hand and
mouth actions. Most importantly, the voxels in the
premotor cortex that responded more during the
sound of hand actions compared to mouth actions
also responded more during the execution of hand
actions compared to mouth actions, and vice versa
for the mouth actions, demonstrating for the ﬁrst
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
388
time a somatotopical organization of the mirror
system in humans, albeit for sounds.
If the observation of other individuals’ actions
are mapped onto our own motor programs, one
may wonder how the perception of actions change
when we acquire new skills. Seung et al. (2005) and
Bangert et al. (2005) show that pianists demon-
strate stronger activations of BA6/44, IPL and
MTG while listening to piano pieces compared
with nonpianists, suggesting that the acquisition of
the novel motor skill of piano playing enhanced
also the auditory mirror representation of these
actions while listening — an observation that
might relate to the fact that pianists often ﬁnd it
harder to keep their ﬁngers still while listening to
piano pieces. Calvo-Merino et al. (2005) showed
male and female dancers’ dance movements that
were speciﬁc for one of the genders. They found
that female dancers activated their premotor cor-
tex more to female dance moves, and male dancers
more to male dance moves. This ﬁnding is partic-
ularly important, as both male and female dancers
rehearse together and have therefore similar de-
grees of visual expertise with both types of move-
ments, but have motor expertise only of their own
gender-speciﬁc movements. The premotor differ-
ences observed therefore truly relate to motor ex-
pertise. It is interesting, that although in both
examples, responses were stronger for experts
compared to nonexperts, mirror activity was not
absent in people devoid of ﬁrsthand motor exper-
tise of the precise actions they were witnessing.
These weaker activations thus probably reﬂect the
activity of more broadly tuned mirror neurons
(Gallese et al., 1996) that may discharge maximally
to other, similar actions (e.g. walking, jumping),
but also respond slightly to these different actions
(e.g. a speciﬁc dance move involving steps and
jumps). With these more widely tuned neurons, we
can gain insights into actions that are novel to us,
by drawing on analogies with similar actions al-
ready within our motor vocabulary.
Conclusions
Both monkeys and humans appear to activate a
circuit composed of temporal, parietal and frontal
neurons while observing the actions of others. The
frontal and parietal nodes of this circuit are active
both when the subjects perform an action and
when they perceive someone else perform a similar
action. These nodes are therefore shared between
the observation and execution of actions, and will
be termed ‘shared-circuits for actions’. The impli-
cations of having shared circuits for actions are
widespread. By transforming the sight of some-
one’s actions into our motor representation of
these actions, we achieve a very simple and yet
very powerful understanding of the actions of oth-
ers (Gallese et al., 1996; Keysers, 2003; Gallese et
al., 2004). In addition to providing insights into
the actions of others, activating motor programs
similar to the ones we have observed/heard is of
obvious utility for imitating the actions of others,
and shared circuits for actions have indeed been
reported to be particularly active during the imi-
tation of actions (Iacoboni et al., 1999; Buccino et
al., 2004b). Finally, as will be discussed below in
more detail, by associating the execution and the
sound of actions, mirror neurons might be essen-
tial for the acquisition of spoken language (Kohler
et al., 2002; Keysers et al., 2003).
Sensations
Observation and experience of touch
If shared circuits may be essential to our under-
standing of the actions of others, how about the
sensations of others? If we see a spider crawling on
James Bond’s chest in the movie Dr. No, we lit-
erally shiver, as if the spider crawled on our own
skin. What brain mechanisms might be responsible
for this automatic sharing of the sensations of
others? May shared circuits exist for the sensation
of touch?
To investigate this possibility, we showed sub-
jects movies of other subjects being touched on
their legs. In control movies, the same legs were
approached by an object, but never touched. In
separate runs ﬁnally, we touched the legs of the
participant. We found that touching the subjects’
own legs activated the primary and secondary so-
matosensory cortex of the subjects. Most interest-
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
389
ingly, we found that large extents of the secondary
somatosensory cortex also respond to the sight of
someone else’s legs being touched. The control
movies produced much smaller activations (Fig. 4;
Keysers et al., 2004a,b).QA :3
Intrigued by the observation of a patient C, who
reported that when she sees someone else being
touched on the face she literally feels the touch on
her own skin (Blakemore et al., 2005), we scanned
both C and a group of normal controls while
touching them on their faces and necks. In a fol-
lowing session they showed video clips of someone
else being touched on the same locations. As in our
study, the experience of touch activated primary
and secondary somatosensory cortices. During
observation, they found SI and SII activation. In
C, these activations were signiﬁcantly stronger,
potentially explaining why she literally felt the
touch that happened to others.
It therefore appears as seeing someone else be-
ing touched activated a somatosensory represen-
tation of touch in the observers, as if they had been
touched themselves. This ﬁnding is particularly
important as it demonstrates that the concept of
shared circuits put forward for actions appears to
be applicable to a very different system: that of
touch.
From touch to pain
Painful stimulation of the skin and the observation
of a similar stimulation applied to others also ap-
pear to share a common circuitry including the
anterior cingulate cortex (ACC) and the anterior
insula. First, a neuron was recorded in the ACC
responding both to pinpricking off the patients
hand and to the sight of the surgeon pinpricking
himself (Hutchison et al., 1999). Later, this anec-
dotic ﬁnding was corroborated by an elegant
fMRI investigation, where on some trials the par-
ticipant received a small electroshock on her hand;
on other trials she saw a signal on a screen signi-
fying that her partner was receiving a similar elec-
troshock. Some voxels in the ACC and the
anterior insula were activated in both cases (Singer
et al., 2004), and the amount of that activation
correlated with how empathic the subjects were
according to two paper-and-pencil empathy scales
that measure speciﬁcally how much an observer
shares the emotional distress of others. The pres-
ence of activations in the anterior cingulate and
anterior insula during the observation of pain oc-
curring to others was corroborated by Jackson et
al. (2005). In a TMS study, Avenanti et al. (2005)
observed that observing someone else being pin-
pricked on his hand selectively facilitated TMS
induced movements of the hand, suggesting that
the sharing of pain inﬂuences the motor behaviour
of the observer. This observation supports the ex-
istence of cross-talks between different shared cir-
cuits.
Emotions
The insula and disgust
Do shared circuits exist also for emotions? A series
of elegant imaging studies by Phillips and collab-
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
Fig. 4. Brain activity when a human is touched on his leg in the
scanner (red), and when he sees another individual being
touched on his leg (blue). The white voxels represent voxels
active in both cases. (Adapted from Keysers et al., 2004). The
right hemisphere is shown on the right of the ﬁgure (neurolog-
ical conventions)
390
orators (Phillips et al., 1997, 1998) suggested that
the anterior insula is implicated in the perception
of the disgusted facial expressions of others. The
same area has been implicated in the experience of
disgust (Small et al., 2003). In addition, both Cal-
der et al. (2000) and Adolphs et al. (2003) reported
patients with insular lesions that lost both the ca-
pacity to experience disgust and to recognize dis-
gust in the faces of others. It therefore appears as
though the insula may provide a shared circuit for
the experience and the perception of disgust.
Using fMRI we measured brain activity while
subjects viewed short movie clips of actors snifﬁng
the content of a glass and reacting with a pleased,
neutral or disgusted facial expression. Thereafter,
we exposed the subjects to pleasant or disgusting
odorants through an anaesthesia mask. The latter
manipulation induced the experience of disgust in
the subjects. We found that the anterior insula
were activated both by the experience of disgust
and the observation of the disgusted facial expres-
sions of others (Wicker et al., 2003) (Fig. 5, yellow
circles). These voxels were not signiﬁcantly acti-
vated by the pleasant odorants or the vision of the
pleased facial expressions of others. We then su-
perimposed the location of the voxels involved in
the experience of disgust and in the observation of
disgust onto an MRI image of a patient with in-
sular damage reporting a reduced experience of
disgust and a deﬁcient capacity to recognize dis-
gust in others (Fig. 5, blue zone; Calder et al.,
2000). The lesion encompassed our activations.
Penﬁeld and Faulk (1955) demonstrated that
electrical stimulation of the anterior insula can
cause sensations of nausea supporting the idea that
the observation of the disgusted facial expressions
of others actually triggered an internal represen-
tation of nausea in the participant.
It therefore appears that the anterior insula in-
deed forms a shared circuit for the ﬁrst and third
person perspective of disgust, a conclusion cor-
roborated by electrophysiological studies (Krolak-
Salmon et al., 2003). The lesion data support the
idea that this circuit is indeed necessary for our
understanding of disgust in others. Interestingly,
just as we showed for the shared circuits for ac-
tions, the insula also appears to receive auditory
information about the disgusted emotion state of
others. Adolphs et al. (2003) showed that their
patient B with extensive insular lesions was unable
to recognize disgust, even if it was acted out with
distinctive sounds of disgust, such as retching and
vocal prosody. Imaging studies still fail to ﬁnd in-
sular activation to vocal expressions of disgust
(Phillips et al., 1998).
The amygdala and fear
A similar logic has been put forward for the re-
lationship between fear and the amygdala, sug-
gesting that the amygdala responds to the sight of
fearful facial expressions and during the experience
of fear. According to this logic, without amygdala,
both the capacity to perceive fear in the face of
others and that to experience fear would be greatly
affected. The state of that literature is undergoing
a recent re-evaluation (Spezio and Adolphs, this
volume). Below we will describe the arguments
ﬁrst in favour, then against the role of the am-
ygdala as a central site both for the experience and
recognition of fear.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
Fig. 5. agittal T1-weighted anatomical MRI of patient NK
(Calder et al., 2003) normalized to MNI space. The blue outline
marks the zone of the left insular infarction. The red outline
shows the zone we found to be activated during the experience
of disgust; the yellow outline indicates those zones found to be
common to this experience and the observation of someone
else’s facial expression of disgust (Wicker et al., 2003). Adapted
from Gallese et al. (2004).
391
For: Anatomically, the amygdala is linked both
to face processing and to bodily states. The am-
ygdala is a complex anatomical structure that re-
ceives highly processed sensory information from
higher sensory cortices (Amaral and Price, 1984),
including the temporal lobe where single neurons
respond to the sight of faces and facial expressions
(Perrett et al., 1984; Hasselmo et al., 1989). These
connections would enable the amygdala to process
facial expressions. It sends ﬁbres back to subcor-
tical structures such as the hypothalamus, enabling
it to induce the kind of changes in the state of the
body that are so typical of fear. It also sends ﬁbres
back to the cortex, including the STS, which could
enable it to inﬂuence the way faces are processed.
In humans, bilateral amygdala damage does
affect the capacity of subjects to recognize fear in
the face of other individuals, but only in about half
the subjects. A review of the literature reveals re-
ports of 24 subjects with bilateral amygdala dam-
age (see Table 1). When asked to rate how afraid,
angry, sad, happy, disgusted or surprised the emo-
tional facial photographs of (Ekman and Friesen,
1976) appeared, 12 of 24 subjects rated facial ex-
pressions of fear as less afraid than did control
subjects without bilateral amygdala lesions (see
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
Table 1. The amygdala and the emotion of fear
Damage Ethiology Perceptual deﬁcits References
Subject Left Right Fear Other
SM +++ +++ UW Yes Surprised a,b,c,g
JM +++ +++ E Yes Sad, disgusted, angry c,g
RH +++ +++ E No Angry c,g
SE +++ +++ E Yes Surprised d,g
DR ++ + S Yes Sad, disgusted, angry, surprised e,g
GT +++ +++ E No f,g
EP +++ +++ E No Angry f,g
SP ++ +++ S Yes Sad, disgusted g
DBB +++ ++ S No Sad, disgusted, angry g
NM ++ +++ ? Yes Sad h
SZ +++ ++ No Angry k
JC ++ +++ E Yes Angry i
YW ++ +++ E Yes i
RB +++ – E Yes i
JK ++ ++ UW No j
MA +++ +++ UW No j
FC +++ +++ UW No j
AF +++ +++ UW Yes j
AW +++ +++ UW No j
EW +++ +++ UW No j
WS +++ +++ UW No j
AvdW ++ ++ UW Yes j
RL ++ ++ UW No j
BR +++ +++ UW Yes j
Note: A number of neuropsychological studies have asked subjects with bilateral amygdala damage to rate how afraid six photographs of the Ekman
series of emotional facial expression photographs looked. Here we show a table reviewing all these studies, reporting for each patient whether he rated
these facial expressions as looking less afraid than do healthy control subjects. This information is taken from the referenced publications except for
patients JK to BR. For these patients, the original publication (Ref. j) reported only group data. M. Siebert and H. Markowitsch gave us the single subject
ratings of their patients and healthy subjects, and we considered deﬁcient those patients that fell below 1.64 standard deviations of the healthy controls. In
total, 12 of 24 subjects with bilateral amygdala damage rated scared facial expressions as less afraid than normal subjects do. Abbreviations: ‘–’: no
damage, or no deﬁcit; ‘+’: minimal damage; ‘++’: partial damage; ‘+++’: extensive or complete damage; UW: Urbach-Wiethe disease, a congenital
disease that causes bilateral calciﬁcations in the amygdala; E: encephalitis, usually affecting extensive regions of the brain; S: surgical removal, usually for
treatment of epilepsy. References: a: Adolphs et al. (1994); b: Adolphs et al. (1995); c: Adolphs et al. (1998); d: Calder et al. (1996); e: Young et al. (1995);
f: Hamann et al. (1996); g: Adolphs et al. (1999); h: Sprengelmeyer et al. (1999); i: Broks et al. (1998); j: Siebert et al. (2003). k: Adolphs and Tranel (2003).
392
Table 1). This ‘fear-blindness’ was not due to gen-
eral facial recognition deﬁcits (the patients never
had problems recognizing happy faces as happy),
nor was it due to the patients not understanding
the concept of fear (all patients speciﬁcally tested
could provide plausible scenarios of situations in
which people are scared). Other negative emotions
such as anger were often also affected.
Imaging studies using static facial expressions
corroborate the idea that the amygdala is impor-
tant for the perception of fear in others: in the
majority of the cases, the amygdala was activated
preferentially when subjects viewed fearful or an-
gry facial expressions as compared to neutral facial
expressions (Zald, 2003). Studies using movies
provide a different message (see below).
Lesions of the amygdala also corroborate to
some extent the idea of its involvement in gener-
ating fear. Monkeys with lesions in the amygdala
appear to be disinhibited: unlike their unlesioned
counterparts, they immediately engage in social
contacts with total strangers and in play with nor-
mally scary objects such as rubber snakes — as if,
without amygdala, the monkeys fail to be scared of
other individuals and objects (Amaral et al., 2003).
In addition, three of the amygdala patients of Ta-
ble 1 (SM, NM and YW) were tested with regards
to their own emotions of fear. SM appears to have
reduced psychophysiological reactions to fear
(Adolphs et al., 1996); NM only remembers hav-
ing been scared once in his life and enjoyed activ-
ities that would be terrifying to most of us (e.g.
bear hunting in Siberia, hanging from a helicopter,
Sprengelmeyer et al., 1999, p. 2455); YW did not
even experience fear while being mugged at night.
This suggests that without amygdala, there is
something different and reduced in the subjective
experience of fear.
Electrical stimulations of the amygdala in hu-
mans lead to a variety of experiences, but when-
ever it evoked an emotion, it was that of fear
(Halgren et al., 1978). Taken together with the
neuroimaging data in humans and the lesion data
in monkeys, the amygdala thus appears to be im-
portant for the normal associations of stimuli with
our personal, ﬁrst person perspective of fear.
The role of the amygdala in experiencing fear is
corroborated by a number of imaging studies.
Arachnophobic individuals, when viewing spiders,
experience more fear and show stronger BOLD
signals in their amygdala compared with control
subjects (Dilger et al., 2003). Cholecystokinin-tet-
rapeptide (cck-4) injections induce panic attacks
that are accompanied by intense feeling of fear and
cause augmentation of regional cerebral blood
ﬂow (rCBF) in the amygdala (Benkelfat et al.,
1995).
The above evidence therefore suggests a role for
the amygdala both in the recognition and the ex-
perience of fear. The idea of shared circuits would
require that parts of the neural representations of
the experience of fear should be triggered by the
observation of other peoples fear. This prediction
receives support from a study by Williams et al.
(2001). They showed subjects Ekman faces of fear,
and simultaneously recorded brain activity and
skin conductance. They found that the trials in
which the fear-faces produced increases of skin
conductance were accompanied by increased
BOLD responses in the amygdala. It therefore ap-
pears as though the vision of a fearful facial ex-
pression activates the amygdala and induces a
body state of fear/arousal in the observer, as in-
dicated by augmented skin conductance. This link
between amygdala and body state is also corrob-
orated by Anders et al. (2004).
Against: While there is evidence both from le-
sion studies and imaging supporting the dual role
of the amygdala in experiencing and recognizing
fear, there is a number of recent studies that shed
doubts on this interpretation.
First, half of the patients with bilateral am-
ygdalar lesions show no impairments in rating fear
in fearful faces. Authors have failed to ﬁnd etio-
logical or anatomical differences between the pa-
tients with and without fear-blindness (Adolphs et
al., 1998). QA :4
Second, a recent study on SM, one of the sub-
jects with bilateral amygdala damage, indicate that
the patient’s problem in identifying the expression
of fear in others is not due to an inability to rec-
ognize fear per se, but an inappropriate explora-
tion of the stimuli (Adolphs et al., 2005): unlike
control individuals, she failed to look at the eye
region of photographs. If she was encouraged to
do so, her fear recognition became entirely normal.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
393
In the context of the connections of the amygdala
with the STS, the function of the amygdala may
not be to recognize the facial expression of fear,
but to render the eye region of facial expressions a
salient stimulus, selectively biasing the stimulus
processing in the STS towards the eye region (see
also Spezio and Adolphs, this volume).
If the amygdala is indeed not responsible for the
recognition of fear but only in orienting visual in-
spection towards the eye region, one would predict
equal activation of the amygdala to all facial ex-
pressions. While this is often not the case when
static images of facial expressions were used (Phan
et al., 2004QA :5 for a review), using short movies of
facial expressions we found that the amygdala was
indeed activated similarly by all facial expressions,
be they emotional or not (van der Gaag et al.,
2005). We used movies of happiness, disgust, fear
and a neutral expression that contained as much
movement as the other facial expressions (blowing
up the cheeks). This ﬁnding sheds doubt on the
idea of the amygdala as showing direct fear selec-
tivity, and supports the idea of the amygdala par-
ticipating in the processing of all facial expressions
(for instance by biasing visual processing to the
eyes). The reason why we found neutral faces to
cause as much activation as emotional and fearful
expressions using movies while studies using static
stimuli have often reported differences remains to
be fully understood. Ecologically, facial expres-
sions are dynamic stimuli, not still photographs:
the task of detecting emotions from photos is ev-
olutionary rather new. We thus suggest that the
lack of amygdalar selectivity found using movies,
although needing replication, may be a more valid
picture of amygdalar function than the selectivity
often observed using photographs.
Doubt must also be shed on the importance of
the amygdala in feeling fear. Monkeys with very
early lesions in the amygdala still demonstrate
signs of panic, although they occur in contexts that
are not normally inducing fear (Amaral et al.,
2003). In addition, there is no good evidence that
patient SM completely lacks fear as an emotion,
although it may well be that she does not exhibit
fear appropriately in context — this is a difﬁcult
issue to measure in humans, and still remains un-
resolved (Adolphs, personal communication).
However, Anderson and Phelps (2002) have as-
sessed this question in patients with amygdala
damage, and also found no evidence that they lack
fear as an emotion. Together, it might thus be
speculated that the amygdala has a role both in the
normal experience of fear and in the recognition of
fear in others, but that this role may be indirect,
through focusing gaze on the eye region and by
linking normally fear-producing stimuli with other
brain areas that, in turn, are responsible for fear.
The amygdala may thus be part of a circuit that
enables us to share the fear of other individuals,
but its role in doing so may be indirect, by biasing
attention towards informative sections of facial
stimuli and by relaying information towards brain
areas responsible for the experience of fear. The
other nodes of this circuitry remain to be investi-
gated.
Shared circuits for actions, sensations and emotions
Subsuming the above evidence, it appears that in
three systems — actions, sensations and emotions
— certain brain areas are involved both in ﬁrst
person experience (I do, I feel) and third person
perspective (knowing what he does or he feels).
These areas or circuits, that we call shared circuits,
are the premotor cortex and inferior parietal lob-
ule interconnected with the STS/MTG for actions,
the insula for the emotion of disgust, the ACC and
the anterior insula for pain, and somatosensory
cortices for touch. Possibly, the amygdala may be
part of a shared circuit for fear. In all these cases,
observing what other people do or feel is therefore
transformed into an inner representation of what
we would do or feel in a similar situation — as if
we would be in the skin of the person we observe.
The idea of shared circuits, initially put forward
for actions (Gallese and Goldman, 1998) therefore
appears much broader.
In the light of this evidence, it appears as though
social situations are processed by the STS to a high
degree of sophistication, including multimodal au-
dio-visual representations of complex actions.
These representations privilege the third person
perspective, with lesser responses if the origin of
the stimulus is endogenous. Through the recruit-
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
394
ment of shared circuits, the brain then adds spe-
ciﬁc ﬁrst person elements to this description. If an
action is seen, the inferior parietal and premotor
areas add an inner representation of actions to the
sensory third person description. If touch is wit-
nessed, the somatosensory cortices add an inner
representation of touch. If pain is witnessed, the
ACC and the anterior insula add a sense of pain. If
disgust is witnessed, the insula adds a sense of
disgust. What emerges from the resulting neural
activity is a very rich neural description of what
has been perceived, adding the richness of our
subjective experience of actions, emotions and
sensations to the objective visual and auditory de-
scription of what has been seen.
We are not normally confused about where the
third person ends and the ﬁrst starts, because al-
though the shared areas react in similar ways to
our own experience and the perception of others,
many other areas clearly discriminate between
these two cases. Our own actions include strong
M1 activation and week STS activations, while
those of others fail to normally activate M1 but
strongly activate the STS. When we are touched,
our SI is strongly active, while it is much less active
while we witness touch occurring to others. In-
deed, patient C who is literally confused about
who is being touched shows reliable SI activity
during the sight of touch (Blakemore et al., 2005).
In this context, the distinction between self and
other is quite simple, but remains essential for a
social cognition based on shared circuits to work
(Gallese and Goldman, 1998; Decety and Som-
merville, 2003). Some authors now search for
brain areas that explicitly differentiate self from
other. Both the right inferior parietal lobule and
the posterior cingulate gyrus have been implicated
in this function (Decety and Sommerville, 2003
and Vogt, 2005 for reviews)
The account based on shared representation we
propose differs from those of other authors in that
it does not assume that a particular modality is
critical. Damasio and coworkers (Damasio, 2003)
emphasize the importance of somatosensory rep-
resentation, stating that it is only once our brain
reaches a somatosensory representation of the
body state of the person we observe that we un-
derstand the emotion he/she are undergoing. We,
on the other hand, believe that somatosensory
representations are important for understanding
the somatosensory sensations of others, but may
not be central to our understanding of other in-
dividuals’ emotions and actions. The current pro-
posal represents an extension from our own
previous proposals (e.g. Gallese et al., 2004),
where we emphasized the motor aspect of under-
standing other people. We believe that motor rep-
resentations are essential for understanding the
actions of others, yet the activity in somatosensory
cortices observed during the observation of some-
one else being touched is clearly nonmotor. In-
stead we think that each modality (actions,
sensations and emotions) is understood and shared
in our brain using its own speciﬁc circuitry. The
neural representation of actions, emotions and
sensations that results from the recruitment of
shared representations are then the intuitive key to
understanding the other person, without requiring
that they have to pass necessarily a somatosensory
or motor common code to be interpreted.
Of course many social situations are complex,
and involve multiple modalities: witnessing some-
one hitting his ﬁnger with a hammer contains an
action, an emotion and a sensation. In most social
situations, the different shared circuits mentioned
above thus work in concert.
Once shared circuits have transformed the ac-
tions, sensations and emotions of others into our
own representations of actions, sensations and
emotions, understanding other people’s boils
down to understanding ourselves — our own ac-
tions, sensations and emotions, an aspect that we
will return to later in relation to theory of mind.
Demystifying shared circuits through a hebbian
perspective
Neuroscientiﬁc evidence for the existence of shared
circuits is rapidly accumulating. The importance of
these circuits for social cognitions is evident. Yet,
for many readers, the existence of single neurons
responding to the sight, sound and execution of an
action — to take a single example — remains a
very odd observation. How can single neurons
with such marvellous capacities emerge? The plau-
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
395
sibility of a neuroscientiﬁc account of social cog-
nitions based on shared circuits stands and falls
with our capacity to give a plausible explanation of
how such neurons can emerge. As outlined in de-
tail elsewhere (Keysers and Perrett, in press), we
propose that shared circuits are a simple conse-
quence of observing ourselves and others (please
refer to Keysers and Perrett, in press, for citations
supporting the claims put forward below).
When they are young, monkeys and humans
spend a lot of time watching themselves. Each
time, the child’s hand wraps around an object, and
brings it towards him, a particular set of neural
activities overlaps in time. Neurons in the premo-
tor cortex responsible for the execution of this ac-
tion will be active at the same time as the audio-
visual neurons in the STS responding to the sight
and sound of grasping. Given that STS and F5 are
connected through PF, ideal Hebbian learning
conditions are met: what ﬁres together wires to-
gether. As a result, the synapses going from STS
grasping neurons to PF and then F5 will be
strengthened as the grasping neurons at all three
levels will be repeatedly coactive. After repeated
self-observation, neurons in F5 receiving the en-
hanced input from STS will ﬁre at the mere sight of
grasping. Given that many neurons in the STS
show reasonably viewpoint-invariant responses,
responding in similar ways to views of a hand
taken from different perspective, the sight of
someone else grasping in similar ways then sufﬁces
to activate F5 mirror neurons. All that is required
for the emergence of such mirror responses is the
availability of connections between STS-PF-F5
that can show Hebbian learning, and there is ev-
idence that Hebbian learning can occur in many
places in the neocortex (Bi and Poo, 2001).
The same Hebbian argument can be applied to
the case of sensations and emotions. While seeing
ourselves being touched, somatosensory activat-
ions overlap in time with visual descriptions of an
object moving towards and touching our body.
After Hebbian association the sight of someone
else being touched can trigger somatosensory acti-
vations (Keysers et al., 2004a,b; Blakemore et al.,
2005).
Multimodal responses are particularly impor-
tant for cases where we do not usually see our own
actions. How, for example, associating the sight of
someone’s lip movements with our own lip move-
ments is an important step in language acquisition.
How can we link the sight of another individual’s
mouth producing a particular sound with our own
motor programs given that we cannot usually see
our own mouth movements? While seeing other
individuals producing certain sounds with their
mouth, the sound and sight of the action are cor-
related in time, and can lead to STS multimodal
neurons. During our own attempts to produce
sounds with our mouth, the sound and the motor
program are correlated in time. As the sound will
recruit multimodal neurons in the STS, the estab-
lished link also ties the sight of other people pro-
ducing similar sounds to our motor program. The
visual information thereby rides on the wave of the
auditory associations (Keysers and Perrett, in
press).
The case of emotions might be similar, yet
slightly more difﬁcult. How can the sight of a dis-
gusted facial expression trigger our own emotion
of disgust, despite the fact that we do not usually
see our own disgusted facial expression? First, dis-
gust can often have a cause that will trigger si-
multaneous disgust in many individuals (e.g., a
disgusting smell). In this case, one’s own disgust
then correlates directly with the disgusted facial
expression of others. Second, in parent–child rela-
tionships, facial imitation is a prominent observa-
tion (e.g. Stern, 2000). In our Hebbian perspective,
this imitation means that the parent acts as a mir-
ror for the facial expression of the child, leading
again to the required correlation between the
child’s own emotion and the facial expression of
that emotion in others. As described above, the
insula indeed receives the required visual input
from the STS, where neurons have been shown to
respond to facial expressions (Mufson and Mesu-
lam, 1982). The insula also receives highly proc-
essed somatosensory information about our own
facial expressions. These somatosensory data will
be Hebbianly associated with both the sight of
other individual’s facial expressions and our own
state of disgust. After that Hebbian training, see-
ing someone else’s facial expressions may trigger a
neuronal representation of the somatosensory
components of our own matching facial expres-
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
396
sions. The debilitating effect of somatosensory le-
sions in understanding the emotions of others
(Adolphs et al., 2000) may indicate that this trig-
gering is indeed important in understanding the
emotions of others.
To summarize, Hebbian association (a simple
and molecularly well-understood process) can
therefore predict the emergence of associations
between the ﬁrst and third person perspective of
actions, sensations and emotions.
Shared circuits and the inanimate world
The world around us is not inhabited only by
other human beings: we often witness events that
occur to inanimate objects. Do the shared circuits
we described above react to the sight of an inan-
imate object performing actions or being touched?
To investigate the ﬁrst question, we showed
subjects movies of an industrial robot interacting
with everyday life objects ( QA :6Gazzola et al., 2004,
Society for Cognitive Neuroscience Annual Meet-
ing). The robot for instance was grasping a wine
glass or closing a salt box. These actions were
contrasted against the sight of a human perform-
ing the same actions. Fig. 6a illustrates a frame
from a typical stimulus, as well as the BOLD sig-
nal measured in BA 44 as deﬁned by the probabi-
listic maps (Amunts et al., 1999). As seen in 1.2,
this area has been shown to be activated both
during the execution of actions and the observa-
tion of another human being performing a similar
action. Here, we see that the same area was also
activated during the sight of a robot performing an
action involving everyday objects. This result is in
contrast with previous reports in the literature that
failed to ﬁnd premotor activation to the sight of a
robot performing actions (Tai et al., 2004). Our
experiment differs in some important aspects from
these studies: ﬁrst, we used more complex actions
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
Fig. 6. (a) Top: location of the right BA44 according to Amunts et al. (1999), deﬁned as the voxels where at least 1 of her 10 subjects
satisﬁed the cytoarchitectonic criterions for BA44. Below: the brain activity in this right BA44 for 14 subjects, expressed in terms of
parameter estimates in the GLM while subjects looked at a ﬁxation cross or at a human or a robot opening a bottle. A star indicates
signiﬁcant differences from the ﬁxation. (b) Location of the region of interest (white) deﬁned in Keysers et al. (2004), and below, the
mean BOLD signal of eight independent subjects while being touched on their legs, seeing another human being touched, and seeing
objects being touched. All three cases differ signiﬁcantly from ﬁxation, but not from one another (adapted from Keysers et al., 2004).
All error bars refer to standard error of the means.
397
instead of grasping of a ball; second our blocks
contained a variety of actions and not the same
action repeated over and over again. Both of these
factors could account for the observed difference.
In the light of our results, it thus appears as
though the shared circuit for actions responds to
complex meaningful actions regardless of whether
they are performed by humans and robots. Half
way along this human–robot continuum, the pre-
motor cortex also responds to the sight of animals
from another species performing actions that re-
semble ours, such as biting (Buccino et al., 2004a).
To test whether the secondary somatosensory
cortex responds to the sight of objects being
touched, we showed subjects movies of inanimate
objects such as ring binders and rolls of paper
towels being touched by a variety of rods. These
conditions were compared against the activity
when the subject himself was touched, and when
he saw another human leg being touched in similar
ways. Results, shown in Fig. 6b indicate that the
SII/PV complex was at least as activated by the
sight of objects being touched as by the sight of
humans being touched. Blakemore et al. (2005)
also showed movies of objects being touched, and
found that compared to seeing a human face being
touched, seeing a fan being touched induced
smaller activations. Unfortunately, the authors
did not indicate if the activation to seeing an object
being touched was signiﬁcant. Why Blakemore et
al. found stronger activity to the sight of a human
face being touched compared to an object, while
we found similar activity to a human leg being
touched compared to toilet paper rolls remains to
be investigated.
Together, data appear to emerge suggesting that
the sight of the actions and tactile ‘experiences’ of
the inanimate world may be transformed into our
own experience of these actions and sensations,
but further investigations of this aspect are im-
portant considering the somewhat contradictory
ﬁndings from different studies.
Shared circuits and communication
We show that the brain appears to automatically
transform the visual and auditory descriptions of
the actions, sensations and emotions of others into
neural representations normally associated with
our own execution of similar actions, and our own
experience of similar sensations and emotions. He-
bbian learning could explain how these automatic
associations arise. Once these associations have
been learned, they transform what other people do
and feel into our own experience of these actions,
sensations and emotions. This transformation rep-
resents a intuitive and powerful form of commu-
nication: it transmits the experience of doing and
feeling from one brain to another. This simple
form of communication has obvious adaptive
value: being able to peek into someone else’s
mind, and to share his experiences renders con-
structive social interactions faster and more effec-
tive. For instance, sharing the disgust of a
conspeciﬁc probing a potential source of food will
prevent the observer from tasting potentially dam-
aging items.
Most forms of communication have a funda-
mental problem: the sender transforms a content
into a certain transmittable form according to a
certain encoding procedure. The receiver then re-
ceives the encoded message, and has to transform
it back into the original content. How does the
receiver learn how to decode the message? When
we learn a spoken language we spend years of our
life guessing this encoding/decoding procedure.
For the case of actions, the shared circuits we
propose use the correlation in time in the STS-PF-
F5 circuit during self-observation to determine the
reciprocal relationship between the motor repre-
sentation of actions and their audio-visual conse-
quences. Similar procedures may apply to
sensations and emotions. The acquired reciprocal
relationships can then be used to decode the mo-
tor, somatosensory and emotional contents con-
tained in the behaviour of other individuals and in
the situation they are exposed to (see also Leiberg
and Anders, this volume).
When dealing with other human beings this de-
coding procedure is generally very successful. Our
brain appears to use the same procedure to un-
derstand members of other species and even inan-
imate objects and robots. In the case of members
of other animal species, the decoded motivations,
emotions and feelings are anthropocentric, and
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
398
imperfect: when monkeys for instance open their
lips to show their teeth, interpreting this as a smile
is a misinterpretation — it is actually a display of
threat. Often such interpretations will enable us to
predict the forthcoming behaviour of the animal
better than if we make no interpretation at all. In
the case of inanimate objects, the interpretations
are very often wrong (e.g. the ring binders prob-
ably ‘felt’ nothing when being touched, and the
robot was not thirsty when it grasped for the glass
of whine). This overgeneralization may simply be a
bug in our brain. Alternatively, overall, it might be
better to apply the rule of the thumb: everything is
probably a bit like myself, than to make no as-
sumption at all. A clear implication of this ten-
dency is that to make the human–machine
communication as smooth as possible, robots
should be made to behave as similarly to humans
as possible.
The limits of simulation — a word of caution
The shared circuits we describe have received con-
siderable interest. Often they now tend to be seen
as a panacea to explain any issues of social cog-
nition. It is important to note that while we believe
shared circuits to be very important for our intu-
ition of the inner life of others, they cannot explain
everything.
We can for instance try to imagine what it feels
like to ﬂy like a bird, although we do not have the
motor programs to do so. Such abstract imagina-
tions are detached from our own bodily experi-
ence, and should thus not be attributed to shared
circuits. We can of course imagine what it feels like
to ﬂap our hands, as kids do to pretend to ﬂy, but
that would still leave us with doubts about what
real ﬂying feels like.
These limitations are often cruelly clear to us
during imitation: we have often seen our mothers
knit, feeling that we can truly understand the
movement, yet when we tried for the ﬁrst time to
knit something ourselves, we realise that our un-
derstanding had been quite superﬁcial indeed, as
we were lacking the true motor programs on which
to mirror the actions we saw.
But even with the required motor skills, we do
not understand all the inner life of other human
beings through shared circuits. C. Keysers, E.
Kohler and M. Goodale (unpublished observa-
tion) have for instance examined brain activity
while watching the eye movements of other indi-
viduals in the hope to ﬁnd evidence that brain ar-
eas such as the frontal eye ﬁeld (FEF) normally
responsible for our own eye movements are critical
for our understanding of the eye movements of
others. We found very little evidence for such a
system: the sight of eye movements activated the
FEF no more than the sight of random dots mov-
ing by the same amount. Despite the difﬁculty of
interpreting negative results, this ﬁnding is not too
surprising: if two people face each other, and one
suddenly stares at the wall behind the other per-
son, the other person will tend to look behind him.
The motor programs involved are very different: a
very small saccade for the ﬁrst individual, and a
turning of the head and torso for the second.
There being so little in common in motor terms, it
makes no sense to analyse the gaze direction of
others through one’s own motor programs. An
external frame of reference, and an analysis of gaze
in this external frame is needed to understand what
the other person is looking at — a task that our
motor system, working in egocentric coordinates,
is very poorly equipped for. Shared circuits and
mirror neurons therefore have little to contribute
to this task. It will remain for future research to
outline the limits of what shared circuits can ex-
plain.
Simulation and theory of mind — a hypothesis
Social cognitions are not restricted to the simula-
tions that shared circuits provide. Explicit
thoughts exist in humans and clearly supplement
these automatic simulations. It is hard for instance
to imagine how a gossip of the type: ‘Did you
know that Marry still believes that her husband is
faithful while everyone else knows that he is hav-
ing an affair with another women every week?’ can
be the result of simulation, yet thinking about the
(false) beliefs of others is clearly an important part
of our social intelligence.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
399
The words theory of mind (ToM) and ‘mental-
izing’ have often been used to describe the set of
cognitive skills involved in thinking about the
mind of others, in particular their beliefs (Frith
and Frith, 2003). People are considered to have a
ToM if they are able to deal with the fact that
other people can have beliefs that differ from re-
ality, a capacity that is tested with so called false
belief tasks such as the famous ‘Sally and Anne’
test (Baron-Cohen et al., 1985). In that test, an
observer sees Sally hide an object in a basket. Sally
then goes away for a while, and unbeknown to her,
Anne moves the object from the basket into a box.
Sally then returns, and the observer is asked:
‘where will Sally [ﬁrst] look for her object?’ If the
observer answers ‘in the basket, because she
doesn’t know that Anne moved it’, the observer
is thought to have a ToM. If the answer is ‘in the
box’, the observer failed. Children from the age of
4 years pass this test, while autistic individuals of-
ten fail the test even in their teens (Baron-Cohen et
al., 1985).
Comparing this ToM task with the tasks in-
volved in the neuroimaging of shared circuits, it is
quite clear that these two ﬁelds of research tap into
phenomena that differ dramatically in the amount
of explicit thoughts that are involved (see also Le-
iberg and Anders this volume). In research on
shared circuits, subjects simply watch short video
clips of actions, emotions and sensations, without
being asked to reﬂect upon the meaning of these
stimuli or the beliefs and thoughts of the actors. In
ToM tasks, subjects are directly invited to reﬂect
about states of minds of others. Strangely enough,
a number of authors have introduced a dichotomy
between simulation processes and more theory
driven processes involved in understanding others
(e.g. Gallese and Goldman, 1998; Saxe, 2005),
suggesting that either ToM or simulation should
explain all of social cognitions. Here we will at-
tempt to provide a model that proposes that ToM
might utilize simulations to reﬂect on the mind of
others.
ToM-type tests have now been investigated a
number of times using fMRI and PET (see Frith
and Frith, 2003 for a comprehensive review), and
all tasks have activated medial prefrontal cortex
(mPFC) compared to conditions requiring less
mentalizing. What is intriguing, is that similar sites
of the mPFC are also involved in reﬂecting about
ourselves and our own emotions (Gusnard et al.,
2001; Frith and Frith, 2003), which lead Uta and
Frith to speculate that thinking about other peo-
ple’s minds might be a process related to thinking
about one’s self. If seen in the context of shared
circuits, this leads to a simple framework for as-
sociating shared circuits and ToM. The mPFC
may originally interpret states of our own mind
and body, as evidenced by experiments such as
that of Gusnard et al. (2001). In this experiment,
subjects saw emotional pictures, and were asked to
judge if the image evoked pleasant or unpleasant
emotions in themselves, or whether the images
were taken indoors or outdoors. The mPFC was
more activated in the former task, where subjects
had to introspect their own emotions.
The mPFC receives indirect inputs about all as-
pects of our own body, including motor, somato-
sensory and visceral representations, which could
allow it to create secondary representation of our
bodily state (Frith and Frith, 2003). Considering
our ﬁrst person perspective, one could thus differ-
entiate a ﬁrst level representation, being our ac-
tions, emotions and sensations as they occur, and a
second level representation in the mPFC of these
states more related to our conscious understanding
and interpretation of ourselves. To illustrate that
difference, if you vomit, you will feel disgust, and
activate your insula (primary representation). If
asked what you feel, you may start reﬂecting upon
what you are feeling in a more conscious way, one
that you can formulate in words (‘I felt like having
a stone in my stomach, I guess those mussels
weren’t that freshy’) and you are likely to acti-
vate your mPFC in addition to the primary rep-
resentations.
This is where simulation ties into the concepts of
theory of mind. Through the shared circuits we
have described, the actions, emotions and sensa-
tions of others are ‘translated’ into the neural lan-
guage of our own actions, emotions and
sensations. By doing so, they have been trans-
formed into what we called primary representa-
tions of these states. This could generate an
implicit sharing and hence understanding of the
states of others. If asked explicitly what went on in
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
400
the mind of that other person, you would need to
generate a secondary, more conscious and cogni-
tive representation of his state. Given that his state
has already been translated into the language of
our own states, one may hypothesize, that this task
would now be no different from reﬂecting about
your own states, and therefore activate the same
mPFC sites. Testing this hypothesis directly will be
an exciting issue in future neuroimaging work.
In this concept, shared circuits act like a trans-
lator, converting the states of others into our own
primary state representations. Often social
processing can stop at that: we share some of the
states of our partner, her/his sadness or happiness
for instance, without thinking any further. These
are the cases that simulation proponents have
concentrated on. In some cases, we might reﬂect
further upon her/his mind, just like we often reﬂect
about our own states. Such reﬂections then pro-
vide much more elaborate, cognitive and differen-
tiated understandings of other individuals. These
latter are the processes that ToM investigators are
excited about.
With those mentalizing processes on top of sim-
ulation, thinking about others can reach levels of
sophistications that go far beyond using simula-
tion alone. Using simulation, we inherently assume
that we are all equal. This is not the case: actions
that may make us happy may make other people
sad, reﬂecting biological and cultural differences,
and keeping in mind those differences may be a
critical role for higher processes (see also Leiberg
and Anders, this volume).
Uncited References
Allison et al., 2000; Barraclough et al., (in press);
Barraclough et al., 2004; Carr et al., 2003; Daprati
et al., 1997; Fogassi, 2004; Fogassi et al., 2001;
Frith and Dolan, 1997; Gallese et al., 1994;
Ghazanfar and Logothetis, 2003; Graziano et al.,
2002; Hebb, 1949; Hietanen and Perrett, 1996;
Jellema and Perrett, 2003a; Jellema and Perrett,
2003b; Keysers and Perrett, 2002; Keysers et al.,
2001; Koski et al., 2003; Koski et al., 2002; Ko-
urtzi and Kanwisher, 2000; Laland and Bateson,
2001; Logothetis et al., 1995; Markram et al.,
1997; Oztop and Arbib, 2002; Perrett et al., 1992;
Perrett et al., 1987; Perrett et al., 1991; Puce and
Perrett, 2003; Rizzolatti et al., 2001; Rizzolatti et
al., 1998; Sperry, 1950; Vonholst and Mittelstaedt,
1950.
Acknowledgements
C.K. was ﬁnanced by a VIDI grant by NWO and a
Marie Curie Excellence grant. The authors are
particularly thankful to Michaela Siebert for shar-
ing her raw data with us to calculate Table 1, to
Andy Calder for providing the anatomical scan of
patient NK, to Ralph Adolphs for helpful discus-
sions regarding the function of the amygdala and
to Vittorio Gallese, Bruno Wicker and Giacomo
Rizzolatti for many inspiring discussions that led
to the development of these models.
References
Adolphs, R., Damasio, H., Tranel, D., Cooper, G. and Dam-
asio, A.R. (2000) A role for somatosensory cortices in the
visual recognition of emotion as revealed by three-dimen-
sional lesion mapping. J. Neurosci., 20: 2683–2690.
Adolphs, R., Damasio, H., Tranel, D. and Damasio, A.R.
(1996) Cortical systems for the recognition of emotion in fa-
cial expressions. J. Neurosci., 16: 7678–7687.
Adolphs, R., Gosselin, F., Buchanan, T.W., Tranel, D., Schyns,
P. and Damasio, A.R. (2005) A mechanism for impaired fear
recognition after amygdala damage. Nature, 433: 68–72.
Adolphs, R. and Tranel, D. (2003) Amygdala damage impairs
emotion recognition from scenes only when they contain fa-
cial expressions. Neuropsychologia, 41: 1281–1289.
Adolphs, R., Tranel, D. and Damasio, A.R. (1998) The human
amygdala in social judgment. Nature, 393: 470–474.
Adolphs, R., Tranel, D. and Damasio, A.R. (2003) Dissociable
neural systems for recognizing emotions. Brain Cogn., 52:
61–69.
Adolphs, R., Tranel, D., Damasio, H. and Damasio, A. (1994)
Impaired recognition of emotion in facial expressions fol-
lowing bilateral damage to the human amygdala. Nature,
372: 669–672.
Adolphs, R., Tranel, D., Damasio, H. and Damasio, A.R.
(1995) Fear and the human amygdala. J. Neurosci., 15:
5879–5891.
Adolphs, R., Tranel, D., Hamann, S., Young, A.W., Calder,
A.J., Phelps, E.A., Anderson, A., Lee, G.P. and Damasio,
A.R. (1999) Recognition of facial emotion in nine individuals
with bilateral amygdala damage. Neuropsychologia, 37:
1111–1117.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
401
Allison, T., Puce, A. and McCarthy, G. (2000) Social percep-
tion from visual cues: role of the STS region. Trends Cogn.
Sci., 4: 267–278.
Amaral, D.G., Capitanio, J.P., Jourdain, M., Mason, W.A.,
Mendoza, S.P. and Prather, M. (2003). The amygdala: is it an
essential component of the neural network for social cogni-
tion? Neuropsychologia, 41: 235–240.
Amaral, D.G. and Price, J.L. (1984) Amygdalo-cortical pro-
jections in the monkey (Macaca fascicularis). J. Comp. Ne-
urol., 230: 465–496.
Amunts, K., Schleicher, A., Burgel, U., Mohlberg, H., Uylings,
H.B. and Zilles, K. (1999) Broca’s region revisited: cytoar-
chitecture and intersubject variability. J. Comp. Neurol., 412:
319–341.
Anders, S., Lotze, M., Erb, M., Grodd, W. and Birbaumer, N.
(2004) Brain activity underlying emotional valence and
arousal: a response-related fMRI study. Hum. Brain Mapp.,
23: 200–209.
Anderson, A.K. and Phelps, E.A. (2002) Is the human am-
ygdala critical for the subjective experience of emotion? Ev-
idence of intact dispositional affect in patients with amygdala
lesions. J. Cogn. Neurosci., 14: 709–720.
Avenanti, A., Bueti, D., Galati, G. and Aglioti, S.M. (2005)
Transcranial magnetic stimulation highlights the sensorimo-
tor side of empathy for pain. Nat. Neurosci., 8: 955–960.
Baker, C.I., Keysers, C., Jellema, T., Wicker, B. and Perrett,
D.I. (2001) Neuronal representation of disappearing and
hidden objects in temporal cortex of the macaque. Exp. Brain
Res., 140: 375–381.
Bangert, M., Peschel, T., Schlaug, G., Rotte, M., Drescher, D.,
Hinrichs, H., Heinze, H.J., and Altenmuller, E., 2005. Shared
networks for auditory and motor processing in professional
pianists: evidence from fMRI conjunction. Neuroimage.QA :7
Baron-Cohen, S., Leslie, A.M. and Frith, U. (1985) Does the
autistic child have a ‘‘theory of mind’’. Cognition, 21: 37–46.
Barraclough, N.E., Xiao, D.K., Baker, C.I., Oram, M.W., and
Perrett, D.I., (in press) Integration of visual and auditory
information by STS neurons responsive to the sight of ac-
tions. J. Cogn. Neurosci.
Barraclough, N.E., Xiao, D.K., Oram, M.W. and Perrett, D.I.
(2004) Primate superior temporal sulcus (STS) neurons inte-
grate visual and auditory information for biological motions.
Soc. Neurosci. Abs., 29.
Bell, B.D. (1994) Pantomime recognition impairment in apha-
sia: an analysis of error types. Brain Lang., 47: 269–278.
Benkelfat, C., Bradwejn, J., Meyer, E., Ellenbogen, M., Milot,
S., Gjedde, A. and Evans, A. (1995) Functional neuroanat-
omy of CCK4-induced anxiety in normal healthy volunteers.
Am. J. Psychiatry, 152: 1180–1184.
Bi, G. and Poo, M. (2001) Synaptic modiﬁcation by correlated
activity: Hebb’s postulate revisited. Ann. Rev. Neurosci., 24:
139–166.
Blakemore, S.J., Bristow, D., Bird, G., Frith, C. and Ward, J.
(2005) Somatosensory activations during the observation of
touch and a case of vision-touch synaesthesia. Brain, 128:
1571–1583.
Broks, P., Young, A.W., Maratos, E.J., Coffey, P.J., Calder,
A.J., Isaac, C.L., Mayes, A.R., Hodges, J.R., Montaldi, D.,
Cezayirli, E., Roberts, N. and Hadley, D. (1998) Face
processing impairments after encephalitis: amygdala damage
and recognition of fear. Neuropsychologia, 36: 59–70.
Bruce, C., Desimone, R. and Gross, C.G. (1981) Visual prop-
erties of neurons in a polysensory area in superior temporal
sulcus of the macaque. J. Neurophysiol., 46: 369–384.
Buccino, G., Binkofski, F., Fink, G.R., Fadiga, L., Fogassi, L.,
Gallese, V., Seitz, R.J., Zilles, K., Rizzolatti, G. and Freund,
H.J. (2001) Action observation activates premotor and pa-
rietal areas in a somatotopic manner: an fMRI study. Eur. J.
Neurosci., 13: 400–404.
Buccino, G., Lui, F., Canessa, N., Patteri, I., Lagravinese, G.,
Benuzzi, F., Porro, C.A. and Rizzolatti, G. (2004a) Neural
circuits involved in the recognition of actions performed by
nonconspeciﬁcs: an FMRI study. J. Cogn. Neurosci., 16:
114–126.
Buccino, G., Vogt, S., Ritzl, A., Fink, G.R., Zilles, K., Freund,
H.J. and Rizzolatti, G. (2004b) Neural circuits underlying
imitation learning of hand actions: an event-related fMRI
study. Neuron, 42: 323–334.
Calder, A.J., Keane, J., Manes, F., Antoun, N. and Young,
A.W. (2000) Impaired recognition and experience of disgust
following brain injury. Nat. Neurosci., 3: 1077–1078.
Calder, A.J., Young, A.W., Rowland, D., Perrett, D.I., Hod-
ges, J.R. and Etcoff, N.L. (1996) Facial emotion recognition
after bilateral amygdala damage: differentially severe impair-
ment of fear. Cogn. Neuropsychol., 13: 699–745.
Calvo-Merino, B., Glaser, D.E., Grezes, J., Passingham, R.E.
and Haggard, P. (2005) Action observation and acquired
motor skills: an fMRI study with expert dancers. Cerebral
Cortex, 15: 1243–1249.
Carr, L., Iacoboni, M., Dubeau, M.C., Mazziotta, J.C. and
Lenzi, G.L. (2003) Neural mechanisms of empathy in hu-
mans: a relay from neural systems for imitation to limbic
areas. Proc. Natl. Acad. Sci. USA, 100: 5497–5502.
Damasio, A.R. (2003) Looking for Spinoza. Harcourt, New
York.
Daprati, E., Franck, N., Georgieff, N., Proust, J., Pacherie, E.,
Dalery, J. and Jeannerod, M. (1997) Looking for the agent:
an investigation into consciousness of action and self-con-
sciousness in schizophrenic patients. Cognition, 65: 71–86.
Decety, J., Chaminade, T., Grezes, J. and Meltzoff, A.N. (2002)
A PET exploration of the neural mechanisms involved in
reciprocal imitation. Neuroimage, 15: 265–272.
Decety, J., Grezes, J., Costes, N., Perani, D., Jeannerod, M.,
Procyk, E., Grassi, F. and Fazio, F. (1997) Brain activity
during observation of actions Inﬂuence of action content and
subject’s strategy. Brain, 120(Pt 10): 1763–1777.
Decety, J. and Sommerville, J.A. (2003) Shared representations
between self and other: a social cognitive neuroscience view.
Trends Cogn. Sci., 7: 527–533.
Dilger, S., Straube, T., Mentzel, H.J., Fitzek, C., Reichenbach,
J.R., Hecht, H., Krieschel, S., Gutberlet, I. and Miltner,
W.H. (2003) Brain activation to phobia-related pictures in
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
402
spider phobic humans: an event-related functional magnetic
resonance imaging study. Neurosci. Lett., 348: 29–32.
Dipellegrino, G., Fadiga, L., Fogassi, L., Gallese, V. and Ri-
zzolatti, G. (1992) Understanding motor events — a neuro-
physiological study. Exp. Brain Res., 91: 176–180.
Ekman, P. and Friesen, M.V. (1976) Pictures of Facial Affect.
Consulting Psychologists Press, Palo Alto CA.
Fadiga, L., Craighero, L. and Olivier, E. (2005) Human motor
cortex excitability during the perception of others’ action.
Curr. Opin. Neurobiol., 15: 213–218.
Fadiga, L., Fogassi, L., Pavesi, G. and Rizzolatti, G. (1995)
Motor facilitation during action observation: a magnetic
stimulation study. J. Neurophysiol., 73: 2608–2611.
Ferrari, P.F., Rozzi, S. and Fogassi, L. (2005) Mirror neurons
responding to observation of actions made with tools in
monkey ventral premotor cortex. J. Cogn. Neurosci., 17:
212–226.
Fogassi, L., 2004. Effectiveness of videorecorded stimuli in F5.
Personal communication.
Fogassi, L., Gallese, V., Buccino, G., Craighero, L., Fadiga, L.
and Rizzolatti, G. (2001) Cortical mechanism for the visual
guidance of hand grasping movements in the monkey — a
reversible inactivation study. Brain, 124: 571–586.
Frith, C. and Dolan, R.J. (1997) Brain mechanisms associated
with top-down processes in perception. Philos. Trans. R. Soc.
London Series B-Biol. Sci., 352: 1221–1230.
Frith, U. and Frith, C.D. (2003) Development and neurophys-
iology of mentalizing. Philos. Trans. R. Soc. Lond. B Biol.
Sci., 358: 459–473.
Gallese, V., Fadiga, L., Fogassi, L. and Rizzolatti, G. (1996)
Action recognition in the premotor cortex. Brain, 119:
593–609.
Gallese, V., Fadiga, L., Fogassi, L. and Rizzolatti, G. (2002)
Action representation and the inferior parietal lobule. Com-
mon Mech. Percept. Act., 19: 334–355.
Gallese, V. and Goldman, A. (1998) Mirror neurons and the
simulation theory of mind-reading. Trends Cogn. Sci., 2:
493–501.
Gallese, V., Keysers, C. and Rizzolatti, G. (2004) A unifying
view of the basis of social cognition. Trends Cogn. Sci., 8:
396–403.
Gallese, V., Murata, A., Kaseda, M., Niki, N. and Sakata, H.
(1994) Deﬁcit of hand preshaping after muscimol injection in
monkey parietal cortex. Neuroreport, 5: 1525–1529.
Gangitano, M., Mottaghy, F.M. and Pascual-Leone, A. (2001)
Phase-speciﬁc modulation of cortical motor output during
movement observation. Neuroreport, 12: 1489–1492.
Gazzola, V., Aziz-Zadeh, L., Formisano, E., and Keysers, C.,
2005. Hearing what you are doing — an FMRI study of
auditory empathy. J. Cogn. Neurosci. Suppl. S, 82.QA :8
Ghazanfar, A.A. and Logothetis, N.K. (2003) Neuropercep-
tion: facial expressions linked to monkey calls. Nature, 423:
937–938.
Grafton, S.T., Arbib, M.A., Fadiga, L. and Rizzolatti, G.
(1996) Localization of grasp representations in humans by
positron emission tomography. 2. Observation compared
with imagination. Exp. Brain Res., 112: 103–111.
Graziano, M.S.A., Taylor, C.S.R. and Moore, T. (2002) Com-
plex movements evoked by microstimulation of precentral
cortex. Neuron, 34: 841–851.
Grezes, J., Armony, J.L., Rowe, J. and Passingham, R.E.
(2003) Activations related to ‘‘mirror’’ and ‘‘canonical’’ neu-
rones in the human brain: an fMRI study. Neuroimage, 18:
928–937.
Grezes, J., Costes, N. and Decety, J. (1998) Top-down effect of
strategy on the perception of human biological motion: a
PET investigation. Cogn. Neuropsychol., 15: 553–582.
Grezes, J., Fonlupt, P., Bertenthal, B., Delon-Martin, C., Se-
gebarth, C. and Decety, J. (2001). Does perception of bio-
logical motion rely on speciﬁc brain regions? Neuroimage,
13: 775–785.
Gusnard, D.A., Akbudak, E., Shulman, G.L. and Raichle,
M.E. (2001) Medial prefrontal cortex and self-referential
mental activity: relation to a default mode of brain function.
Proc. Natl. Acad. Sci. USA, 98: 4259–4264.
Halgren, E., Walter, R.D., Cherlow, D.G. and Crandall, P.H.
(1978) Mental phenomena evoked by electrical stimulation of
the human hippocampal formation and amygdala. Brain,
101: 83–117.
Halsband, U., Schmitt, J., Weyers, M., Binkofski, F., Grutzner,
G. and Freund, H.J. (2001) Recognition and imitation of
pantomimed motor acts after unilateral parietal and premo-
tor lesions: a perspective on apraxia. Neuropsychologia, 39:
200–216.
Hamann, S.B., Stefanacci, L., Squire, L.R., Adolphs, R.,
Tranel, D., Damasio, H. and Damasio, A. (1996) Recogniz-
ing facial emotion. Nature, 379: 497.
Harries, M.H. and Perrett, D.I. (1991) Visual processing of
faces in temporal cortex — physiological evidence for a
modular organization and possible anatomical correlates. J.
Cogn. Neurosci., 3: 9–24.
Hasselmo, M.E., Rolls, E.T. and Baylis, G.C. (1989) The role of
expression and identity in the face-selective responses of neu-
rons in the temporal visual-cortex of the monkey. Behav.
Brain Res., 32: 203–218.
Hauk, O., Johnsrude, I. and Pulvermuller, F. (2004) Somato-
topic representation of action words in human motor and
premotor cortex. Neuron, 41: 301–307.
Hebb, D. (1949) The Organisation of Behavior. Wiley, New
York.
Heiser, M., Iacoboni, M., Maeda, F., Marcus, J. and Mazzi-
otta, J.C. (2003) The essential role of Broca’s area in imita-
tion. Eur. J. Neurosci., 17: 1123–1128.
Hietanen, J.K. and Perrett, D.I. (1993) Motion sensitive cells in
the macaque superior temporal polysensory area1. Lack of
response to the sight of the animals own limb movement.
Exp. Brain Res., 93: 117–128.
Hietanen, J.K. and Perrett, D.I. (1996) Motion sensitive cells in
the macaque superior temporal polysensory area: response
discrimination between self-generated and externally gener-
ated pattern motion. Behav. Brain Res., 76: 155–167.
Hutchison, W.D., Davis, K.D., Lozano, A.M., Tasker, R.R.
and Dostrovsky, J.O. (1999) Pain-related neurons in the hu-
man cingulate cortex. Nat. Neurosci., 2: 403–405.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
403
Iacoboni, M., Koski, L.M., Brass, M., Bekkering, H., Woods,
R.P., Dubeau, M.C., Mazziotta, J.C. and Rizzolatti, G.
(2001) Reafferent copies of imitated actions in the right su-
perior temporal cortex. Proc. Natl. Acad. Sci. USA, 98:
13995–13999.
Iacoboni, M., Woods, R.P., Brass, M., Bekkering, H., Mazzi-
otta, J.C. and Rizzolatti, G. (1999) Cortical mechanisms of
human imitation. Science, 286: 2526–2528.
Jackson, P.L., Meltzoff, A.N. and Decety, J. (2005) How do we
perceive the pain of others? A window into the neural proc-
esses involved in empathy. Neuroimage, 24: 771–779.
Jellema, T. and Perrett, D.I. (2003a) Cells in monkey STS re-
sponsive to articulated body motions and consequent static
posture: a case of implied motion. Neuropsychologia, 41:
1728–1737.
Jellema, T. and Perrett, D.I. (2003b) Perceptual history inﬂu-
ences neural responses to face and body postures. J. Cogn.
Neurosci., 15: 961–971.
Keysers, C., 2003. Mirror neurons. In: Encyclopedia of Neuro-
science, 3rd edn. Elsevier, Amsterdam.
Keysers, C., Gallese, V., Tereshenko, L., Nasoyan, A.,
Sterbizzi, I., and Rizzolatti, G., 2004a. Investigation of au-
ditory and motor properties in the STS (Unpublished).
Keysers, C., Kohler, E., Umilta, M.A., Nanetti, L., Fogassi, L.
and Gallese, V. (2003) Audiovisual mirror neurons and ac-
tion recognition. Exp. Brain Res., 153: 628–636.
Keysers, C. and Perrett, D.I. (2002) Visual masking and RSVP
reveal neural competition. Trends Cogn. Sci., 6: 120–125.
Keysers, C., and Perrett, D.I., in press. Demystifying social
cognitions — a Hebbian circuit. Trends Cogn. Sci.QA :9
Keysers, C., Wicker, B., Gazzola, V., Anton, J.L., Fogassi, L.
and Gallese, V. (2004b) A touching sight: SII/PV activation
during the observation and experience of touch. Neuron, 42:
335–346.
Keysers, C., Xiao, D.K., Foldiak, P. and Perrett, D.I. (2001)
The speed of sight. J. Cogn. Neurosci., 13: 90–101.
Kohler, E., Keysers, C., Umilta, M.A., Fogassi, L., Gallese, V.
and Rizzolatti, G. (2002) Hearing sounds, understanding ac-
tions: action representation in mirror neurons. Science, 297:
846–848.
Koski, L., Iacoboni, M., Dubeau, M.C., Woods, R.P. and
Mazziotta, J.C. (2003) Modulation of cortical activity during
different imitative behaviors. J. Neurophysiol., 89: 460–471.
Koski, L., Wohlschlager, A., Bekkering, H., Woods, R.P.,
Dubeau, M.C., Mazziotta, J.C. and Iacoboni, M. (2002)
Modulation of motor and premotor activity during imitation
of target-directed actions. Cereb Cortex, 12: 847–855.
Kourtzi, Z. and Kanwisher, N. (2000) Activation in human
MT/MST by static images with implied motion. J. Cogn.
Neurosci., 12: 48–55.
Krolak-Salmon, P., Henaff, M.A., Isnard, J., Tallon-Baudry,
C., Guenot, M., Vighetto, A., Bertrand, O. and Mauguiere,
F. (2003) An attention modulated response to disgust in hu-
man ventral anterior insula. Ann. Neurol., 53: 446–453.
Laland, K.N. and Bateson, P. (2001) The mechanisms of im-
itation. Cybern. Syst., 32: 195–224.
Leslie, K.R., Johnson-Frey, S.H. and Grafton, S.T. (2004)
Functional imaging of face and hand imitation: towards a
motor theory of empathy. Neuroimage, 21: 601–607.
Logothetis, N.K. (2003) The underpinnings of the BOLD func-
tional magnetic resonance imaging signal. J. Neurosci., 23:
3963–3971.
Logothetis, N.K., Pauls, J. and Poggio, T. (1995) Shape rep-
resentation in the inferior temporal cortex of monkeys. Curr.
Biol., 5: 552–563.
Luppino, G., Murata, A., Govoni, P. and Matelli, M. (1999)
Largely segregated parietofrontal connections linking rostral
intraparietal cortex (areas AIP and VIP) and the ventral
premotor cortex (areas F5 and F4). Exp. Brain Res., 128:
181–187.
Manthey, S., Schubotz, R.I. and von Cramon, D.Y. (2003)
Premotor cortex in observing erroneous action: an fMRI
study. Brain Res. Cogn. Brain Res., 15: 296–307.
Markram, H., Lubke, J., Frotscher, M. and Sakmann, B. (1997)
Regulation of synaptic efﬁcacy by coincidence of postsynap-
tic APs and EPSPs. Science, 275: 213–215.
Matelli, M., Camarda, R., Glickstein, M. and Rizzolatti, G.
(1986) Afferent and efferent projections of the inferior area-6
in the macaque monkey. J.Comp. Neurol., 251: 281–298.
Mufson, E.J. and Mesulam, M.M. (1982) Insula of the old-
world monkey 2 Afferent cortical input and comments on the
claustrum. J. Comp. Neurol., 212: 23–37.
Nishitani, N. and Hari, R. (2000) Temporal dynamics of cor-
tical representation for action. Proc. Natl. Acad. Sci. USA,
97: 913–918.
Nishitani, N. and Hari, R. (2002) Viewing lip forms: cortical
dynamics. Neuron, 36: 1211–1220.
Oram, M.W. and Perrett, D.I. (1994) Responses of anterior
superior temporal polysensory (Stpa) neurons to biological
motion stimuli. J. Cogn. Neurosci., 6: 99–116.
Oram, M.W. and Perrett, D.I. (1996) Integration of form and
motion in the anterior superior temporal polysensory area
(STPa) of the macaque monkey. J. Neurophysiol., 76:
109–129.
Oztop, E. and Arbib, M.A. (2002) Schema design and imple-
mentation of the grasp-related mirror neuron system. Biol.
Cybern., 87: 116–140.
Penﬁeld, W. and Faulk, M.E. (1955) The insula: further obser-
vations on its function. Brain, 78: 445–470.
Perani, D., Fazio, F., Borghese, N.A., Tettamanti, M., Ferrari,
S., Decety, J. and Gilardi, M.C. (2001) Different brain cor-
relates for watching real and virtual hand actions. Neuroim-
age, 14: 749–758.
Perrett, D.I., Harries, M.H., Bevan, R., Thomas, S., Benson,
P.J., Mistlin, A.J., Chitty, A.J., Hietanen, J.K. and Ortega,
J.E. (1989) Frameworks of analysis for the neural represen-
tation of animate objects and actions. J. Exp. Biol., 146:
87–113.
Perrett, D.I., Hietanen, J.K., Oram, M.W. and Benson, P.J.
(1992) Organization and functions of cells responsive to faces
in the temporal cortex. Philos.Trans. R. Soc. London Series
B-Biol. Sci., 335: 23–30.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
404
Perrett, D.I., Mistlin, A.J. and Chitty, A.J. (1987) Visual neu-
rons responsive to faces. Trends Neurosci., 10: 358–364.
Perrett, D.I., Mistlin, A.J., Harries, M.H., and Chitty, A.J.,
1990. Understanding the visual appearance and consequences
of hand actions. In: Goodale, M.A. (Ed.), Vision and Action:
The Control of Grasping. Ablex Publishing, pp. 163–180.QA :10
Perrett, D.I., Oram, M.W., Harries, M.H., Bevan, R., Hie-
tanen, J.K., Benson, P.J. and Thomas, S. (1991) Viewer-cen-
tered and object-centered coding of heads in the macaque
temporal cortex. Exp. Brain Res., 86: 159–173.
Perrett, D.I., Smith, P.A.J., Potter, D.D., Mistlin, A.J., Head,
A.S., Milner, A.D. and Jeeves, M.A. (1984) Neurones re-
sponsive to faces in the temporal cortex: studies of functional
organization, sensitivity to identity and relation to percep-
tion. J. Comp. Physiol. Psychol., 3: 197–208.
Perrett, D.I., Smith, P.A.J., Potter, D.D., Mistlin, A.J., Head,
A.S., Milner, A.D. and Jeeves, M.A. (1985) Visual cells in the
temporal cortex sensitive to face view and gaze direction.
Proc. R. Soc. Lond. B Biol. Sci., 223: 293–317.
Phan, K.L., Wager, T.D., Taylor, S.F. and Liberzon, I. (2004)
Functional neuroimaging studies of human emotions. CNS
Spectrom., 9: 258–266.
Phillips, M.L., Young, A.W., Scott, S.K., Calder, A.J., Andrew,
C., Giampietro, V., Williams, S.C., Bullmore, E.T., Bra-
mmer, M. and Gray, J.A. (1998) Neural responses to facial
and vocal expressions of fear and disgust. Proc. R. Soc.
London B Biol. Sci., 265: 1809–1817.
Phillips, M.L., Young, A.W., Senior, C., Brammer, M., An-
drew, C., Calder, A.J., Bullmore, E.T., Perrett, D.I., Row-
land, D., Williams, S.C., Gray, J.A. and David, A.S. (1997) A
speciﬁc neural substrate for perceiving facial expressions of
disgust. Nature, 389: 495–498.
Puce, A. and Perrett, D. (2003) Electrophysiology and brain
imaging of biological motion. Philos. Trans. R. Soc. Lond. B
Biol. Sci., 358: 435–445.
Rijntjes, M., Dettmers, C., Buchel, C., Kiebel, S., Frackowiak,
R.S. and Weiller, C. (1999) A blueprint for movement: func-
tional and anatomical representations in the human motor
system. J. Neurosci., 19: 8043–8048.
Rizzolatti, G. and Craighero, L. (2004) The mirror-neuron sys-
tem. Ann. Rev. Neurosci., 27: 169–192.
Rizzolatti, G., Fadiga, L., Gallese, V. and Fogassi, L. (1996)
Premotor cortex and the recognition of motor actions. Cogn.
Brain Res., 3: 131–141.
Rizzolatti, G., Fogassi, L. and Gallese, V. (2001) Neurophys-
iological mechanisms underlying the understanding and im-
itation of action. Nat. Rev. Neurosci., 2: 661–670.
Rizzolatti, G. and Luppino, G. (2001) The cortical motor sys-
tem. Neuron, 31: 889–901.
Rizzolatti, G., Luppino, G. and Matelli, M. (1998) The organ-
ization of the cortical motor system: new concepts Elect-
roencephalogr. Clin. Neurophysiol., 106: 283–296.
Rizzolatti, G. and Matelli, M. (2003) Two different streams
form the dorsal visual system: anatomy and functions. Exp.
Brain Res., 153: 146–157.
Saxe, R. (2005) Against simulation: the argument from error.
Trends Cogn. Sci., 9: 174–179.
Selemon, L.D. and Goldmanrakic, P.S. (1988) Common cor-
tical and subcortical targets of the dorsolateral prefrontal
and posterior parietal cortices in the rhesus-monkey — ev-
idence for a distributed neural network subserving spatially
guided behavior. J. Neurosci., 8: 4049–4068.
Seltzer, B. and Pandya, D.N. (1978) Afferent cortical connec-
tions and architectonics of superior temporal sulcus and sur-
rounding cortex in rhesus-monkey. Brain Res., 149: 1–24.
Seltzer, B. and Pandya, D.N. (1994) Parietal, temporal, and
occipital projections to cortex of the superior temporal sulcus
in the rhesus-monkey — a retrograde tracer study. J. Comp.
Neurol., 343: 445–463.
Seung, Y., Kyong, J.S., Woo, S.H., Lee, B.T. and Lee, K.M.
(2005) Brain activation during music listening in individuals
with or without prior music training. Neurosci. Res., 52:
323–329.
Siebert, M., Markowitsch, H.J. and Bartel, P. (2003) Am-
ygdala, affect and cognition: evidence from 10 patients with
Urbach-Wiethe disease. Brain, 126: 2627–2637.
Singer, T., Seymour, B., O’Doherty, J., Kaube, H., Dolan, R.J.
and Frith, C.D. (2004) Empathy for pain involves the affec-
tive but not sensory components of pain. Science, 303:
1157–1162.
Small, D.M., Gregory, M.D., Mak, Y.E., Gitelman, D., Me-
sulam, M.M. and Parrish, T. (2003) Dissociation of neural
representation of intensity and affective valuation in human
gustation. Neuron, 39: 701–711.
Sperry, R.W. (1950) Neural basis of the spontaneous optoki-
netic response produced by visual inversion. J. Comp.
Physiol. Psychol., 43: 482–489.
Sprengelmeyer, R., Young, A.W., Schroeder, U., Grossenbac-
her, P.G., Federlein, J., Buttner, T. and Przuntek, H. (1999)
Knowing no fear. Proc. R. Soc. Lond. B Biol. Sci., 266:
2451–2456.
Stern, D.N. (2000) The Interpersonal World of the Infant. Basic
Books, New York.
Tai, Y.F., Scherﬂer, C., Brooks, D.J., Sawamoto, N. and
Castiello, U. (2004) The human premotor cortex is ‘mirror’
only for biological actions. Curr. Biol., 14: 117–120.
Tanne-Gariepy, J., Rouiller, E.M. and Boussaoud, D. (2002)
Parietal inputs to dorsal versus ventral premotor areas in the
macaque monkey: evidence for largely segregated visuomotor
pathways. Exp. Brain Res., 145: 91–103.
Umilta, M.A., Kohler, E., Gallese, V., Fogassi, L., Fadiga, L.,
Keysers, C. and Rizzolatti, G. (2001) I know what you are
doing: a neurophysiological study. Neuron, 31: 155–165.
van der Gaag, C., Minderaa, R., and Keysers, C., 2005. Emo-
tion observation, recognition and imitation: towards an un-
derstanding of empathy of individual emotions. J. Cogn.
Neurosci., Suppl S, 166. QA :11
Vogt, B.A. (2005) Pain and emotion interactions in subregions
of the cingulate gyrus. Nat. Rev. Neurosci., 6: 533–544.
Vonholst, E. and Mittelstaedt, H. (1950) Das Reafferenzprinzip
— (Wechselwirkungen Zwischen Zentralnervensystem und
Peripherie). Naturwissenschaften, 37: 464–476.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
405
Waldvogel, D., van Gelderen, P., Muellbacher, W., Ziemann,
U., Immisch, I. and Hallett, M. (2000) The relative metabolic
demand of inhibition and excitation. Nature, 406: 995–998.
Wheaton, K.J., Thompson, J.C., Syngeniotis, A., Abbott, D.F.
and Puce, A. (2004) Viewing the motion of human body parts
activates different regions of premotor, temporal, and pari-
etal cortex. Neuroimage, 22: 277–288.
Wicker, B., Keysers, C., Plailly, J., Royet, J.P., Gallese, V. and
Rizzolatti, G. (2003) Both of us disgusted in my insula: the
common neural basis of seeing and feeling disgust. Neuron,
40: 655–664.
Williams, L.M., Phillips, M.L., Brammer, M.J., Skerrett, D.,
Lagopoulos, J., Rennie, C., Bahramali, H., Olivieri, G.,
David, A.S., Peduto, A. and Gordon, E. (2001) Arousal dis-
sociates amygdala and hippocampal fear responses: evidence
from simultaneous fMRI and skin conductance recording.
Neuroimage, 14: 1070–1079.
Young, A.W., Aggleton, J.P., Hellawell, D.J., Johnson, M.,
Broks, P. and Hanley, J.R. (1995) Face Processing impair-
ments after amygdalotomy. Brain, 118: 15–24.
Zald, D.H. (2003) The human amygdala and the emotional
evaluation of sensory stimuli. Brain Res. Brain Res. Rev., 41:
88–123.
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
1
3
5
7
9
11
13
15
17
19
21
23
25
27
29
31
33
35
37
39
41
43
45
47
PBR V156 : 56021
406
