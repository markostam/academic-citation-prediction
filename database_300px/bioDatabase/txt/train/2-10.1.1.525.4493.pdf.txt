 
 
 
 
 
Discussion Paper #2007-6 
 
Multiplicity and Sensitivity of Stochastically Stable 
Equilibria in Coordination Games 
  
by  
Toshimasa Maruta and Akira Okada 
June, 2007 
 
Multiplicity and Sensitivity of Stochastically Stable Equilibria
in Coordination Games1
Toshimasa Maruta2 and Akira Okada3
June 13, 2007
Abstract: We investigate the equilibrium selection problem in n-person binary coor-
dination games by means of the adaptive play with mistakes (Young 1993). We show
that whenever the difference between the deviation losses of respective equilibria is not
overwhelming, the stochastic stability exhibits a notable dependence on payoff parameters
associated with strategy profiles where the numbers of players for the respective strategies
are nearly equal. This feature necessitates the existence of games that possess multiple
stochastically stable equilibria.
Journal of Economic Literature Classification Numbers: C70, C72, D70.
Keywords: Equilibrium selection, stochastic stability, unanimity game, coordination
game.
1Authors thank Michihiro Kandori and Daisuke Oyama for their comments on earlier versions of the paper.
2Corresponding author: Advanced Research Institute for the Sciences and Humanities and Population Re-
search Institute, Nihon University, 12-5 Goban-cho, Chiyoda, Tokyo 102–8251, Japan. E-mail: tosh@arish.nihon-
u.ac.jp Phone: +81 3 5275 9607 Fax: +81 3 5275 9204.
3Graduate School of Economics, Hitotsubashi University, 2-1 Naka, Kunitachi, Tokyo 186-8601 Japan. E-
mail: aokada@econ.hit-u.ac.jp Phone: +81 42 580 8599 Fax: +81 42 580 8748
1 Introduction
In a unanimity game, each player receives a positive payoff only when everyone plays the same
strategy. In any other strategy profile, the payoff is zero. When one of the two strict equilibria
payoff-dominates the other, it may seem natural to expect the payoff dominant equilibrium
to be the unique equilibrium selection outcome. For example, the theory of Harsanyi and
Selten (1988) fulfills this expectation, as a payoff dominant equilibrium in a unanimity game is
risk dominant. Young (1998) pointed out, however, that the expected result need not be true
in equilibrium selection by stochastic evolution. Specifically, working in a multi-population
random matching environment, Young (1998) shows that there are unanimity games with four
players in which both equilibria are stochastically stable although one of them payoff-dominates
the other in a wide margin.
At first sight, the source of the “counter-intuitive” result seems to be the non-generic
payoffs in unanimity games. Working in the adaptive play with mistakes a` la Young (1993),
we identify the source of the multiplicity. What is responsible is not payoff ties per se, but a
particular way the stochastically stable equilibrium depends on non-equilibrium payoffs that
arise at strategy profiles where the numbers of players employing the respective strategies are
nearly equal.
An example of such a dependence is the following. Consider symmetric binary four-person
games, in which the payoff of a particular strategy, A or B, is determined by the number of
players who take that strategy. In Figure 1, α and β are equilibrium payoffs. In G1, each εk is a
non-equilibrium payoff associated with A. It follows from our main result that if the difference
between α and β is not so large, then (A, . . . , A) is a unique stochastically stable equilibrium
for every εk > 0, even if α < β. Specifically, our analysis shows that the claim is true whenever
2α > β. This is a consequence from the fact that, as long as the deviation losses are relatively
close, payoffs in the middle range of the table have a decisive effect on the stochastic stability.
Similarly in G2, (B, . . . , B) is uniquely stochastically stable provided 2β > α and εk > 0. By
continuity, the multiplicity follows in the limiting unanimity game.
A related point can be made in terms of the “mistake-counting” argument in a simple
adjustment scenario that is solely based on the stage game best response. In G1, let the initial
state be (B, . . . , B). If one of the players makes a mistake, all the others can switch to A. By
contrast, just one mistake is not enough if the initial state is (A, . . . , A). This is just a rough
idea, as it does not depend on the deviation losses whatsoever. Our analysis offers conditions
under which the simple intuition agrees with the stochastic stability in the adaptive play.
1
1 2 3 4
ak 0 ε2 ε3 α
bk 0 0 0 β
G1
1 2 3 4
ak 0 0 0 α
bk 0 ε2 ε3 β
G2
Figure 1: Four-person symmetric binary coordination games.
In the next section, we specify the class of games under study and recall some relevant
aspects of the adaptive play. The main analysis is given in section three. A sufficiency result
for the stochastically stable equilibrium allows us to make the preceding argument both precise
and more general. Concluding remarks are given in the final section. The appendix gives some
of the details that are skipped in the main text.
2 Preliminaries
There are n players, denoted by i ∈ I = {1, . . . , n}, n ≥ 3. Each player chooses her strategy
σi ∈ {A,B}. A generic strategy profile is denoted by σ ∈ Σ = {A,B}n. Let |σ|X be the
number of players employing X ∈ {A,B} in σ. The payoff of player i is given as follows:
ui(σ) =
a
i
|σ|A , if σ
i = A,
bi|σ|B , if σ
i = B,
where aik and b
i
k are functions defined on {1, . . . , n} such that
(G1) aik and b
i
k are nondecreasing in k,
(G2) ain > b
i
1 and b
i
n > a
i
1.
The game thus defined is called a binary coordination game. The condition (G1) implies that
the payoff associated with a particular strategy depends only on the number of players who
adopt that strategy. By (G2), both (A, . . . , A) and (B, . . . , B) are strict equilibria. In order to
ensure that the game has exactly two strict equilibria, we introduce an additional condition.
For every i ∈ I, define ki = max{ k | bin−k > aik+1 }. Let Figure 2 depict payoff parameters
of a particular player i ∈ I. Then the number ki is m − 1. Let k = |σ−i|A be the number
of others adopting A and BRi(·) be the pure best response correspondence. It follows that
2
q
bn
qa1
aaaa


qbn−1
qa2
Q
Q
Q
Q
Q
Q
Q
Q
!!!!!!!!
qbn−m+1
qam
HHHH

qam+1q
bn−m



hhhhhhhh
q
an−m
q bm+1
((((
XXXX
q
an−m+1
q bm




hhhhhhhh
qan−1
qb2
((((
hhhh
qan
qb1
0 1 m− 1 m n−m− 1 n−m n− 2 n− 1· · · · · · · · ·
Number of others who play A
Figure 2: Payoff parameters in an n-person simple binary coordination game.
BRi(σ) = {B} if k ≤ ki and A ∈ BRi(σ) otherwise. Note that 0 ≤ ki ≤ n − 2 for every ∈ I.
For every k = 0, 1, . . . , n− 2, let
I(k) =
{
i ∈ I | ki ≤ k } , I(k) = { i ∈ I | ki ≥ k } , I(k) = { i ∈ I | ki = k } .
I(k) is the set of players with threshold ki less than or equal to k. Similarly for the other two.
The additional condition concerns the distribution of these thresholds.
(G3) If there is k, 2 ≤ k ≤ n− 2, such that |I(k − 2)| = k, then I(k − 1) 6= ∅.
Roughly speaking, (G3) implies that the thresholds may differ across players, but they can do
so only in a “connected” way.1 A simple binary coordination game is a binary coordination
game that satisfies (G3). For every σ ∈ Σ and X ∈ {A,B}, let IX(σ) =
{
i ∈ I | σi = X }.
Lemma 1. A simple binary coordination game has exactly two strict equilibria.
Proof. Let σ ∈ Σ be a strategy profile such that |σ|A = k. By (G2), if k = 1 or k = n−1, then
σ is not an equilibrium. Thus assume that 2 ≤ k ≤ n − 2 and that σ is a strict equilibrium.
Then one can verify that IA(σ) = I(k−2) and that IB(σ) = I(k). It follows that |I(k−2)| = k,
2 ≤ k ≤ n− 2, and I = I(k − 2) ∪ I(k), which contradict (G3).
It should be noted that for a binary coordination game without multiple best responses,2
(G3) is a necessary condition for the game to possess exactly two equilibria. Take such a game
1It is clear that (G3) is a generalization of the symmetric payoff assumption.
2A binary coordination game involves no multiple best responses if and only if BRi(σ) = {A} whenever
|σ−i|A > ki.
3
and assume that there is k, 2 ≤ k ≤ n − 2, such that |I(k − 2)| = k and I = I(k − 2) ∪ I(k).
Then the strategy profile σ such that IA(σ) = I(k − 2) is a strict equilibrium.
Following Harsanyi and Selten (1988), let us call αi = ain − bi1 the deviation loss of i ∈ I
at equilibrium (A, . . . , A). The deviation loss at (B, . . . , B) is βi = bin − ai1.
As an equilibrium selection model, we employ the adaptive play with mistakes, introduced
by Young (1993). We assume that the reader is familiar to the stochastic stability analysis in
general, and the adaptive play with or without mistakes in particular. For details, the reader
is referred to Young (1993). The sizes of a history and of a sample are denoted by T and
s, respectively. Let A and B denote the T -fold concatenations of (A, . . . , A) and (B, . . . , B).
We assume that s ≤ T/2. In section A.1 in the appendix, we show that in a simple binary
coordination game the adaptive play without mistakes converges to either A or B whenever
s ≤ T/2. Therefore the method of Young (1993) to identify the stochastically stable equilibrium
is applicable in the simplest manner.3 The resistance from A to B is denoted by r(A,B).
r(B,A) is the resistance for the other direction. (A, . . . , A) is uniquely stochastically stable if
and only if r(A,B) > r(B,A).
3 Equilibrium Selection
3.1 The Relevant Linear Program and the Main Result
Consider the adaptive play with mistakes for a simple binary coordination game. The current
state is A. In any path from A to B, there is a player who optimally chooses strategy B
for the first time. Let us call that player a first exitor. The first exitor i ∈ I must have a
sample against which playing B is optimal. Such a sample must contain considerable number
of Bs played by others. Since player i is a first exitor, all such Bs are mistakes. We are going
to set up a linear program that gives us the minimum number of Bs that i must face. Its
optimal solution not only gives us the number, but also reveals the way the mistakes occur. In
many-person games, not only the number, but also the distribution of mistakes matters. The
linear program introduced below takes care of the case in point.
Fix a player i ∈ I. Set
zik = a
i
n − ain−k + bik+1 − bi1
3If we drop (G3), then not only the game may have more than two strict equilibria, but also the adaptive
play without mistakes may not converge to any strict equilibrium state. See the example given in section A.1.
On the other hand, the results in the next section apply to any binary coordination game as long as it has
exactly two strict equilibria, to which the adaptive play without mistakes converges.
4
for k = 1, . . . , n− 1. Note that zik is nonnegative and nondecreasing in k. The relevant linear
program is given as follows:
(PiA) minx1 + 2x2 + · · ·+ (n− 1)xn−1
s.t. x1 + · · ·+ xn−1 ≤ s,
∑n−1
k=1 z
i
kxk ≥ s(ain − bi1), xk ≥ 0.
In this program, xk is the number of profiles that contain exactly k mistakes.
∑
k xk is the
number of profiles that contain at least one mistake. The first constraint comes from the fact
that this number cannot exceed the sample size. The second constraint expands into
binxn−1 + · · ·+ bi2x1 + (s−
∑n−1
k=1 xk)b
i
1 ≥ ai1xn−1 + · · ·+ ain−1x1 + (s−
∑n−1
k=1 xk)a
i
n.
Thus it ensures that strategy B is a best response against the sample. The objective function
gives the total number of mistakes in the sample. It is clear that (PiA) has an optimal solution.
The stochastic stability analysis hinges on the number of mistakes. Do we need additional
integer constraints? For our purposes, we do not need them, as we only need the following
implications. By the definition of the first exitor, if the optimal value of (PiA) is at least v for
every i ∈ I, then v is a lower bound of the resistance r(A,B). If the optimal value of (PiA) is
strictly greater than v for every i ∈ I, then the resistance r(A,B) is strictly greater than v.4
We are ready to show the main result of the paper.
Theorem. Consider an n-person simple binary coordination game. If there is a positive integer
m such that
(A1) m ∈ arg min
k
zik 6=0
k
zik
, (A2) m ≤ n− 1
2
, (A3) aim+1 ≥ bin−m
are satisfied for every i ∈ I, then (A, . . . , A) is stochastically stable. If (A3) is satisfied by a
strict inequality, then (A, . . . , A) is a unique stochastically stable equilibrium.
Proof. The result is a consequence of the following facts.
(1) Under (A2) and (A3), the resistance from (B, . . . B) to (A, . . . A) is at most sm.
(2) Under (A1), (A2) and (A3), the optimal value of (PiA) is at least sm for every i ∈ I. If
(A3) is strengthened to a strict inequality, the optimal value is strictly greater than sm.
4In general, the resistance r(A,B) need not be the value of the optimal integer solution of some (PiA).
5
Phase 1 Phase 2 Phase 3 Phase 4
T︷ ︸︸ ︷ s︷ ︸︸ ︷ s︷ ︸︸ ︷ s︷ ︸︸ ︷
σ1 B · · · B A∗ · · · A∗ B · · · B A · · · A
...
... · · ·
...
... · · ·
...
... · · ·
...
... · · ·
...
σm B · · · B A∗ · · · A∗ B · · · B A · · · A
σm+1 B · · · B B · · · B A · · · A A · · · A
...
... · · ·
...
... · · ·
...
... · · ·
...
... · · ·
...
σn B · · · B B · · · B A · · · A A · · · A
Figure 3: A path from B to A.
To prove (1), it suffices to construct a path from B to A in which there are exactly sm
mistakes. See Figure 3. In Phase 2, let every player sample Phase 1. There are exactly sm
mistakes in Phase 2. Let i ∈ {1, . . . ,m} and j ∈ {m+1, . . . , n}. In Phase 3, let j sample Phase
2. Then A is a best response for j by (A3). In Phase 4, let i sample Phase 3. Then respective
strategies yield ain−m+1 and bim. By (A2), n −m ≥ m. Therefore (A3) and (G1) imply that
ain−m+1 ≥ aim+1 ≥ bin−m ≥ bim, which allows i to choose A. Letting j sample the final available
segment of Phase 2 and the initial segment of Phase 4, we make her choose A in Phase 4 as
well. Finally, note that these sample assignments are possible as long as s ≤ T/2.
To prove (2), pick i ∈ I and let (x1, . . . , xn−1) be an optimal solution of (PiA). By (A1),
mzikxk ≤ kzimxk
for every k = 1, . . . , n− 1. Assume for the contrary that the optimal value is smaller than sm.
Then
m
∑
k z
i
kxk ≤ zim
∑
k kxk < z
i
msm.
Therefore
∑
k z
i
kxk < sz
i
m. On the other hand, the best response constraint in (P
i
A) dictates
that
∑
k z
i
kxk ≥ s(ain − bi1). Hence ain − bi1 < zim, or ain−m < bim+1. It follows from (A2)
that n −m ≥ m + 1. Thus the preceding strict inequality contradicts (A3) and (G1) since
ain−m ≥ aim+1 ≥ bin−m ≥ bim+1. The claim for the unique selection can be proved similarly.
Figure 2 should help us better understand the implications of the conditions. (A3) implies
that ki ≤ m − 1 for every i ∈ I. (A2) and (A3) imply that the graph of A and the graph of
B intersects in the left half of the domain. One might say that strategy A has the larger basin
of attraction in this case. In many-person games, (A, . . . , A) needs an additional condition
6
to become stochastically stable.5 The condition (A1) is deeply related to the relevant linear
program. The fractions to be minimized appear as the relative cost coefficients in the simplex
algorithm. If m is a unique minimizer in (A1), then (A1) through (A3) imply that in any
optimal solution of (PiA) the sample size constraint binds and the solution typically contains
at least two non-zero entries.6 This means that the program admits no simple solution that is
analogous to those found in two-person games.
3.2 Sensitivity of Stochastic Stability on Payoffs in the “Middle”
It is clear that there are ranges for payoff parameters within which all the conditions in the
preceding theorem are satisfied. A set of conditions below is particularly useful in revealing
the sensitivity of the stochastic stability on payoffs at strategy profiles where the numbers of
players for the respective strategies are nearly equal.
Proposition 1. Consider an n-person simple binary coordination game. If there is a positive
integer m ≤ (n − 1)/2 such that the following conditions are satisfied for every i ∈ I, then
(A, . . . , A) is a unique stochastically stable equilibrium:
(1.1) βi <
(n−m− 1)αi
m
.
(1.2) aim+1 > b
i
n−m.
(1.3) There exists γi ∈ (bin−m, aim+1) such that for every k 6= n− 1,
ain−k > γ
i +
(m− k)αi
2m
and bik+1 < γ
i − (m− k)α
i
2m
.
A sketch of the proof follows. (1.1) and (1.3) imply that mzik < kα
i for k 6= m. Pick
sufficiently small εi > 0 such that mzik ≤ k(αi−εi) for every k. Decreasing aim+1 and increasing
bin−m appropriately and then setting aim+1 = · · · = ain−m = b
i
m+1 = · · · = bin−m, (1.2) allows us
to construct a simple binary coordination game G in which
zik =
α
i − εi, if k = m, . . . , n−m− 1,
zik, otherwise.
5One can verify that by increasing bin while keeping all the others fixed (B, . . . , B) eventually becomes a
unique stochastically stable equilibrium, provided the sample size s is not extremely small. See section A.2.
Hence the validity of the “intuition” that the stochastic stability selects an equilibrium with the largest basin
of attraction is dubious outside the class of two-by-two games, even in models with state independent mistake
(or mutation) rate.
6This follows from Proposition 3 in the appendix.
7
(n−m−1n−1 )s︷ ︸︸ ︷ ( mn−1 )s︷ ︸︸ ︷
σ1 A · · · A B∗ · · · B∗
...
... · · ·
...
... · · ·
...
σn−1 A · · · A B∗ · · · B∗
σn A · · · A A · · · A
Sample 1
s︷ ︸︸ ︷
σ1 B∗ · · · B∗
...
... · · ·
...
σm B∗ · · · B∗
σm+1 A · · · A
...
... · · ·
...
σn A · · · A
Sample 2
Figure 4: Samples in the adaptive play with mistakes.
It follows that G satisfies (A1) to (A3). By (2) in the proof of the main result, every feasible
solution of (PiA) has a value greater than sm. Since z
i
k ≥ zik, every feasible solution of (PiA)
is feasible in (PiA). Therefore every feasible solution of (P
i
A) has a value greater than sm. On
the other hand, m satisfies (A2) and (A3) in the original game. Thus it follows from (1) in
the proof of the main theorem that the resistance from (B, . . . B) to (A, . . . A) is at most sm.
Note that as long as (1.2) is satisfied, (1.3) places no additional restrictions on the pay-
off parameters aim+1, . . . , a
i
n−m and bim+1, . . . , bin−m. Therefore the advantage of strategy A
over strategy B can be arbitrarily small. The result shows that any slight advantage in the
“middle” can compensate a disadvantage near equilibrium whenever the disadvantage is not
overwhelming. It generalizes the argument given in the introduction.
Figure 4 illustrates how Proposition 1 works. By (1.1), sample 1 in Figure 4 does not have
enough mistakes to make player n switch. Neither does sample 2, since bim+1 < a
i
n−m by (1.2).
Note that these samples contain sm mistakes. On the other hand, in the proof of the main
theorem we saw that the phase 2 in Figure 3, which also contains sm mistakes, can reach A.
3.3 Multiplicity of Stochastically Stable Equilibria
Interchanging aik and b
i
k and replacing z
i
k with w
i
k = b
i
n − bin−k + aik+1 − ai1, the main theorem
generates a set of conditions that ensures the stochastic stability of (B, . . . , B). If all the con-
ditions for respective equilibria are satisfied within a single game, then multiple stochastically
stable equilibria arise.
An n-person simple binary coordination game is said to possess m-indifference property if
for every i ∈ I both A and B are best responses against σ ∈ Σ whenever there are at least m
others who play A and at least m others who play B. An equivalent condition is given in (2.2)
8
below. A unanimity game is a simple binary coordination game with 1-indifference property
with additional conditions that ai1 = a
i
n−1 and bi1 = bin−1 for every i ∈ I.
Proposition 2. Consider an n-person simple binary coordination game. If there are a positive
integer m < (n−1)/2 and real numbers γi ∈ [bi1, ain)∩ [ai1, bin) such that the following conditions
are satisfied for every i ∈ I, then both (A, . . . , A) and (B, . . . , B) are stochastically stable:
(2.1) βi ≤ (n−m− 1)α
i
m
and αi ≤ (n−m− 1)β
i
m
.
(2.2) bim+1 = · · · = bin−m = aim+1 = · · · = ain−m = γi.
(2.3) For the remaining parameters k = 1, . . . ,m− 1, n−m, . . . , n− 2,
ain−k ∈
[
γi + (m−k)α
i
2m , γ
i + (n−m−k−1)β
i
2m
]
, bik+1 ∈
[
γi − (n−m−k−1)βi2m , γi − (m−k)α
i
2m
]
.
For games with 1-indifference property, (2.3) can be simply dropped.
In this result, payoff parameters should satisfy twice as many conditions as those in Propo-
sition 1. Here again, (2.1) and (2.3) take care of conditions (A1) and (B1)7. A special care
must be taken, however, for the consistency of (2.1) and (2.3). At this point, the condition
that m < (n − 1)/2 comes in. Without it, (2.1) may become trivial. Moreover, it implies
that each interval in (2.3) has nonempty interior, and that the minimum of the interval for
ain−k (b
i
k+1, respectively) is strictly less than the maximum of the interval for a
i
n−k+1 (b
i
k+2,
respectively). The latter implication makes sure that the intervals are distributed in such a
way that is consistent with (G1).
There are other classes of games in which non-trivial multiplicity may arise. An (n, l)-
coordination game, where l > n/2, is an n-person simple binary coordination game with non-
negative payoffs such that a particular strategy yields a positive payoff if and only if there are
at least l− 1 others who play the same. Such a game can be a natural model of collective deci-
sion making. Proposition 2 is not applicable to (n, l)-coordination games as payoff ties extend
asymmetrically around the center. Invoking the main result directly, however, one can show
that an (n, l)-coordination game can possess non-trivial multiple stochastically stable equilibria
if and only if l > (n+ 3)/2.
7The counterpart condition of (A1) for the stochastic stability of (B. . . . , B).
9
4 Concluding Remarks
We have shown equilibrium selection results under which the multiplicity of stochastically
stable equilibria can be understood as a consequence of its particular form of dependence
on non-equilibrium payoffs. Given an m-indifferent simple binary coordination game with
multiple stochastically stable equilibria, Proposition 1 implies that each neighborhood of the
game contains a game in which (A, . . . , A) is uniquely stochastically stable and another in
which (B, . . . , B) is uniquely stochastically stable. As a correspondence, the stochastically
stable equilibrium is upper hemicontinuous but not lower hemicontinuous.8
In one of the rare studies that focus on the equilibrium selection in a many-person stage
game, Kim (1996) obtains, among other things, a unique equilibrium selection for a symmetric
n-person binary coordination game by means of the stochastic stability. Following Kandori,
Mailath, and Rob (1993), he works in a single population random matching environment. The
source of the difference between his result and ours should be found in the difference between
the respective equilibrium selection dynamics.9 In the adaptive play with mistakes, a state
is a finite sequence of stage game strategy profiles. The whole state space can be naturally
embedded into the mixed strategy space of the stage game. The crucial property is that
the range is full dimensional, in that it includes every extreme point in the mixed strategy
space. In the single population random matching model, by contrast, the range of the natural
embedding is single dimensional. In particular, the range includes just two extreme points,
the two unanimous pure strategy profiles. A consequence is that some features that the best
response structure of the stage game possesses may simply disappear. For this reason, neither
the presence of multiple best responses in unanimity games nor the mistake counting argument
in Figure 4 has any implication in the model.10,11 This observation should also convince us
the reason why Young (1998) finds the multiplicity: the state space of the multi-population
random matching is full dimensional.12
8This feature reminds us of the equilibrium refinement literature. See, for example, Okada (1981).
9Combining the result of Kim (1996) and ours, it follows that a simple binary coordination game that satisfies
all the conditions of Proposition 2 is an example of games for which Kandori et al. (1993) and Young (1993)
produce different selection outcomes. Jacobsen et al. (2000) find two-person coordination games on which the
selection outcomes of the two models differ.
10As Kim (1996) suggests, it may well be the case that the “intuition” mentioned in footnote 5 is valid for
single population models.
11Concerning the stability properties of versions of the replicator dynamics, Weibull (1995) discusses the
difference between the single population model and the multi-population model.
12Thus, results analogous to ours should hold true in the multi-population random matching model.
10
Unexpected results in binary coordination games are not specific to the stochastic evolu-
tion literature. Morris and Ui (2005) and Oyama, Takahashi, and Hofbauer (2005) generalize
previous results in equilibrium selection, respectively, by robustness with respect to incomplete
information (Kajii and Morris 1997) and by perfect foresight dynamics (Matsui and Matsuyama
1995). Even for unanimity games, however, no clear-cut results have been shown. Meanwhile,
Hofbauer (1999) offers a dynamic selection model in which the risk dominant equilibrium (in
the sense of Harsanyi and Selten 1988) is selected in n-person unanimity games.
One might be inclined to think that binary coordination games are particularly simple
class of games. As far as equilibrium selection is concerned, such a view may be ill-founded.
Appendix
A.1 Convergence in the adaptive play
For convenience, we collect relevant definitions and properties.
• ki = max{ k | bin−k > aik+1 }. Recall that 0 ≤ ki ≤ n− 2.
• For σ ∈ Σ such that |σ−i|A = k, BRi(σ) = {B} if k ≤ ki and A ∈ BRi(σ) if k > ki.
• For every k = 0, 1, . . . , n− 2,
I(k) =
{
i ∈ I | ki ≤ k } , I(k) = { i ∈ I | ki ≥ k } , I(k) = { i ∈ I | ki = k } .
• For every σ ∈ Σ, IA(σ) =
{
i ∈ I | σi = A} and IB(σ) = { i ∈ I | σi = B }.
• A simple binary coordination game is a binary coordination game satisfying
(G3) If there is k, 2 ≤ k ≤ n− 2, such that |I(k − 2)| = k, then I(k − 1) 6= ∅.
Recall that T and s are the history size and the sample size of the adaptive play. Adaptive
play without mistakes is absorbing if, starting from any state, the play can reach a strict
equilibrium state in a finite number of steps.
Lemma 2. Adaptive play without mistakes for a simple binary coordination game is absorbing
if T = 2 and s = 1.
11
Proof. Consider the adaptive play with (T, s) = (2, 1). Let σ ∈ Σ be the sample given to i ∈ I
on a particular day. To avoid ambiguities caused by multiple best responses, let the player
choose B if and only if B is a unique best response against σ. Formally,
bri(σ) =
A, if i ∈ I(k − 1),B, if i ∈ I(k), (?)
where k = |σ−i|A, the number of others that adopt A. Clearly, bri(σ) ∈ BRi(σ).
Pick σ1 ∈ Σ. Starting from σ1, we construct a path that leads to either (A, . . . , A) or
(B, . . . , B). Set |σ1|A = k1 so that
σ1 = (
k1︷ ︸︸ ︷
A, . . . , A,B, . . . , B).
We can assume that 1 ≤ k1 ≤ n − 1. On day 2, let everyone sample σ1. Following (?), they
play σi2 = br
i(σ1). The outcome of day 2 is σ2. By construction,
• For every i ∈ I(k1 − 2), i ∈ IA(σ2).
• For every i ∈ I(k1), i ∈ IB(σ2).
• For every i ∈ I(k1 − 1), i ∈ IA(σ2) if and only if i ∈ IB(σ1).
Thus σ2 can be written as
σ2 = (
k2︷ ︸︸ ︷
|I(k1−2)|︷ ︸︸ ︷
A, . . . , A,
|I(k1−1)∩IB(σ1)|︷ ︸︸ ︷
A, . . . . . . , A,
|I(k1−1)∩IA(σ1)|︷ ︸︸ ︷
B, . . . . . . , B,
| I(k1)|︷ ︸︸ ︷
B, . . . , B).
Case 1. k2 > k1. Following (?), let σi3 = br
i(σ2) for every i ∈ I. We show that k3 = |σ3|A > k2.
In σ2, every i ∈ I has at least k1 others playing A. Therefore i ∈ IA(σ3) for every i ∈ I(k1−1).
Hence k3 ≥ k2. If k2 ≥ n− 1, then σ3 = (A, . . . , A). Thus we can assume 2 ≤ k2 ≤ n− 2.
Claim 1: If I(k1 − 1) ∩ IA(σ1) = ∅ then I(k1) ∩ I(k2 − 1) 6= ∅.
Proof. Assume that I(k1 − 1) ∩ IA(σ1) = ∅. It follows that |I(k1 − 1)| = k2. If
I(k1) ∩ I(k2 − 2) 6= ∅, then I(k1) ∩ I(k2 − 1) 6= ∅. If I(k1) ∩ I(k2 − 2) = ∅, then
I(k2−2) = I(k1−1). Hence |I(k2−2)| = k2. Thus (G3) implies that I(k2−1) 6= ∅.
Since k2 > k1, I(k2 − 1) ⊂ I(k1). Therefore I(k1) ∩ I(k2 − 1) 6= ∅. ‖
12
It follows from Claim 1 that either I(k1− 1)∩ IA(σ1) 6= ∅ or I(k1)∩ I(k2− 1) 6= ∅. Therefore
k3 > k2. Under the sample assignment σit+1 = br
i(σt) for every i ∈ I, we have shown that
k2 > k1 implies k3 > k2. By induction, the play eventually reaches (A, . . . , A) if k2 > k1.
Case 2. k2 < k1. Following (?), let σi3 = br
i(σ2) for every i ∈ I. We show that k3 = |σ3|A < k2.
In σ2, every i ∈ I has at most k1 − 1 others playing A. Therefore i ∈ IB(σ3) for every
i ∈ I(k1 − 1). Hence k3 ≤ k2. If k2 ≤ 1, then σ3 = (B, . . . , B). Thus we can assume
2 ≤ k2 ≤ n− 2.
Claim 2: If I(k1 − 1) ∩ IB(σ1) = ∅ then I(k1 − 2) ∩ I(k2 − 1) 6= ∅.
Proof. Assume that I(k1−1)∩IB(σ1) = ∅. It follows that |I(k1−2)| = k2. Assume
thatR = I(k1−2)∩ I(k2−1) = ∅. Then I(k2−2) = I(k1−2). Hence |I(k2−2)| = k2.
Thus (G3) implies that I(k2 − 1) 6= ∅. Since k2 < k1, I(k2 − 1) ⊂ I(k1 − 2).
Therefore R = I(k1 − 2) ∩ I(k2 − 1) 6= ∅. We have shown that R = ∅ implies
R 6= ∅. This is equivalent to R 6= ∅. ‖
It follows from Claim 2 that either I(k1 − 1) ∩ IB(σ1) 6= ∅ or I(k1 − 2) ∩ I(k2 − 1) 6= ∅.
Therefore k3 < k2. Under the sample assignment σit+1 = br
i(σt) for every i ∈ I, we have shown
that k2 < k1 implies k3 < k2. By induction, the play eventually reaches (B, . . . , B) if k2 < k1.
Case 3. k2 = k1 and 2 ≤ k2 ≤ n− 2. In this case, σ2 can be written as follows.
σ2 = (
k2︷ ︸︸ ︷
|I(k2−2)|︷ ︸︸ ︷
A, . . . , A,
|I(k2−1)∩IB(σ1)|︷ ︸︸ ︷
A, . . . . . . , A,
|I(k2−1)∩IA(σ1)|︷ ︸︸ ︷
B, . . . . . . , B,
| I(k2)|︷ ︸︸ ︷
B, . . . , B).
If I(k2 − 1) = ∅, then |I(k2 − 2)| = k2. Thus (G3) implies I(k2 − 1) 6= ∅.
Let σi3 = br
i(σ2). Then
σ3 = (
k3︷ ︸︸ ︷
|I(k2−2)|︷ ︸︸ ︷
A, . . . , A,
|I(k2−1)∩IA(σ1)|︷ ︸︸ ︷
A, . . . . . . , A,
|I(k2−1)∩IB(σ1)|︷ ︸︸ ︷
B, . . . . . . , B,
| I(k2)|︷ ︸︸ ︷
B, . . . , B).
If k3 6= k2, then we can apply either Case 1 or Case 2. Thus we can assume that k3 = k2 = k1.
Then
|I(k2 − 1) ∩ IA(σ1)| = |I(k2 − 1) ∩ IB(σ1)| ≥ 1. (†)
13
The inequality follows from I(k2 − 1) 6= ∅. For every i ∈ I(k2 − 1) ∩ IA(σ1), let σi4 = bri(σ2).
For everyone else, let σi4 = br
i(σ3). Then
σ4 = (
k4︷ ︸︸ ︷
|I(k2−2)|︷ ︸︸ ︷
A, . . . , A,
|I(k2−1)∩IA(σ1)|︷ ︸︸ ︷
A, . . . . . . , A,
|I(k2−1)∩IB(σ1)|︷ ︸︸ ︷
A, . . . . . . , A,
| I(k2)|︷ ︸︸ ︷
B, . . . , B).
By (†), k4 > k2. Following (?), let σi5 = bri(σ4) for every i ∈ I. We show that k5 = |σ5|A > k4.
In σ4, every i ∈ I has at least k2 others playing A. Therefore i ∈ IA(σ5) for every i ∈ I(k2−1).
Hence k5 ≥ k4. If k4 ≥ n− 1, then σ5 = (A, . . . , A). Thus we can assume that 3 ≤ k4 ≤ n− 2.
Claim 3: If I(k2) ∩ I(k4 − 2) = ∅ then I(k2) ∩ I(k4 − 1) 6= ∅.
Proof. Assume that I(k2) ∩ I(k4 − 2) = ∅. It follows that |I(k4 − 2)| = k4. Thus
(G3) implies that I(k4 − 1) 6= ∅. Since k4 > k2, I(k4 − 1) ⊂ I(k2). Therefore
I(k2) ∩ I(k4 − 1) 6= ∅. ‖
Noting that I(k4−2) ⊂ I(k4−1), it follows from Claim 3 that I(k2)∩I(k4−1) 6= ∅. Therefore
k5 > k4, which allows us to apply Case 1 for the rest of the play.
Case 4. k2 = k1 = 1 or k2 = k1 = n− 1. Consider the first case. Then σ2 can be written as
σ2 = (A,
|I(0)∩IA(σ1)|︷ ︸︸ ︷
B, . . . . . . , B,
| I(1)|︷ ︸︸ ︷
B, . . . , B).
Letting σ13 = br
1(σ2) and σi3 = br
i(σ1) for every i 6= 1, we have σ3 = (B, . . . , B). In the second
case,
σ2 = (
|I(n−3)|︷ ︸︸ ︷
A, . . . , A,
|I(n−2)∩IB(σ1)|︷ ︸︸ ︷
A, . . . . . . , A, B).
Letting σn3 = br
n(σ2) and σi3 = br
i(σ1) for every i 6= n, we have σ3 = (A, . . . , A).
Lemma 3. Adaptive play without mistakes for a simple binary coordination game is absorbing
if s ≤ T/2.
Proof. Consider the adaptive play in which s ≤ T/2. Fix an initial state, an arbitrary sequence
in Σ with length T . Let it be day 1. On day 1 through day s, let everyone sample the outcomes
from day −s + 1 through day zero and play best response. The assignment is possible since
s ≤ T/2. We can assume that players choose the same strategy throughout Phase 1, which
consists of day 1 through day s. Phase 1 results in the s-run of σ1 ∈ Σ.
14
In the adaptive play with (T, s) = (2, 1), there is a path from σ1 that eventually leads
either (A, . . . , A) or (B, . . . , B). It suffices to replicate the sequence in the adaptive play with
the current setting. Among cases appeared in the proof of Lemma 2, the replication is obvious
unless k1 = k2 = k3. Take σ1, . . . , σ4 that appeared in Case 3 in the proof of Lemma 2, where
k1 = k2 = k3. Let Phase k be the s-run of σk, k = 1, 2, 3, and let Phase 3 follow Phase 2, which
follows Phase 1.
Next s dates consist Phase 4. It suffices to show that it can be the s-run of σ4. Throughout
Phase 4, let every i ∈ I(k2 − 1) ∩ IA(σ1) sample the final available segment of Phase 2 and
the initial available segment of Phase 4. Let everyone else sample the entire Phase 3. These
sample assignments are possible since s ≤ T/2.
It is clear that every i /∈ I(k2 − 1) ∩ IA(σ1) plays σi4 throughout Phase 4. On first day
in Phase 4, i ∈ I(k2 − 1) ∩ IA(σ1) observes the s-run of σ2. Thus she can play A. Hence the
outcome of the first day in Phase 4 can be σ4. On t-th day in Phase 4, inductively, i observes
the s− t+ 1-run of σ2 and the t− 1-run of σ4. Since A ∈ BRi(σ2) ∩BRi(σ4), she plays A on
day t. Consequently, Phase 4 can come out as the s-run of σ4.
In section 2 we remarked that a binary coordination game without (G3) may have a third
strict equilibrium. Moreover, games without (G3) need not possess the desirable convergence
property in the adaptive play.
Example 1. Let players i = 1, 2 have payoff function u in Figure 5. Let player i = 3 have payoff
function w in the Figure. Let players i = 4, 5 have payoff function v in the Figure. It follows
that (k1, k2, k3, k4, k5) = (0, 0, 0, 3, 3). Since |I(3 − 2)| = 3, (G3) is violated. Nonetheless the
five-person game has exactly two strict equilibria, because player 3 has a unique best response
only if all the others are making a unanimous choice. Now consider the strategy profiles
(A,A,A,B,B) and (A,A,B,B,B). Each is a non-strict equilibrium, in which all players but 3
are playing their unique best responses. It is clear that all the states consisting solely of these
equilibria form a non-singleton recurrent class in the adaptive play.
A.2 Simple optimal solutions in the relevant program
The next result characterizes the conditions under which (PiA) admits a simple optimal solution.
Proposition 3. Consider the program (PiA) of a player i ∈ I in a binary coordination game.
Denote by λ1 and λ2 the Lagrange multipliers for the best response constraint and the sample
size constraint, respectively. The following conditions are equivalent:
15
1 2 3 4 5
ak 0 ε2 ε3 ε4 α
bk 0 0 0 0 β
u
1 2 3 4 5
ak 0 0 0 0 α
bk 0 ε2 ε3 ε4 β
v
1 2 3 4 5
ak 0 0 0 0 α
bk 0 0 0 0 β
w
Figure 5: Payoffs in a five-person game, in which 0 < ε2 < ε3 < ε4 < min{α, β}.
(1) There is k∗ ∈ arg min
k
zik 6=0
k
zik
such that bik∗+1 ≥ ain−k∗.
(2) There is an optimal solution in which λ2 = 0.
(3) The solution
(x∗1, . . . , x
∗
n−1 : λ
∗
1, λ
∗
2) =
( k∗︷ ︸︸ ︷
0, . . . , 0,
s(ain − bi1)
zik∗
, 0, . . . , 0 :
k∗
zik∗
, 0
)
is optimal.
Proof. Since (3) implies (2), it suffices to show that (2) implies (1) and that (1) implies (3). In
this proof, we omit superscripts for an arbitrarily chosen i ∈ I. We invoke the duality theorem.
Note that the dual program of (PiA) is given by
max s(an − b1)λ1 − sλ2
s.t. z1λ1 − λ2 ≤ 1, . . . , zkλ1 − λ2 ≤ k, . . . , zn−1λ1 − λ2 ≤ n− 1,
together with the nonnegativity condition λ1 ≥ 0 and λ2 ≥ 0.
Assuming (2), we show (1). Take an optimal solution with λ2 = 0. Then by dual feasibility,
zkλ1 ≤ k. Thus λ1 ≤ k/zk for every zk 6= 0. By complementary slackness, zkλ1 = k for every
k such that xk 6= 0. In particular, zk > 0 for every such k. Therefore
λ1 = min
k
zk 6=0
k
zk
> 0.
Let
arg min
k
zk 6=0
k
zk
= {k1, . . . kl}.
Assume that bikj+1 < a
i
n−kj for every j = 1, . . . , l. Then zkj < an − b1. Thus
zk1xk1 + · · ·+ zklxkl < (an − b1)xk1 + · · ·+ (an − b1)xkl
16
= (an − b1)(x1 + · · ·+ xn) ≤ s(an − b1).
Therefore
∑
k zkxk < s(an − b1) since xk > 0 implies k = kj for some j = 1, . . . , l. But
this contradicts the complementary slackness since λ1 > 0. Therefore there is k∗ such that
k∗/zk∗ = mink,zk 6=0 k/zk and b
i
k∗+1 ≥ ain−k∗ .
Assuming (1), we show (3). Consider the solution given in (3). Nonnegativity constraints
are all satisfied. Since bk∗+1 ≥ an−k∗ , zk∗ ≥ an−b1, which implies xk∗ ≤ s. Thus (x1, . . . , xn−1)
is primal feasible. Since λ∗2 = 0, the dual constraint is given by zkλ∗1 ≤ k, which is satisfied by
the definition of λ∗1. Thus (λ∗1, λ∗2) is dual feasible. It is straightforward to verify complementary
slackness. Thus the solution is optimal by the duality theorem.
Interchanging aik and b
i
k and replacing z
i
k with w
i
k = b
i
n − bin−k + aik+1 − ai1, the result
generates the conditions for the program (PiB).
The result allows us to justify the claim made in footnote 5. Consider a simple binary
coordination game that satisfies (A1), (A2), and (A3) with strict inequality. Let the param-
eters of the game be (aik, b
i
k). Consider another game (a
i
k, b
i
k) in which b
i
n = b
i
n + ξ but all the
others remain unchanged. Let us verify that increasing ξ > 0 eventually results in a game in
which (B, . . . , B) is a unique stochastically stable equilibrium, provided the sample size s is
not extremely small.
If ξ is sufficiently large, then
{n− 1} = arg min
k
zik 6=0
k
zik
and {1} = arg min
k
wik 6=0
k
wik
.
In fact, the former is obvious since bin appears only in z
i
n−1. For the latter, it suffices to pick
ξ > max
{
(wik − kwi1)/(k − 1) | k 6= 1, wik − kwi1 > 0
}
whenever the set is non-empty.
By Proposition 3, the optimal value of (PiA) is given by s(n − 1)(ain − bi1)/zin−1. Taking
the integer constraint and the non-first exitors into account, we obtain
r(A,B) ≤ n
⌈
(ain − bi1)s
zin−1
⌉
= n
⌈
sαi
αi + βi
⌉
.
Concerning (PiB), Proposition 3 implies that
min
{⌈
sβi
βi + ai2 − bin−1
⌉
, s
}
≤ r(B,A).
If ξ is sufficiently large so that
nαi
αi + βi
< min
{
βi
βi + ai2 − bin−1
, 1
}
,
17
then r(A,B) < r(B,A) as long as s is large enough to preserve the strict inequality after the
rounding. The argument also shows that if s is extremely small, such as s = 1, then the
stochastic stability does not depend at all on the magnitudes of the deviation losses. In such
a case, the model is essentially equivalent to the simple mistake counting model mentioned in
the fourth paragraph of section 1.
References
Harsanyi, J.C. and R. Selten (1988). A General Theory of Equilibrium Selection in Games, Cambridge:
MIT Press.
Hofbauer, J. (1999). “The spatially dominant equilibrium of a game,” Annals of Operations Research,
89:233–251.
Jacobsen, H.J., M. Jensen, B. Sloth (2000). “KMR and Young processes select different equilibria: Two
examples,” mimeo.
Kajii, A. and S. Morris (1997). “The robustness of equilibria to incomplete information,” Econometrica,
65: 1283-1309.
Kandori, M., G. Mailath, and R. Rob (1993). “Learning, mutation and long-run equilibria in games,”
Econometrica, 61: 29–56.
Kim, Y. (1996). “Equilibrium selection in n-person coordination games,” Games and Economic Behav-
ior , 15: 203–227.
Matsui, A. and K. Matsuyama (1995). “An approach to equilibrium selection,” Journal of Economic
Theory , 65: 415-434.
Morris, S. and T. Ui (2005). “Generalized potentials and robust sets of equilibria,” Journal of Economic
Theory , 124: 45-78.
Okada, A. (1981). “On stability of perfect equilibrium points,” International Journal of Game Theory ,
10: 67-73.
Oyama, D., S. Takahashi, and J. Hofbauer (2005), “Monotone methods for equilibrium selection under
perfect foresight dynamics,” mimeo.
Weibull, J. (1995). Evolutionary Game Theory , Cambridge: MIT Press.
Young, P.H. (1993). “The evolution of conventions,” Econometrica, 61: 57–84.
Young, P.H. (1998). “Conventional contracts,” Review of Economic Studies, 65: 776–792.
18
