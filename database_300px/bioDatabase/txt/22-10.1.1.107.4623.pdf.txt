Game-Theoretic Analysis of Cooperation Among Supply Chain Agents: Review
and Extensions
Mahesh Nagarajan • Greys Sosˇic´
Sauder School of Business, University of British Columbia, Vancouver, B.C., Canada V6T 1Z2
Marshall School of Business, University of Southern California, Los Angeles, California 90089
mahesh.nagarajan@sauder.ubc.ca • sosic@marshall.usc.edu
August 2005; Revised May 2006;
Accepted for publication in European Journal of Operational Research, May 2006
Abstract
This paper surveys some applications of cooperative game theory to supply chain management.
Special emphasis is placed on two important aspects of cooperative games: profit allocation and
stability. The paper first describes the construction of the set of feasible outcomes in commonly seen
supply chain models, and then uses cooperative bargaining models to find allocations of the profit pie
between supply chain partners. In doing so, several models are analyzed and surveyed, and include
suppliers selling to competing retailers, and assemblers negotiating with component manufacturers
selling complementary components. The second part of the paper discusses the issue of coalition
formation among supply chain partners. An exhaustive survey of commonly used stability concepts
is presented. Further, new ideas such as farsightedness among supply chain players are also discussed
and analyzed. The paper also opens some avenues of future research in applying cooperative game
theory to supply chain management.
Keywords: Supply chain management, Cooperative game theory, Bargaining, Coalitions
1. Introduction
Traditional research in operations management focused on providing tools and recipes to help decision
makers with tactical operational decisions. These include production planning, capacity investment and
allocation, inventory decisions on how much (quantity) and where (location) to produce, procure and
store, shipment schedules, and more recently, joint pricing and inventory decisions as well. The tools
used in analyzing these problems largely relied upon dynamic programming and other optimization tech-
niques. This stream of research was fruitful in providing practitioners a variety of algorithms designed
to compute optimal quantities, schedules, etc., as well as provide theoretical insights to researchers.
In the last several years, the evolution of supply chain management recognized that (i) a business
process consists of several decentralized firms and (ii) operational decisions of these different entities
impact each others’ profit, and thus the profit of the whole supply chain. With this understanding came
a great deal of interest in modeling and understanding the impact of strategic operational decisions of
the various players in supply chains. To effectively model and analyze decision making in such multi-
person situation where the outcome depends on the choice made by every party, game theory is a natural
choice. Researchers in supply chain management now use tools from game theory and economics to
understand, predict, and help managers to make strategic operational decisions in complex multi-agent
supply chain systems.
Loosely speaking, game theory models situations where players make decisions to maximize their
own utility, while taking into account that other players are doing the same and that decisions made by
players impact each others utilities. There is a broad division of game theory into two approaches: the
cooperative and the noncooperative approach. These approaches, though different in their theoretical
content and the methodology used in their analysis, are really just two different ways of looking at
the same problem. To quote the words of Aumann: “the game is one ideal and the cooperative and
noncooperative approaches are two shadows”.
The noncooperative theory of games is strategy oriented – i.e., it studies what one may expect the
players to do and the nitty-gritty details of how they get there. Cooperative game theory, on the other
hand, takes a different tack. It directly looks at the set of possible outcomes, studies what the players
can achieve, what coalitions will form, how the coalitions that do form divide the outcome, and whether
the outcomes are stable and robust. Thus, one may say that the noncooperative theory is a micro
approach in that it focuses on precise descriptions of what happens.
The field of supply chain management has seen, in recent years, a wide variety of research papers
that employ noncooperative game theory to model interaction between players. For an excellent survey
and state of art techniques, we refer you to Cachon and Netessine (2004). The use of cooperative game
theory is, however, much less prevalent. In this paper, we review the existing literature on applications
of cooperative games to supply chain management. In doing so, we also shed some light on certain
methodological issues when modeling supply chain problems and possible areas for future research.
This paper focuses on applications in supply chains with two central themes of cooperative games.
The first theme is that of feasible outcomes. Feasible outcomes represent the total set of all possible
outcomes that players may realize, even if, for instance, they may not be incentive compatible for
them. Identifying this set and its properties is an important step. Once this set is established and
1
defined, one moves to the question of how players actually end up with an outcome from this feasible
set. Cooperative game theory offers several recipes for this process. One such important application
is bargaining between the players. In this study, we focus extensively on bargaining games and their
implications to supply chains.
Yet another important theme is that of stability. When players decide on allocations from the set of
feasible outcomes, independent of the process (for instance bargaining), some or all players can pursue
options such as joining together as a coalition and agreeing on a joint course of action. Two questions
immediately raise themselves: (i) How will players in an alliance divide the gains accrued by their joint
venture?, and (ii) what are the stable coalitions/outcomes that emerge in a particular setting?
We wish to point out that there are several areas of cooperative games that lend very nicely to
applications in supply chains, that we do not review in this paper. Our focus in this paper, as mentioned,
is merely on two concepts, negotiation in simple supply chains and profit sharing and alliance formations.
Typically, our analysis looks at two echelons with a few supplier selling to downstream buyers. Clearly,
supply chains in today’s world can be more complex than the ones in our examples. A very important
area that we do not discuss in this review is profit/cost allocation in more general supply chain networks.
Analyzing supply chain networks is an important research area, especially due to the current impetus
towards information sharing, collaborative planning and forecasting, capacity sharing contracts etc.
Cooperative game theory can be used to analyze general supply chain networks. For theoretical issues
and a framework for this analysis, we refer you to Slikker and van den Nouweland (2001).
The two topics that we analyze are fairly common place in business settings. First, our use of
a negotiation approach to understand certain contracting and profit sharing issues is not farfetched.
Indeed, anecdotal evidence and articles in the academic literature have overwhelmingly indicated that
contractual relationships between agents in a supply chain are characterized by negotiating over terms
of the trade. Sellers and buyers often negotiate price, quantity, delivery schedules, etc. Bajary et al.
(2002) argue that in the construction industry 43% of all projects are awarded using negotiation, while
the rest use some form of auction. They find that supplier reputation, complexity of the project, and
the absence of a large supplier base are positive determinants for negotiations to be preferred over other
mechanisms. Bonaccorsi et al. (2000) claim that in medical procurement, negotiation is often the norm
when quality is uncertain. The Taiwanese semiconductor industry association (TSIA, www.tsia.org)
reports that over a third of all contractual terms between its members and OEMs are negotiated. Iskow
and Sexton (1992), Worley et al. (2000), etc. are other examples of recent research that have largely
described existing bargaining institutions and contracting in commodity sectors. Other examples include
timber procurement (Elyakime et al., 1997), automobile industry and retail. These examples illustrate
that negotiation is common in determining the terms of procurement contracts. Thus, adopting a
negotiation framework to examine revenue (profit) allocations and contracting parameters in a supply
chain seems very natural.
The second issue of alliance formation is as important and is fairly widespread. Examples of al-
liances in supply chains are numerous. In what follows we provide some examples of alliances between
component manufacturers in supply chains similar to assembly systems. Greene (2002) indicates several
instances of alliances between component manufacturers in the semiconductor industry. Reasons for
such alliances are manifold. Some of these include capacity sharing, savings due to economies of scales,
2
increased competitiveness and other strategic reasons. In addition, another important reason for firms
to form strategic alliances is to improve their relative negotiating position. Examples include SMIC, one
of China’s largest chip manufacturing company forming an alliance with IMEC, the Belgian research
company to form a supplier alliance that sells 90nm chips to Texas Instruments. Other examples include
alliances between Asyst and Shinko in semiconductor equipment manufacturing, etc. Stallkamp (2001)
discusses alliances formations among auto part suppliers with the view of increasing supplier power. In
his article, he mentions a recent move, in which Delphi and Lear (interior trim manufacturers) have
independently displayed interest in forming strategic alliances with suppliers of wiring, carpets and
molded plastic with the aim of being major cockpit suppliers to the OEMs (in this case, one of the
Big Three auto manufacturers). Some other examples of coalitions formed with a view of increasing
negotiation power include cooperatives as bargaining institutions in several U.S. agricultural markets
(Hueth and Marcout 2003), alliances among commodity producers (Krasner 1974), coalitions among
suppliers in the retail sector (Lass et al. 2001). In yet another example, Symbol technologies, a leading
scanner manufacturer, has formed a strategic partnership with Paxar/Monarch, a leader in bar code
labeling. Together, they have become a major supplier of kits (a bundle that includes a bar code labeler
and a scanner) that are purchased by retailer.
In discussing these two questions in the framework of supply chain management, we have organized
the paper as follows: In Section 2, we introduce some basic concepts of cooperative bargaining. We
then proceed to review related literature from supply chain management, discuss some techniques used
in cooperative bargaining and discuss possible areas of future research. In Section 3, we provide an
exhaustive discussion and review of coalition games and applications, once again highlighting techniques
and areas for future research.
2. Negotiation models
In this section, we review the literature and study the application of cooperative bargaining models
to various supply chains. The main motivation behind using a formal negotiation model is that it
allows us to establish a framework to examine the effect of allocation of channel profits using bargaining
solutions across several structurally different supply chains. In doing so, we shed some light on many
modeling questions. Some of these include: How does one model the negotiation power of agents in a
supply chain? What are the effects of negotiation power of the agents in the supply chain on the profit
allocation? From a modeling perspective, these are important and non trivial questions that need to
be addressed. The answer to the first question is in two parts. The first aspect of negotiation power
arises purely due to the choice of the negotiation model that one uses. This may thus be an exogenous
factor. The second aspect is by virtue of the position of a player in the supply chain, the competition
between players and existence of outside options to players, the mechanism of trade, etc. Thus, these
may be somewhat endogenous and are specific to the supply chain in question.
In this study, we primarily focus on two outcomes of negotiation models as applied to supply chains.
The first outcome is the mechanism of trade or the contracting outcomes when players negotiate over
the terms of trade. Terms of trade loosely represents a whole array of contractual parameters that in-
clude wholesale price, purchasing quantity, as well as capacity investments, commitment to promotional
3
activities, etc. The second outcome is the impact on the structure of the supply chain. If negotiations
are conducted between various players in a supply chain, how will their relative negotiation power affect
the structure of the supply chain? One interesting aspect is the idea of forming bargaining alliances.
Others may include emergence of third party mediators who sell insurance, commitments to protect
against risky negotiations, etc. We devote much attention to the idea of alliance formation and asso-
ciated notions of stability in Section 3. Thus, in this section, rather than discuss stability, we discuss
modeling and technical issues that arise in modeling negotiations between coalitions of players.
Traditional operations management literature has seen a wide variety of papers in which risk-neutral
agents adopt the roles of suppliers and retailers across supply chains featuring both vertical and hor-
izontal competition. In almost all cases, the supply chain attempts to coordinate the channel using a
variety of contracts and the resulting first best channel profit is then divided among the agents. Transfer
prices, revenue sharing, buy-back pricing, or quantity discounts are some of the popular instruments
that are used to achieve this end. However, in these settings, ex post to coordination, the question
of how the shares are determined is left unaddressed. Further, in the case of risk-averse agents, even
the issue of coordination is usually unclear and thus shares of profits are largely left unaddressed. To
understand some of these issues, we look at negotiation using existing economic bargaining theory. We
consider agents with different risk postures and deduce the relationship to bargaining solutions and the
nature of the contracts and channel profits.
This section is organized as follows: We first provide a brief overview of cooperative economic
bargaining theory. This helps understand how a basic negotiation between two agents is modeled. With
this understanding, some existing results from the literature are reviewed. Finally, we discuss research
opportunities that exist within this framework that is relevant to supply chain management.
2.1 The Bargaining Model
The bargaining game in cooperative game theory addresses the following problem. Consider a group of
two or more agents faced with a set of feasible outcomes, any one of which will be the result if it is spec-
ified by unanimous agreement of all participants. In the event that no unanimous agreement is reached,
a given disagreement outcome is the result. If the feasible outcomes are such that each participant can
do better than the disagreement outcome, then there is an incentive to reach an agreement; however, so
long as at least two of the participants differ over which outcome is most preferable, there is a need for
bargaining and negotiation over which outcome should be agreed upon. Note that since unanimity is
required, each participant has the ability to veto any outcome different from the disagreement outcome.
To model this atomic negotiation process, we use the cooperative bargaining process initiated by
Nash (1951). It is pertinent to mention that experimental bargaining theory indicates stronger empirical
evidence of this bargaining theory than any others. Rather than provide a tutorial on Nash bargaining
(NB), we state the main result and refer the reader to Nash (1951) and Roth (1995).
We now turn our attention to the formulation of the model. Nash engaged in an axiomatic derivation
of the bargaining solution. The solution refers to the resulting payoff allocation that each of the
participants unanimously agrees upon. The axiomatic approach requires that the resulting solution
should possess a list of properties. The axioms do not reflect the rationale of the agents or the process
4
in which an agreement is reached but only attempts to put restrictions on the resulting solution. Further,
the axioms do not influence the properties of the feasible set. Before listing the axioms, we will now
describe the construction of the feasible set of outcomes.
Formally, Nash defined a two-person bargaining problem (which can be extended easily to more than
two players) as consisting of a pair 〈F, d〉, where F is a closed convex subset of IR2, and d = (d1, d2) is a
vector in IR2. F is convex, closed, non-empty, and bounded. Here, F , the feasible set, represents the set
of all feasible utility allocations and d represents the disagreement payoff allocation or the disagreement
point. The disagreement point may capture the utility of the opportunity profit. Nash looked for a
bargaining solution – i.e., an outcome in the feasible set that satisfied a set of axioms. The axioms
ensure that the solution is symmetric (identical players receive identical utility allocations), feasible
(the sum of the allocations does not exceed the total pie), Pareto optimal (it is impossible for both
players to improve their utilities over the bargaining solutions), the solution be preserved under linear
transformations and be independent of “irrelevant” alternatives. Due to constraints on space, we refer
the reader to Roth (1979) for a very good description of the solution approach and a more detailed
explanation of the axioms. The remarkable result due to Nash is that there is a bargaining solution
that satisfies the above axioms and it is unique!
Theorem 1 (Nash, 1951) There is a unique solution that satisfies all the “Axioms”. This solution,
for every two person bargaining game 〈F, d〉, is obtained by solving
arg max
x=(x1,x2)∈F,x≥d
(x1 − d1)(x2 − d2).
The axiomatic approach, though simple, can be used as a building block for much more complex
bargaining problems. Even though the axiomatic approach is prescriptive, descriptive noncooperative
models of negotiation such as the Nash demand game (Roth, 1995) and the alternating offer game
(Rubinstein, 1982), reach similar conclusions as Nash bargaining. This somewhat justifies the Nash
bargaining approach to model negotiations. In our discussion, we have only provided a description
of the bargaining problem and its solution between two players. However, this result can easily be
generalized to any number of players simultaneously negotiating for allocations in a feasible set.
2.1.1 The Nash bargaining problem in a typical newsvendor setting
We start by building the basic bargaining model in which a manufacturer (with utility uM ) sells to a
retailer (who is similar to a newsvendor with utility uR). The players negotiate on the terms of trade,
effectively the utility allocations. The retailer faces a random demand the density of which is f(ε).
He has to place an order of Q units in anticipation of the demand. He incurs purchasing, holding,
and shortage costs, and he gains revenue proportional to the quantity he sells. We will denote his
revenue per unit as s, the other costs per unit as w, h and v, respectively. The manufacturer faces
a production cost per unit, denoted as c, and sells to the retailer at a wholesale price w. Denote the
profit, given a demand realization ε, of the retailer and the manufacturer as piR(w,Q, ε) and piM (w,Q, ε)
respectively. With a slight abuse of notation, we denote the expected profits as E[piR(w,Q, ε)] = piR
and E[piM (w,Q, ε)] = piM , by simply dropping ε from the arguments. For the sake of exposition, we
5
describe the construction of the game using wholesale price contracts. At a later stage, we discuss the
use of other contracting mechanisms.
Recall that the NB game requires us to identify a feasible set of payoffs and a disagreement point
that are pre-determined and are independent of the negotiations. To do so, let us first suppose that the
supplier and the retailer negotiate on (w,Q). The feasible set is constructed as follows: We first define
∆ = {(E(uM (piM (w,Q, ε)), E(uR(piR(w,Q, ε))) : (w,Q) ∈ T}
for some suitable compact set T ⊆ IR. The set T is assumed to be a rectangular set. This will be the
case, for instance, when both the wholesale price and the purchasing quantity are allowed to take values
in a closed interval in the positive real axis. We let Ω be the convex hull of ∆ and we henceforth refer
to Ω as the feasible set. Note that, in the above formulation, the feasible set is the set of all randomized
feasible pairs of expected utility allocations of the total pie.
The disagreement outcomes have several interpretations, depending on the context. They represent a
certain level of expected utility that each player requires as a minimum level of acceptance to participate
in the trade. We set this to zero. In a setting where players are risk neutral, this is without loss of
generality – i.e., the structure of the results trivially change. When players are risk averse, one needs
to be a bit more careful. However, the results for the above system (a manufacturer – retailer chain) in
our paper, essentially remain the same.
When players are risk neutral and negotiate on both w andQ, one can make a few observations. First,
the bargaining solution of the game will not be a randomized outcome. This is because risk neutrality
implies ∆ = Ω. Further, note that the bargaining solution necessarily requires Pareto optimality as a
condition. This immediately ensures that when the players are risk neutral the negotiated quantity is
always the coordinating quantity, Qc. This simplifies the analysis and removes double marginalization
effects. The negotiated value of w allocates the channel surplus between the two players. This simple
observation continues to hold when more complex contracts are considered (i.e., buy-back, revenue
sharing, etc.), as long as one assumes that all parameters of the contract are simultaneously negotiated.
2.2 Cooperative Bargaining and Negotiation Power
When two players negotiate, it is reasonable to expect that the player with the higher bargaining power
(the more “powerful” player) receives a larger share of the pie than his weaker counterpart. With this
simple underlying idea we can now speak about a situation in which one player is more powerful than
the other.
2.2.1 Risk neutrality and negotiation power
First, it is clear that two “similar” players must get equal allocations from the feasible set. This is due
to the solution requiring symmetry as a necessary condition. Nash institutes the idea of similarity based
on the risk preferences of the players. In other words, two players who are risk neutral must obtain
the same effective profit. The solution of the NB exactly implies maximizing the geometric mean of
the allocation minus the disagreement point. We can easily observe that risk-neutral players, despite
6
having unequal disagreement points, have the same net allocations. Thus, risk-neutral players in an NB
game are equally powerful.
2.2.2 Risk aversion and negotiation power
The behavior of the solution changes, however, when the players exhibit different preferences (or equiv-
alently, when they have different utilities). Using measures of comparative risk aversion as suggested
by Arrow (1965), Pratt (1964), and Yaari (1969), it can be shown (Khilstorm et al., 1979) that in a
two-person bargaining problem, the Nash bargaining solution assigns a player increasing utilities as
his opponent becomes more risk averse. Thus, a player’s bargaining power increases as his opponent
becomes more risk averse.
2.3 The Generalized Nash Bargaining (GNB) Game
Thus far, we have seen two ways of incorporating negotiation power in the Nash bargaining model.
Risk preference usually induces non linearity of costs, but is not the only way to capture negotiating
power. In the newsvendor setting, risk aversion makes it very hard, if not impossible, to obtain closed
form expressions for allocations of profits. Further, the use of risk aversion forces the discussion to be
contract specific. This distracts us from the objective of getting tractable expressions and structural
results, which makes it imperative to preserve the linear structure offered by risk neutrality. The GNB
solution provides a recipe for capturing negotiation power without relaxing risk neutrality. It is obtained
by ignoring the axiom of symmetry in the NB game. It can be shown (Roth, 1979) that the remaining
axioms determine a family of solutions of the form
arg max
x∈Ω,x≥d
(x1 − d1)α(x2 − d2)β
with α + β = 1. The indices are loosely representative of the individual powers of the agents. For
instance, when two players with zero disagreement values negotiate on allocations of $1, the GNB
solution implies that the first player gets x1 = α and the second player receives x2 = 1 − α = β.
Our assumption of normalizing the disagreement points to zero may seem restrictive when the indices
are unequal. A natural interpretation of these indices is given by Muthoo (1996). It uses what are
referred to as commitment tactics. The main idea in such models is that before embarking on some
negotiation process (Nash bargaining, in our case), players take actions that partially commit them to
certain bargaining positions. The meaning of the commitment is that a player is unwilling to accept
a share smaller than the announced commitment. Commitment tactics allows us to preserve linearity
and thus provides a way of preserving the simple structure of the NB solution. It is important to note
that the commitment is not directly related to the disagreement point. However, it is evident that each
of the players will commit to a share that is not smaller than their disagreement points. Actually, it
seems natural to expect the players to inflate their commitments and thus increase their share of the
pie. But, in doing so the players need to exercise some caution because if the sum of the commitments
is larger than the pie, and if the bargaining process is to have a non-trivial solution, at least one of
the players must revoke his commitment. Revoking such a partial commitment is costly. It could, for
instance, be attributed to or construed as a loss of credibility. After such partial commitments have been
7
made, the players engage in the Nash bargaining process to strike a deal and arrive at their allocations.
Simultaneously they try to minimize the extent to which they must revoke their commitments. Such
commitment tactics are not unusual and often signal a player’s bargaining power. Bacharach and Lawler
(1981), Schelling (1960), and Cutcher-Gershenfeld et al. (1995) discuss the role of these tactics and give
examples from industry. For a more detailed discussion on commitments and their role in bargaining,
we refer the reader to Schelling (1960). For theoretical details of commitment tactics in negotiation
models, we refer you to Muthoo (1996).
2.4 Bargaining in Supply Chain Management
We now look at some applications of bargaining theory to supply chain management. We first review
some literature. We then present results on negotiations between a single manufacturer and a retailer.
We then look at some games in which a manufacturer negotiates sequentially with multiple retailers.
We discuss the implications on negotiation power and the structure of the supply chain. We also briefly
discuss bargaining situations when only parts of a contract are negotiated by players.
2.4.1 Cooperative bargaining in supply chain management
We first review the literature on applications of cooperative bargaining to supply chain management.
We lay emphasis on the word cooperative. We note that there are several papers that study negotiations
between agents without using a formal cooperative model. We do not review this literature. In these
papers, bargaining/negotiations refer to profit sharing using some cooperative allocation scheme, with-
out an explicit consideration of the underlying negotiation model. Bargaining is viewed as a sub-step,
used, for instance, to split ex-post gains (through renegotiation of contracts). An example of this stream
of literature is van Mieghem (1999). A paper that uses the idea of commitments to model negotiation
power is Bernstein and Marx (2006). Once again, they follow a noncooperative analysis, quite different
from the above description.
Perhaps the earliest known instance of an application of cooperative bargaining in a supply chain
context is the work by Kohli and Park (1989). The authors study a model in which a buyer and seller
negotiate the terms of a quantity discount contract in an EOQ setting. The underlying negotiation
model uses NB and its variants proposed by Kalai and Smordinsky (1975) and Eliashberg (1986). The
authors study the allocations as a function of risk aversion and bargaining power.
Reyniers and Tapiero (1995) use a formal cooperative model to study the effect of price and after-
sales warranty costs on transacted quantity and the quality of the end product when a supplier and
producer of products negotiate. Gurnani and Shi (2005) use a GNB model to study a business-to-
business supply chain. Chod and Rudi (2003) use NB in a stage of a biform game (more on this later)
that analyzes strategic investments in capacity.
2.4.2 Negotiation and contracting in supply chain management
In the last few years, more results on negotiation and contracting are known. In what follows, we look
at various supply chains and present and discuss these results. Consider a simple supply chain in which
a supplier sells to a newsvendor, who buys in anticipation of the demand. We know that, if the players
8
are risk neutral and the contractual agreements are implemented using a Stackelberg game, a simple
wholesale price contract results in channel inefficiency due to double marginalization. Moreover, we
know that a buy-back contract (Pasternack, 1985) or a revenue sharing contract (Cachon and Lariviere,
2004) removes this difficulty and results in channel coordination. In what follows, we look at this supply
chain and use NB to get some contractual insights.
In the discussion in Section 2.1.1 we essentially described the feasible set and the outcome of the
bargaining game when a wholesale price is used. We saw that double marginalization is not an issue
when players are risk neutral. In fact, when two risk-neutral players negotiate, as long as all decision
parameters of the problem are negotiated, we get the same result independent of the actual contracting
scheme. This is no longer true when players are risk averse. In what follows, we motivate and discuss
this issue. Our exposition here is to lay a basic framework and to offer more details than in any previous
work on cooperative negotiation. The model below is similar to the one discussed in Section 2.1.1: There
is exactly one product, the demand for which is random and is satisfied by the retailer, R. We assume
that the demand is independent of the fixed market selling price. The distribution and the density of
the demand are known. There is no information asymmetry. The manufacturer, M , and the retailer
negotiate on the prices and the quantity. The prices are of two kinds. There is a wholesale price, w,
that the manufacturer charges the retailer and a buy-back price, b, that the retailer receives per unit
of unsold inventory, which he returns to the manufacturer at the end of the period. We assume for
simplicity that there is no explicit shortage costs at the retailer. The feasible set and the disagreement
points are as discussed in the previous section. As mentioned, the agents negotiate on a feasible set
that represents expected utilities as a function of the price vector P = (w, b,Q). When players are risk
neutral, in a simple manufacturer retailer supply chain, any process where all contract parameters are
negotiated is equivalent to a process where negotiations are conducted over shares of some fixed pie.
This is because, for a given quantity Q, contract parameters have a one-one mapping to the shares of
the expected profits of the channel when Q units are transacted.
However, consider the case when the manufacturer is risk neutral but the retailer is risk averse with
utility uR(·), and the bargaining game in which the manufacturer and retailer are negotiating on the
wholesale price w, the buy-back price b, and the order quantity Q. We then have the following result
in which the buy-back price and quantity sold are explicitly known.
Theorem 2 P ∗ = (w∗, b∗, Q∗) yields the NB solution. Moreover: b∗ = s+h and F (Q∗) = (s−c)/(s+h).
First of all, note that Q∗ maximizes the channel profit, when the channel is owned by a risk-neutral
manufacturer. Traditionally this is referred to as the first-best solution. When the retailer and the
manufacturer are both risk neutral, the channel is said to be coordinated when it stocks the above
quantity. Note that when b = s + h, the retailer makes a constant profit pi∗R = (s − w)Q and the
manufacturer’s expected profit is given by
Eε(pi∗M ) = (w − c)Q− (s+ h)
∫ Q
0
(Q− ε)f(ε)dε.
Thus, the NB is reduced to:
max
w
{
(w − c)Q− (s+ h)
∫ Q
0
(Q− ε)f(ε)dε
}
{uR ([s− w]Q)} .
9
Our choice of Q∗ implies that for any P = (w, b,Q),
Eε(piM (P, ε)) + Eε(piR(P, ε)) ≤ Eε(pi∗M ) + pi∗R.
Now, for a given P , one can choose w∗ such that Eε(piM (P, ε)) ≤ Eε(pi∗M ) and Eε(piR(P, ε)) ≤ pi∗R. Such
a choice is possible because of continuity. (Essentially, by setting Q = Q∗ we have maximized the size
of the pie for a risk-neutral channel.) Hence, it is possible to find allocations which will improve the
profits of both the agents. By setting b as above, the retailer becomes risk insensitive. Now, since uR(·)
is increasing and concave, uR(pi∗R) ≥ uR(Eε(piR(P, ε))) ≥ Eε(uR ◦ piR(P, ε)). This shows that any choice
of prices other than the one indicated is Pareto sub-optimal, hence it cannot be the NB solution. It is
now a straightforward computation to determine w∗.
There are several takeaways. First, when one or more players are risk averse, contract negotiations
are no longer simply equivalent to negotiations for a share of some pie. Second, one can actually show
that the in the bargaining solution, the buy-back is able to provide some kind of insurance to the
risk-averse player – i.e., the retailer. We can also show, by comparing utilities across two different
bargaining games that contracts, such as revenue sharing schemes, do not result in the same solution.
In fact, one can show that if two risk-averse players negotiate on the space of contracts, typically, a
buy-back contract or a consignment type contract is predicted by the bargaining solution. Moreover, if
risk-averse players negotiate on shares of profit rather than actual terms of trade, the channel performs
inefficiently. This is formalized in the following proposition, which we state without proof.
Proposition 1 Let Qc be the quantity that coordinates a risk-neutral channel. Suppose that the man-
ufacturer and the retailer are risk averse. The the NB solution will never pick Qc.
The above analysis can be expanded to accommodate certain other bargaining games. This is
useful in deriving insights that can be beneficial to practitioners. Risk aversion can be used to model
bargaining power in a supply chain. From the above analysis, one can actually show that the more risk
averse the retailer, the higher the utility of the manufacturer. An interesting trade-off that emerges
is that a manufacturer tries to make the retailer behave like a risk-neutral entity by charging him
insurance through a buy-back contract. Now, one can think of a three-tier system where a risk-averse
manufacturer supplies to a risk-averse retailer. Using a similar analysis as above, one can show that a
risk-neutral distributor placed between the manufacturer and retailer actually improves the utility for
all players. The distributor here essentially acts as an insurance agent! This possibly gives additional
insight on a distributor’s role in a supply chain.
2.5 Nash Bargaining in Sequential Negotiations
We next present an application of Nash bargaining in a supply chain where a manufacturer sequentially
negotiates with multiple retailers. Consider a supply chain in which there is a single manufacturer
supplying to k retailers. Further, assume that these retailers do not compete in the same market.
As before, the manufacturer and each individual retailer negotiate on a (w, b) contract in which the
manufacturer sells to the retailer a certain quantity at the negotiated wholesale price, w, and accepts
returns of unsold inventory at the buy-back price, b. If the retailers are identical in all respects, the
10
negotiation process becomes easy as the supply chain can be thought of as k copies of a supply chain
with a single manufacturer and single retailer, which we have quite extensively dealt with in the previous
sections.
If we suppose that the retailers are not identical (we will be more precise very soon), the negotiation
process becomes less transparent. For one, the Robinson-Patman act requires that every retailer be
given the same price contract. The bargaining process becomes more interesting due to this constraint.
By way of illustrating this difficulty and to motivate our first game, consider a supply chain with a
single risk-neutral manufacturer supplying to two non-competing risk-neutral retailers differentiated
by their market selling prices. Assume that all parties are risk neutral and thereby maximize their
expected profits. The manufacturer and retailers negotiate on the prices and each retailer orders a
quantity that maximizes his expected profit at the negotiated prices. Note that, in the absence of a
legal constraint, each channel will independently pick a price that coordinates the channel and splits
the channel coordinated profit equally between the manufacturer and the respective retailer. We infer
this from the results on NB models in the previous sections. The outcome is not clear in the presence
of a constraint, especially when the two retailers face different market selling prices. Indeed, it is not
even clear if the two channels will pick prices that will coordinate them. In fact, there is no single
clear negotiation process that is immediate to such a channel, but there are several possibilities. In the
following discussion we propose one such game and deduce results for the above channels.
2.5.1 A sequential bargaining model with n retailers
Let I = {R1, R2, . . . , Rn} denote the set of retailers. In this game, we adopt a sequential bargaining
model in which at each stage the negotiation between the participants is modeled as a NB game. In
the first stage, the manufacturer negotiates with the “first” retailer and arrives at a “price”. We are
rather loose with our nomenclature at this point. We let “price” represent a vector of negotiating
instruments. For instance, the wholesale price, the buy-back price, and the quantity that the retailer
buys from the manufacturer are possible parameters that could be negotiated by the parties. The
parameters that the parties choose to negotiate are specified in each game. Anyhow, for simplicity, we
bundle these parameters and call them “price”. In the second stage of the game, the manufacturer does
the same with the “second” retailer and arrives at some new prices. In the n-th stage of the game,
the manufacturer negotiates with the last retailer and arrives at the n-th prices. We do not allow for
re-negotiation, but however require that each of the first n − 1 retailers is no worse off when offered
the n-th prices compared to the prices they arrived at by negotiation in their respective stages. We
further require that the resulting prices are such that the manufacturer is not interested in playing with
any non-trivial subset of retailers. Indeed, the profit obtained by the manufacturer might depend on
the sequence of the retailers in the negotiation process. If Π(n) is the set of all permutations of the
n retailers, the manufacturer will choose the “best” sequence. Let Θ(k) be the set of all subsets of I
such that each subset has exactly k retailers. For λki ∈ Θ(k), i = 1, 2, . . . , Cnk , let Π(λki ) be the set of
all permutations of λki . Note that if, for some reason, the manufacturer plays with the set of retailers
λki , he will choose the best sequence from Π(λ
k
i ), which we denote as λ
∗(i, k). We denote the resulting
prices as P (λ∗(i, k)). In a game in which the wholesale and buy-back prices are negotiated, we would
11
have P (λ∗(i, k)) = (w(λ∗(i, k), b(λ∗(i, k))). In the game with the n retailers, let Pi denotes the prices
at the end of the i-th stage – i.e., when the manufacturer finishes negotiations with the i-th retailer.
Hence, Pn is the final price at the end of the negotiations and all the n retailers will accept this price.
Finally, we denote pikM (Pi) and piRj (Pi) as the profit made by the manufacturer with the k-th retailer,
when he offers the prices Pi to him, and the profit made by the Rj retailer at the same prices. We
propose that the resulting prices Pn satisfy the following constraints:
n∑
i=1
piiM (Pn) ≥
∑
j∈λki
pijM (P (λ
∗(i, k)), λki ∈ Θ(k), k = 1, 2, . . . , n− 1 (1a)
piRj (Pn) ≥ piRj (Pj) j = 1, 2, . . . , n− 1 (1b)
piRj (Pj) ≥ 0 j = 1, 2, . . . , n− 1 (1c)
piRn(Pn) ≥ 0. (1d)
(1a) ensures that the manufacturer will find it more profitable to play with all the retailers and will not
prefer to ignore any subset of retailers. (1b) ensures that with the final negotiated prices every retailer
makes at least what he was “promised” at the end of his negotiations with the manufacturer. Note that
we do not allow for re-negotiation and hence when the manufacturer returns to a retailer with whom
he had negotiated earlier and forces the new and final price on him, the retailer will not have cause to
complain. (1c) ensures that at no stage, retailers accept a negative allocation. (1d) ensures that the
last retailer, who will be visited exactly once, will participate.
Note that, in this game, we have ignored explicit disagreement points that players may exogenously
possess. We assume that these are zero. Rather, we have implicit disagreement points. That is, in the
sequential game, a retailer in any stage of negotiation, will accept no less than he what he was promised
before. Thus, the disagreement points arise naturally at each step of the negotiation for the retailers.
The complete n-retailer game is described as follows. First of all, we look at the set of prices that
satisfy the above four constraints. If this set is non-empty, then it is clear that it is in the interest of the
manufacturer to play with all the n retailers. Moreover, if the set is convex, we can find the resulting
prices from the NB game the manufacturer plays with the last retailer. If the set is not convex, we can
do the same using the largest convex subset. However, if the set is empty, the manufacturer and the
retailers cannot agree upon any payoffs (i.e., the feasible set is trivial) and hence all parties will get
zero. At this stage, we cast aside the requirement to play with all the retailers and will formulate the
same game with n − 1 retailers (as of yet we have not mentioned how we determine the retailer to be
removed) and continue. This will continue until the feasible set becomes non-empty.
2.5.2 An example with two retailers
To illustrate this game and to get some insights on the “best” sequence for the manufacturer, we first
consider the case of a single manufacturer and two retailers. Let the retailers be RL, RH with L and
H denoting lower and higher market selling prices, sL < sH . To describe the game, the manufacturer
negotiates with the “first” retailer (which can be either L or H) and arrives at P1. He then negotiates
with the second (or the last) retailer in this case and they arrive at P2, which is the common price that
both retailers have to accept. To formulate the constraints of this game, we use the same notations as
12
above, and let pˆiiM denote the maximum profit the manufacturer would have obtained by playing with
just one retailer.
pi1M (P2) + pi
2
M (P2) ≥ pˆiHM/2 (2a)
piR1(P2) ≥ piR1(P1)(= pˆi1M/2) (2b)
piR2(P2) ≥ 0. (2c)
Note that equation (2a) is similar to equation (1a). The manufacturer is better of playing with the two
retailers than by just going with a single retailer.
This motivates our first example. Assume that, in the aforementioned game, the parties negotiate on
the wholesale price, the buy-back price, and the quantity that the individual retailers purchase from the
manufacturer. More precisely, we let Pi = (wi, bi, Qi). The solution must satisfy the three constraints
(2). Further, let Qˆi, i ∈ {1, 2,H, L} represent the channel coordinating quantity in the first and second
channel (as per the sequence), or the quantity that coordinates the channel when the manufacturer
plays with H or L retailer as the case may be. Let pii(Q) be the total profit of the i-th channel when
the retailer orders Q from the manufacturer.
The description of this game is as follows: In the first stage, the manufacturer negotiates with the
first retailer and they arrive at a price vector P1 = (w1, b1, Q1). The manufacturer then negotiates with
the second retailer and they subsequently arrive at P2 = (w2, b2, Q2). The wholesale and buy-back price
from the second negotiation is carried back to the first retailer. We assume at this point that the first
retailer still has to buy the quantity Q1, though at the new prices (w2, b2). Subsequently, we will show
that this assumption on the commitment of the order quantity is superfluous.
Lemma 1 Suppose that at the end of the game the resulting prices are (w, b) and the quantities sold to
the retailers are Q1 and Q2, respectively. Then Qi = Qˆi.
Proof: Firstly, note that piiM (w, b,Qi)+piRi(w, b,Qi) = pi
i(Qi) ≤ pii(Qˆi), i = 1, 2. Hence when Qi 6= Qˆi,
we have piiM (w, b,Qi) = αipi
i(Qˆi) and piRi(w, b,Qi) = βipi
i(Qˆi) and αi+βi < 1. There exists εi > 0 such
that
(αi + εi)pii(Qˆi) + (βi + εi)pii(Qˆi) ≤ pii(Qˆi).
Hence, if we show that there exists (w, b) such that piiM (w, b, Qˆi) = (αi + εi)pi
i(Qˆi), i = 1, 2, then by
Pareto optimality the proof is complete. Let Υi(Q) denote the expected returns to the manufacturer
from the retailer i when i orders Q units, and let fi denote the density of the demand faced by the
retailer i. Indeed as
piiM (w, b, Qˆi) = wQˆi − bΥi(Qˆi) = wQˆi − b
∫ Qˆi
0
[Qˆi − t]fi(t)dt,
we need only verify that QˆH/QˆL 6= Υi(QˆH)/Υi(QˆL). This is straightforward and that concludes the
proof.
The above lemma leads us to the main result, which we state without proof, indicating the negoti-
ation outcome.
13
Theorem 3 If (w, b) are the final prices and Qˆi are the quantities sold to the retailers in the respective
channels, then piiM (w, b, Qˆi) = piRi(w, b, Qˆi) = pi
i(Qˆi)/2, i = 1, 2.
We find that when there are more than two retailers, the constraint (1a) becomes binding – i.e., the
manufacturer will usually choose to ignore some retailers. We also find that the bargaining solution no
longer coordinates every channel. However, using a different contract mechanism, such as an additional
slotting fee (which allows for more flexibility), the results for the two retailer game can be mimicked in
a n retailer setting.
2.5.3 Sequential bargaining in the assembly model
Another application of sequential negotiation by Nagarajan and Bassok (2004), who look at a supply
chain with a single assembler who buys complementary components from n suppliers, assembles the
final product, and sells it to his customers. Players take actions in the following sequence. First,
(Stage 3) the suppliers form coalitions between themselves. Second, (Stage 2) the coalitions compete
for a position in the bargaining sequence. Finally, (Stage 1) the coalitions negotiate with the assembler
on the wholesale price and quantity of goods to be sold to the assembler. The negotiation process is
sequential, that is the assembler negotiates with one coalition at a time and the assembler has the power
to determine the negotiation sequence, while the suppliers can freely form alliances. They show that
the profit of each player is a function of his negotiation power relative to the negotiation power of the
other players, the negotiation sequence, and the coalitional structure. Moreover, when the assembler is
weak (low negotiation power), it is in general in the best interest of the suppliers to join forces in one
big alliance. In this case the assembler prefers to negotiate with as many suppliers as possible. On the
other hand, when the assembler is powerful, it is the interest of the suppliers to stay independent, while
the assembler would like to negotiate with a small number of suppliers.
2.6 Bargaining as a Subgame
One can think of instances where only some terms of a contract are negotiated, while other terms of
trade are derived using other mechanisms. For instance, in the context of the above games, one can
think of a setting in which a manufacturer and retailer negotiate on the wholesale and buy-back prices,
but not on the quantity. The retailer can be freely allowed to choose the quantity, depending on the
outcome from the negotiations. In principle, such games are no harder to solve, but require a more
careful construction of the feasible set. One can show that in this game, where the prices are negotiated
first and the quantity decision is made afterwards by the retailer, the outcome is such that the channel
is coordinated, but the prices are such that the retailer makes more than the manufacturer. That is,
even when players are risk neutral, they do not equally share the channel profits. We do not discuss
such games in this paper. For one, they are not well studied and, moreover, the outcomes are specific
to the assumptions about which the parameters are negotiated and what the subsequent moves are.
14
2.7 Extensions and Future Work
As can be seen, the use of cooperative bargaining in supply chain management is fairly limited. We feel
that there are several possible extensions and related areas of work that need to be studied. First, very
little is known about the effect of risk aversion on supply chain contracts. Moreover, the effect of risk
aversion may even have far reaching effect on the structure of the supply chain. One such instance is
the emergence of risk-neutral intermediaries, such as large distributors, who are able to effectively sell
insurance to downstream risk-averse agents.
Bargaining and contracting when parties posses asymmetric/incomplete information is yet another
important direction. Harsanyi and Selten (1972) in a seminal study demonstrate a variant of the NB
concept that incorporates incomplete information. Supply chain contracting using negotiations with
asymmetric players may help formalize notions such as inventory and information being substitutes.
A recent trend in supply chains is the emergence of coalitions of buyers and sellers who form alliances
to effectively negotiate by enhancing their clout in the supply chain. Cooperative bargaining between
coalitions is still an important but relatively unexplored area of study.
We hope these will be topics of future research.
3. Coalition Formation and Coalition Structures
Coalitions and alliances have been present in various forms in different businesses and industries. While
there exist a significant body of work dealing with coalition formation and stability in economics liter-
ature, there is very little research done within this framework in the supply chain management (SCM)
literature. Although many results in SCM point towards the importance of cooperation among the sup-
ply chain members in order to improve its performance, only a few researchers so far have tried to use
models from cooperative game theory, which appears to be a natural framework for such analysis. This
was also pointed out in Cachon and Netessine (2004), which provides a brief (but extensive) literature
survey of papers in SCM that adopt cooperative concepts (the core, the Shapley value, and the biform
games).
The importance of coalition formation was noted as early as in von Neumann and Morgenstern
(1944). Although they may be better known for introducing the strategic and the extensive form
games, they have also introduced the concept of stable sets in coalitional form games. Thus, coalition
formation was first studied in the framework of the coalitional form games, but has received rather
limited popularity. It is interesting to note that as early as 1961 there was an SCM paper (Chacko
1961) that analyzed a model of a multiplant multiproduct manufacturing company with two distributors.
Based on 52-month data, it analyzed the effects of coalition formation (among the company and the
customers of the distributors, the company and other manufacturing companies, among the customers,
etc.) on joint profits. However, there was no subsequent work on coalitions in SCM immediately
following this paper.
During the last three decades, coalition formation became a more popular topic in game-theoretical
research, but the new framework combines it with a noncooperative environment. In this section, we
focus on coalition structures and their stability. For a good review of coalition structures, see Greenberg
15
(1994). In what follows, we first review games in coalitional form and their applications, and then address
noncooperative models of coalition formation.
3.1 Games in Coalitional Form
A pair (N, v), where N = {1, 2, . . . , n} is the set of players, and v : 2N → IR is a function such that
v(∅) = 0, is called a cooperative game in coalitional form. A subset S ⊆ N is called a coalition, N is
called the grand coalition, and v is called the characteristic function of the game. A coalition structure,
Z, is a partition on N . That is, Z = {Z1, . . . , Zm},∪mi=1Zi = N,Zj ∩ Zk = ∅, j 6= k.
It is assumed that the payoffs of coalition members do not depend on nonmembers, hence v(S)
denotes the value that the members of coalition S can generate on their own. Yi (1997) shows that
many economic models of coalition formation create either positive externalities (e.g., output cartels –
the members of the merging cartels reduce their output in order to internalize the positive externalities
which output reduction creates on each other, and the remaining cartels benefit from the merger by free-
riding on the merging cartels output reduction) or negative externalities (e.g. research joint ventures –
when coalitions merge, their members combine their research assets and develop a technology with lower
marginal costs, which enables them to steal business from other coalitions, reducing other coalitions
profits) on nonmembers. We believe that this may be one of the reasons that cooperative games in
coalitional form have not achieved higher popularity.
Coalition formation and stability is tightly related to the method used to distribute the value gen-
erated by coalition members. Indeed, the early work on cooperative games concentrated on allocation
of payoffs, and only later addressed a more complex issue of coalition stability. A mapping Φ which
assigns to every cooperative game (N, v) a subset Φ(v) ⊆ IRn is called a solution concept. Φ is a
one-point solution concept if |Φ(v)| = 1 for every cooperative game (N, v). We will refer to one-point
solution concepts as allocation rules. The value an allocation rule assigns to a particular game (N, v)
will be called an allocation and denoted by ϕ = (ϕ1, . . . , ϕn) ∈ IRN . If
∑
N ϕi = v(N), we say that the
allocation is efficient.
3.1.1 Allocation rules
A simple example of an efficient allocation rule is a fractional rule, which assigns to every player a
predetermined fraction of the total value attained by the grand coalition,
ϕi = γiv(N), γi ∈ [0, 1],
∑
i∈N
γi = 1.
It is very simple to calculate, and satisfies some monotonicity criteria, which makes it appealing for
cost allocation models (Young, 1994). Thus, the fractional rule satisfies aggregate monotonocity, which
implies that a player’s allocation does not decrease if the value of the grand coalition weakly increases,
while the values of all other coalitions remains fixed,
v(N) ≥ w(N) and v(S) = w(S) ∀S ⊂ N ⇒ ϕi(v) ≥ ϕi(w) ∀i.
In addition, the fractional rule satisfies coalitional monotonicity, which implies that a player’s allocation
should not decrease if the values of all coalitions that contain him weakly increase, while the value of
16
remaining coalitions remains the same,
v(S) ≥ w(S) ∀S 3 i and v(S) = w(S) ∀S 63 i ⇒ ϕi(v) ≥ ϕi(w) ∀i.
Gerchak and Gupta (1991) analyze the problem of joint cost allocation in a centralized inventory
system with n retailers. They consider several cost-allocation options, and propose as a “fair” allocation
a fractional rule, where each player’s allocation is proportional to the expected cost that it would incur
on its own.
Meca et al. (2004) develop a simple inventory model with n retailers of an identical product who face
deterministic, constant demand. The model assumes zero lead time, and that the retailers incur order
placing cost and holding cost. The firms can cooperate to reduce their ordering costs. The authors
assume that firms share only information on their individual optimal annual number of orders, and
develop a proportional rule, to allocate joint ordering cost. This cost only depends on the ordering cost
and the individual average number of orders per time unit, which is public information. An interesting
property of this allocation rule is that it results in same decisions as if information about players’
individual costs and demands has been revealed.
Plambeck and Taylor (2004b) analyze a model with one manufacturer and n buyers. Before demand
realization, the buyers invest in innovation, while the manufacturer builds capacity. After demand is
realized, the firms renegotiate the supply contracts to achieve an efficient allocation of capacity among
the buyers. One of the allocations considered is the fractional rule. The authors consider two possible
remedies for breach of contract, specific performance and expectation damages, and show their impact
on firms’ decisions and profits.
The nucleolus and the Shapley value are well-known allocation rules with a common desirable
property, that they are both uniquely determined. Nucleolus (Schmeidler 1969) is the unique allocation
ϕ that lexicographically minimizes the vector of excesses
e(S, ϕ) = v(S)−
∑
S
ϕi, S ⊂ N,
when these excesses are arranged in descending order. Unlike the fractional rule, it does not satisfy any
of the monotonicity criteria.
Shapley value (Shapley 1953) is an allocation rule that satisfies the following axioms:
1. Symmetry: for all permutations pi of N , ϕpii(piv) = ϕi(v), where piv(S) = v(piS) for all S;
2. Null player: if i is a null player, i.e. v(S ∪ {i}) = v(S) for all S ⊂ N , then ϕi(v) = 0;
3. Efficiency:
∑
N ϕi(v) = v(N);
4. Additivity: ϕi(v + w) = ϕi(v) + ϕi(w) for any pair of cooperative games (N, v) and (N,w).
An intuitive interpretation of the Shapley value is as follows. Consider all possible orderings of
players, and define a marginal contribution of player i with respect to a given ordering as his marginal
worth to the coalition formed by the players before him in the order, v({1, 2, . . . , i−1, i})−v({1, 2, . . . , i−
17
1}), where 1, 2, . . . , i−1 are the players preceding i in the given ordering. The Shapley value is obtained
by averaging the marginal contributions for all possible orderings. This average is given by
ϕi(v) =
∑
{S:i∈S}
(|S| − 1)!(n− |S|)!
n!
(v(S)− v(S \ {i}), (3)
and it was shown by Shapley that (3) is the unique allocation rule which satisfies the above four axioms.
The Shapley value satisfy both aggregate and coalitional monotonicity. It also satisfies a stronger
concept of strong monotonocity, which implies that a player’s allocation should not decrease if the value
of coalitions that contain it increase relative to the value of coalitions to which it does not belong,
v(S)− v(S \ {i}) ≥ w(S)− w(S \ {i}) ∀S ⇒ ϕi(v) ≥ ϕi(w).
Despite its nice properties (if the core, defined below, is non-empty, then the nucleolus always belongs
to the core), the nucleolus is yet to find its application in SCM literature. There have, however, been
some papers that adopted the Shapley value.
The earliest application of the Shapley value in SCM literature can be found in the area of joint cost
allocations. In a paper related to Gerchak and Gupta (1991), Robinson (1993) models their inventory
problem as a cooperative game, and compares the Shapley allocations with those proposed by Gerchak
and Gupta.
To the best of our knowledge, one of the two SCM papers considering the nucleolus is Hartman and
Dror (1996). They model allocation of benefits or cost stemming from inventory centralization for n
stores, described in Gerchak and Gupta (1991). The authors impose three criteria that an allocation
rule has to satisfy – stability of the group, justifiability (consistency between costs and benefits) and
computational ease. After testing seven allocation rules (which included several fractional rules), they
show that only the nucleolus and the Shapley value satisfy both justifiability and stability criteria, but
require computations of order O(2n).
After these papers, the Shapley value has been neglected by the researchers in the SCM field until
recently, when it was used as a solution concepts in several SCM papers.
Raghunathan (2003) studies the value of demand information sharing and impact of demand corre-
lation in a model with one manufacturer and n retailers, wherein the end demands may be correlated.
The benefits stemming from information sharing are allocated according to the Shapley value. The
author shows that higher correlation increases the manufacturer’s allocation, and has the opposite ef-
fect on the retailers. In addition, because the marginal value of information from an additional retailer
decreases as the end demand becomes more correlated, the manufacturer may want to limit the number
of retailers with high correlation.
Granot and Sosˇic´ (2003) study a model of a decentralized distribution system with inventory sharing
consisting of n retailers, which we describe in more detail in Section 3.2. They show that the Shapley
value induces decisions that maximize the profit from inventory sharing, providing the players remain
in the grand coalition. This points to one of the drawbacks of the Shapley value – it may not belong to
the core, hence some players may have an incentive to defect from the grand coalition.
Reinhardt and Dada (2005) in a brief note consider a model with n firms who cooperate by pooling
their critical resources. The benefits generated through this cooperation are distributed among the firms
18
according to Shapley value. As the Shapley value can be difficult to compute with a large number of
players, the authors develop an algorithm that computes it in pseudo-polynomial time for a particular
class of games, which they call coalition symmetric.
Kemahlıog˘lu Ziya (2004) analyzes a supply chain consisting of one supplier and n retailers facing
stochastic independent demand. The supplier can keep inventory reserved for each retailer, or form
a coalition with the retailers and pool the inventory to share among them. In the latter case, the
total profit is distributed among players according to Shapley value. The author shows that Shapley
allocations coordinate the supply chain and are individually rational.
Leng and Parlar (2005) model a three-level supply chain consisting of a supplier, a manufacturer
and a retailer. The supply chain members share demand information to achieve supply chain-wide cost
savings. All three supply chain members form an information-sharing coalition, and the savings are
allocated among them according to the nucleolus and the Shapley value.
3.1.2 Core and coalition structure core
Perhaps the best known stability concepts are the core (Gillies, 1959) and the coalition structure core
(Aumann and Dreze, 1974). An allocation ϕ is a member of the core of (N, v) if it satisfies∑
i∈S ϕi ≥ v(S) ∀S ⊆ N,∑n
i=1 ϕi(v) = v(N).
The core posses a stability property – when core allocations are used, no subset of players has an
incentive to secede from the grand coalition and form its own coalition. Its main drawback is that, in
general, it can be an empty set. For a given coalition structure Z, an allocation ϕ is a member of the
coalition structure core of (N, v) if ∑
i∈S ϕi ≥ v(S) ∀S ⊆ N,∑
i∈Zk ϕi(v) = v(Zk) ∀Zk ∈ Z.
Thus, while the core addresses the stability of the grand coalition, the coalition structure core addresses
the stability of an arbitrary coalition structure. Both stability concepts are myopic in their nature, in
sense that they look only at one-step deviations by either a single player or a subset of players. The SCM
literature so far seemed to be interested only in the myopic stability of the set of all players, the grand
coalition. Thus, to the best of our knowledge, there are no papers in our field that use the coalition
structure core. There have, however, been quite a few papers that have analyzed core allocations.
As mentioned above, the core can be an empty set. Thus, it is not surprising that several papers
studied its non-emptiness for some special classes of SCM models. In addition, since core can contain
multiple elements, some authors develop methods for selection of unique core members.
Robinson (1993) shows the non-emptiness of the core for the game described in Gerchak and Gupta
(1991). In addition, he shows that the fractional allocation proposed by Gerchak and Gupta (1991)
does not belong to the core, while the nucleolus and the Shapley value do.
Hartman and Dror address non-emptiness of the core in several papers. In the previously mentioned
paper, Hartman and Dror (1996) impose the stability criterion as one of the desirable properties that
19
the schemes for distribution of cooperative value should posses. This condition corresponds to the
core membership. Hartman et al. (2000) prove the non-emptiness of the core for a single period
inventory model with n players facing demands with symmetric distributions, and for players facing
joint multivariate normal demand distribution. Hartman and Dror (2003) show the non-emptiness of
the core for a single period inventory model with n players facing normally distributed, correlated
individual demands. Mu¨ller et al. (2003) strengthen their results by showing non-emptiness of the core
for all possible joint distributions of demand. They also provide conditions under which the core is a
singleton. Slikker et al. (2005) enrich this model by allowing the retailers to use transshipments (at
a positive cost) after demand realization is known. They show that the core is nonempty even if the
retailers have different retail and wholesale prices.
Chen and Zhang (2006) formulate the inventory centralization problem as a stochastic linear program
(LP), and show that nonemptiness of the core follows directly from the strong duality of stochastic LP.
In addition, the stochastic LP approach provides a way to compute an element in the core. The authors
also show the non-emptiness of the core for the newsvendor game with more general, concave ordering
cost. Finally, they show that determining whether an allocation is in the core of the newsvendor game
is NP-hard.
Hartman and Dror (2005) study a model of inventory centralization for n retailers facing random
correlated demands. They consider two different games – one based on expected costs (benefits), and
the other based on demand realizations. For the first case, they show the non-emptiness of the core when
holding and shortage costs are identical for all subsets of retailers, and demand is normally distributed.
However, the core can be empty when the retailers’ holding and penalty costs differ. For the second
case, the core can be empty even when the retailers are identical.
Hartman and Dror (2004) consider a model with joint ordering in which the cost of ordering an item
has two separable components – a fixed cost independent of item type, and an item specific cost. The
authors address two questions – what items should be ordered together, and how should the ordering
costs be allocated among the players. They show that the core of the game is non-empty when items
should be ordered together. However, if the shared portion of the ordering cost is too small, the core
may be an empty set.
Klijn and Slikker (2005) study a location-inventory problem with m customers and n distribution
centers (DCs). Demand at each demand point is modeled as a continuous stochastic process, and it is
assumed that demands are identically and independently distributed. DCs follow a continuous review
policy with a positive fixed leadtime, and all stockouts are backordered. The inventory costs consist of
ordering and holding cost. DCs may cooperate by forming a coalition and reassigning the initial demand
within the coalition to minimize costs. It is assumed that the customers are indifferent about where
their orders are shipped from, and that the outbound transportation costs do not depend on where the
orders are shipped from. Under these conditions, the authors show non-emptiness of the core.
O¨zen et al. (2004) consider a game with n newsvendors, m warehouses, and a supplier, in which
the retailers are supplied from the warehouses. The retailers can increase their expected joint profits by
coordinating their initial orders and redistributing the ordered quantities at the warehouse, after demand
realization. They show that this game has a non-empty core. O¨zen and Sosˇic´ (2006) extend this model by
assuming that reallocation of inventories happens after a demand signal is observed. The signal updates
20
the information about the demand distribution, but may not reveal the true demand realization. The
authors analyze the impact of two contracting schemes (the wholesale price contract and the buy-back
contract) in three models (non-cooperating retailers, cooperating retailers, and manufacturers resale of
returned items) on the manufacturer’s profit, and study the conditions for achieving a system-optimal
solution. They show that the core is not empty under both contracting schemes.
In a previously mentioned paper, Leng and Parlar (2005) show the non-emptiness of the core for
their information-sharing game.
Ben-Zvi (2004) and Ben-Zvi and Gerchak (2006) study newsvendor games in which the retailers
that have different shortage costs centralize their inventories. They analyze several approaches to the
distribution of stocks in the case of a shortage, and show that these games have a non-empty core.
O¨zen et al. (2005) analyze the convexity of some simple newsvendor games. As a result of the
convexity, the marginal vectors of a game are the extreme points of the core, the bargaining set coincides
with the core, and the Shapley value is the barycenter of the core. While the newsvendor games are
not convex in general, the authors concentrate on the class of newsvendor games with independent
symmetric unimodal demand distributions and identify cases that lead to the convex games.
3.2 Two-Stage Games
In many real-life situations, supply chain members are likely to make some decisions individually, while
some others may be made in cooperation with other players, with the ultimate goal of maximizing
individual payoffs. For instance, inventory centralization models described in the previous section may
be modified so that players individually determine their stocking decisions, and then jointly determine
transshipment patterns. Unfortunately, classic game theory does not provide models for this type
of games. Branderburger and Stuart (2004) provide an axiomatization for this type of games, and
introduce the name biform games. A biform game, in general, consists of two stages. In the first stage,
the players unilaterally choose their strategies (in a noncooperative fashion), and the outcome is a
cooperative game played in the second stage. Stuart (2005) uses the biform model to study competitive
newsvendor problem wherein inventory decisions are followed by price competition. Price competition
is modeled through core membership. He shows that the model can be reduced to the Cournot oligopoly
problem. As a result, instead of considering the relationship between understocking and overstocking
cost, inventory decision is made by considering the tradeoff between fewer units at a higher price versus
more units at a lower price.
Note that biform games impose the constraint that the allocation rules used in the cooperative stage
have to satisfy core constraints. We do not want to limit our attention to this class of games – we want
to address more general models that combine competition and cooperation, and we will refer to them
as two-stage games.
In the SCM literature, the first authors to adopt this type of models were Anupindi et al. (2001,
1999). They analyze a distribution problem where independent retailers selling an identical product
face stochastic demands, and must order their inventory prior to demand realizations. After demands
are realized, the retailers can gain additional profit by sharing the leftover inventory, that is, by shipping
residual supplies to retailers with residual demands. In the first stage, the retailers unilaterally determine
21
their inventory orders. Their decisions are based on previously selected allocation rules for distribution
of the profit from inventory sharing. In the second, cooperative stage, the retailers share their inventories
and allocate the corresponding additional profit. The allocation rule used in these models is based on
a dual solution for the transshipment problem. Such an allocation is always in the core, and therefore
encourages the retailers not to form subcoalitions during the transshipment stage.
It is implicitly assumed by Anupindi et al. that the retailers will share all of their unsold inventories
and unsatisfied demands in the second, cooperative stage. Granot and Sosˇic´ (2003) add an additional,
noncooperative stage between the two stages of the afore mentioned model, where each retailer deter-
mines the amount of its residuals that it wants to share with other retailers. They show that core
allocations may encourage the retailers to withhold some of the residuals, and thus decrease the cooper-
atively generated profit. In addition, they show that the fractional rule and the Shapley value encourage
the retailers to share all of their residuals, but in general do not belong to the core.
Plambeck and Taylor use two-stage models in several papers. Plambeck and Taylor (2005) study
a model with two original equipment manufacturers (OEMs) who sell their capacity to the contract
manufacturer (CM). In the first stage, the OEMs noncooperatively choose their capacity and inno-
vation levels. In the second, cooperative stage, the manufacturers pool their capacity and negotiate
the allocation of the additional profit stemming from capacity pooling. They show the impact of the
bargaining power of different supply chain members on equilibrium decisions and the resulting profit.
Plambeck and Taylor (2004a) analyze a model in which two buyers noncooperatively invest in
innovation and obtain supply from a single manufacturer through quantity flexibility contracts. In the
second stage, the contract can be renegotiated and the capacity reallocated among the buyers. They
show that the potential for renegotiation may strengthen or weaken the buyers incentive to invest in
demand-stimulating innovation, depending on the size of its demand. Plambeck and Taylor (2004b), as
mentioned before, consider a similar model, where they consider two possible remedies for the breach of
contract – specific performance and expectation damages. They analyze the effect of players’ bargaining
power and the two remedies on the equilibrium outcomes, and discuss the conditions under which a
first-best outcome may be achieved.
Chod and Rudi (2003) analyze a model with two independent firms which unilaterally invest in
resources based on imperfect market forecasts. As time progresses and new information becomes avail-
able, the firms update their forecasts and have the option to cooperatively trade their resources. The
trade is negotiated in a Nash bargaining game. The authors study the impact of forecast revisions,
market variability, foreign exchange volatility, and market correlation on equilibrium investments and
the corresponding expected prices, profits, and consumer surplus.
3.3 Noncooperative Models of Coalition Formation
Introduction of coalition formation to noncooperative games has its origins rather early. The most
widespread stability concept from noncooperative game theory is the Nash equilibrium (Nash, 1951),
which considers only single-player deviations. If we assume that all supply chain members can commu-
nicate among themselves and can join or leave alliances freely, they may consider both unilateral and
joint deviations from any coalition structure. Auman (1959) extended the Nash equilibrum concept by
22
defining stability with respect to deviations by coalitions. A strategy profile is said to be a strong Nash
equilibrium if no set of players can jointly deviate and make all of its members better off. However,
this stability concept requires players to follow strategies that they have agreed upon, even if they may
benefit from defections. Thus, similarly to the core and the coalition structure core, it is myopic in its
nature.
The above mentioned approaches may not be appropriate for many real-life situations. For instance,
consider an arbitrary coalition structure, Z, and suppose that a subset of players, Z, can increase their
payoffs by deviating and forming a different coalition structure. For a myopic view of stability, this would
make Z unstable. However, we should consider possible further defections from the initial deviation.
Another coalition may decide to deviate from the current status quo, which may benefit a possibly
different set of players. In fact, any defection may trigger a sequence of further moves and eventually
culminate with an outcome in which some players that initially deviated, members of Z, receive a lower
payoff than the one they obtained in Z. Under such a scenario, farsighted players may prefer not to
move in the first place and thus Z, which initially appeared unstable, may actually prove to be stable.
To remedy this shortcoming, Bernhaim et al. (1987) introduce the concept of coalition-proof Nash
equilibrium, which involves self-enforcing agreements among coalition members. This solution concept
takes into consideration future deviations, but the attention is restricted to defections that are immune
to deviations by subcoalitions. That is, it does not take into account the possibility that some members
of the deviating coalition may further deviate with someone outside that coalition. A solution concept
that allows players to look ahead and consider possible further deviations, and which considers deviations
by coalitions where subcoalitions may further deviate with players outside that coalition, is the largest
consistent set, introduced by Chwe (1994).
3.3.1 The largest consistent set
Let us denote by ≺i the players’ strong preference relations, described as follows: for two coalition
structures, Z1 and Z2,
Z1 ≺i Z2 ⇔ uZ1i < uZ2i ,
where uZi is a player i’s payoff in the coalition structure Z. If Z1 ≺i Z2 for all i ∈ S0, we write
Z1 ≺S0 Z2. For a given coalition S0, let FS0(Z) denote the set of coalition structures achievable by
a one-step coalitional move by S0 from Z. Denote by ⇀S0 the following relation: Z1 ⇀S0 Z2 if the
coalition structure Z2 is obtained when S0 deviates from the coalition structure Z1. Then, Z2 ∈ FS0(Z1).
We say that Z1 is directly dominated by Z2, denoted by Z1 < Z2, if there exists an S0 such that
Z2 ∈ FS0(Z1) and Z1 ≺S0 Z2. We say that Z1 is indirectly dominated by Zm, denoted by Z1  Zm,
if there exist Z1,Z2,Z3, . . . ,Zm and S1, S2, S3, . . . , Sm−1 such that Zi+1 ∈ FSi(Zi) and Zi ≺Si Zm for
i = 1, 2, 3, . . . ,m− 1.
A set Y is called consistent if the following holds: Z ∈ Y if and only if for all S0 and all V ∈ FS0(Z)
there is a B ∈ Y , where V = B or V  B, such that Z 6≺S0 B. Chwe (1994) proves the existence,
uniqueness, and non-emptiness of the largest consistent set (LCS). Because every coalition considers
the possibility that, once it reacts, another coalition may react, and then yet another, and so on, the
LCS incorporates farsighted coalitional stability. The LCS describes all possible stable outcomes and
23
has the merit of “ruling out with confidence”: if Z is not contained in the LCS, Z cannot be stable.
Xue (1998) refines the LCS concept by introducing the perfect foresight.
While Chwe establishes the existence of a LCS, a criticism of this solution concept is that it may be
too inclusive. Mauleon and Vannetelbosch (2004) refine the LCS by assuming that defecting coalition
S0 should contemplate the possibility to end with positive probability at any coalition structure B ∈ Y ,
where V = B or V  B. They call the set obtained under this criteria the largest cautious consistent set
(LCCS). Konishi and Ray (2003) propose an alternate dynamic approach to stability of coalition struc-
tures, which they call the equilibrium process of coalition formation (EPCF), and establish a possible
link between the LCS and the limit states of absorbing deterministic EPCFs.
3.3.2 Equilibrium process of coalition formation (EPCF)
Recall that uZi denotes player i’s payoff in the coalition structure Z, and let δi denote his discount
factor. Then, i’s payoff from a sequence of coalition structures {Zt} may be written as
∑∞
t=0 δ
t
iu
Zt
i .
A process of coalition formation (PCF) is a transition probability p : Z × Z → [0, 1], so that∑
V∈Z p(Z,V) = 1 ∀Z ∈ Z. A PCF p induces a value function vi for each player i, which represents
the infinite horizon payoff to a player starting from any coalition structure Z under the Markov process
p, and is the unique solution to the equation
vi(Z, p) = uZi + δi
∑
V∈Z
p(Z,V)vi(V, p).
We say that S has a profitable move from Z under p if there is V ∈ FS(Z),V 6= Z, such that vi(V, p) ≥
vi(Z, p) ∀i ∈ S. We say that S has a strictly profitable move from Z under p if there is V ∈ FS(Z) such
that vi(V, p) > vi(Z, p) ∀i ∈ S. A move V is called efficient for S if there is no other move W for S such
that vi(W, p) > vi(V, p) ∀i ∈ S. Now, we can define EPCF, as follows: a PCF is an equilibrium PCF if:
1. whenever p(Z,V) > 0 for some V 6= Z, then there is S such that V is a profitable and efficient
move for S from Z,
2. if there is a strictly profitable move from Z, then p(Z,Z) = 0 and there is a strictly profitable
and efficient move V with p(Z,V) > 0.
Thus, a deviation from one coalition structure to another occurs only if all members of the deviating
coalition agree to move and they cannot find a strictly better alternative coalition structure. In addition,
the deviation from a coalition structure must occur if there is a strictly profitable move. Notice that
this definition does not require that every strictly profitable move has a positive probability. Konishi
and Ray (2003) show that there is an equilibrium process of coalition formation.
If p(Z,V) ∈ {0, 1} ∀Z,V, a PCF is called deterministic. A coalition structure Z is said to be
absorbing if p(Z,Z) = 1, while a PCF is absorbing if, for every coalition structure V, there is some
absorbing coalition structure Z such that p(k)(Z,V) > 0, where p(k) denotes the k-step transition
probability. Konishi and Ray show that, for large δ, the set of all absorbing states under all deterministic
EPCFs is a subset of the LCS. Thus, absorbing states may provide a refinement of the LCS.
24
3.3.3 The LCS and the EPCF
The LCS uses the logic that players take into account all possible defections by fellow players before
agreeing on an outcome. Thus, if the n players are involved in some kind of a negotiation process
which will eventually determine a mutually amicable coalition structure, the LCS takes into account
the possible scenarios threats and counter-threats involving defections and counter-defections that the
players will consider before signing a binding agreement.
The EPCF takes a completely different approach. It allows players to defect from any state and
rewards them with a state dependent payoff. Individual players in a status quo coalition structure can
calculate the expected discounted rewards if the coalition structures evolved along any sample path. The
stable outcomes can be interpreted as ultimate coalition structures from which no further movements are
likely. It is interesting to note that, though the two approaches are completely different, the absorbing
states of the EPCF may provide a refinement of the LCS.
3.3.4 Applications of farsighted stability
As mention above, the farsighted stability concepts seem to be better suited to depict real-life situations
than the myopic ones, as they take into account possible dynamics in coalition formation. There have
recently been a few papers that have used farsighted stability concepts in supply chain setting.
The first paper to use the farsighted stability in SCM literature is Granot and Sosˇic´ (2005). They
develop a model of three retailers whose products may be substitutable, and who may form coalitions.
A firm joining a coalition reduces its cost, but it also reduces the cost of other coalition members. In
addition, coalition members benefit at the expense of companies left outside the coalition. The authors
use the LCS to determine what coalition structures are the farsighted stable outcomes.
Nagarajan and Bassok (2004) study an assembly model with one retailer who purchases a single
unit from each one of the n suppliers. The final product is a collection of n components. The demand
for the final product is random, and the model assumes single period with symmetric information. The
authors use the farsighted notion to completely characterize the stable outcomes in supply chain in
which players may form coalitions to possibly enhance their negotiation power.
Nagarajan and Sosˇic´ (2005) study dynamic alliance formation among agents in competitive markets.
Their model considers price competition among n agents selling substitutable products and facing both
deterministic and stochastic demand. The agents may form coalitions, which determine common price
and compete against each other. The authors analyze farsighted stability as a function of the market
size and the degree (substitutability) of competition.
Sosˇic´ (2004) builds on the results from Anupindi et al. (2001) and Granot and Sosˇic´ (2003). While
the latter papers consider only myopic stability and conclude that, without enforceable contracts, man-
agement of inventories may result with residual losses, the author shows that the grand coalition is
stable in the farsighted sense when Shapley value is used to allocate cooperative profit. As shown in
Granot and Sosˇic´, this leads to maximization of the cooperatively generated value.
Granot and Yin (2004) analyze two contracting systems between an assembler and his suppliers,
push (where suppliers set price first, and the assembler orders second) and pull (where the assembler
offers price to each supplier first, and suppliers then determine quantity). They investigate various
25
aspects of the two systems, including alliance formation, profit allocation and members’ preferences
over the two systems. Using the LCCS, they show stability of the grand coalition in the push system,
while under the pull system any coalition structure can be stable.
Sosˇic´ (2005) extends the model developed by Leng and Parlar (2005) by allowing supply-chain
members not to participate in the information-sharing coalition. In other words, all possible coalition
structures (not only the grand coalition) are considered. The author shows that the grand coalition is
not the only farsighted stable outcome, and in fact may be less preferred than some smaller information-
sharing alliances.
Nagarajan and Sosˇic´ (2006) study a decentralized assembly supply chain, where n component-
suppliers sell to a downstream assembler who decides the purchasing quantity, assembles the compo-
nents, and sells the final product. They analyze three separate cases: one in which the suppliers are the
Stackelberg leaders, one in which the assembler is the Stackelberg leader, and one in which the assem-
bler and the suppliers make decisions simultaneously. Suppliers may form coalitions, and the authors
characterize coalition structures that are farsighted stable.
3.4 Future Work
As mentioned above, coalition structures and the models that include cooperative behavior among
players seem to be a natural framework to model cooperation in supply chains. Several researchers in
this area have already adopted various models that deal with coalition formation and stability, and we
hope to see many more in the future. Note that this is a rather new stream of research in SCM, and
many referenced articles are still working papers.
One other aspect of coalitional games is the computation of stable outcomes. Extensive work by
computer scientists has focused on determining whether an allocation is in the core. It is well known
that, in general, these problems are computationally hard. Computing the LCS has received much less
attention. A recent paper (Nagarajan, 2005) shows that, for many commonly seen supply chain games,
the LCS can be computed efficiently in polynomial time.
There are numerous opportunities to create hybrid models that combine competitive and cooperative
behavior. For instance, Plambeck and Taylor (2005) study a model with double moral hazard, where
two firms engage in joint production. The repeated nature of their interaction implies that today’s
actions influence the effectiveness of their future actions. Repeated interaction also facilitates the use
of relational contracts, which are sustained by the ongoing value of the relationship. The authors show
that an optimal relational contract does not depend on the past history, but may require that the firms
terminate their relationship with positive probability in every period.
We present below some results for a repeated three-stage game with two players. Extending this
model to an arbitrary number of players may be an interesting future research topic.
3.4.1 Inventory sharing in a repeated newsvendor game
Our analysis in this section is concerned with repeated interactions between two retailers in inventory
sharing agreements. Papers by Anupindi et al. (2001, 1999) and Granot and Sosˇic´ (hereafter referred to
as G&S) (2003) have analyzed a single-period distribution problem with independent retailers. Anupindi
26
et al. use an allocation rule based on a dual solution for the transshipment problem. G&S show that
allocations based on dual solutions will not, in general, induce the retailers to share all of their residuals
with others, hence a first-best solution may not be achieved when dual allocations are used.
Note that the papers mentioned above assume that the game is played only once. That is, the
retailers have only one opportunity to interact. Clearly, if the game was played repeatedly, the retailers
would take into account their future interactions and possible future payoffs when making their decisions.
Thus, it is our goal to study the impact of repeated interactions in a decentralized framework in which
the retailers share their leftover inventories/demands in every round of the game. In each round, the
retailers are facing a newsvendor framework. Due to the difficulties in calculating dual allocations,
we limit our attention to the simple case with two retailers. As shown in G&S, in a single-shot game
where each of the two retailers receives dual allocations of the profit from transshipment, the retailer
who shares less residuals receives the entire cooperative surplus. Consequently, in an equilibrium each
retailer shares zero residuals. We show that this result does not hold in an infinitely repeated game. In
addition, we provide conditions under which dual allocations lead to a first best-solution, and develop
a contract that induces a first-best outcome under general conditions.
The plan of the section is as follows. We first present a simplified version of the single-period game
introduced in G&S (where we assume n = 2), and then the repeated inventory-sharing game and its
equilibrium outcomes. We then compare these results with a first-best solution. Due to space restric-
tions, we omit the proofs. They can be obtained from the authors upon request.
The single-shot inventory-sharing game
We describe here a simplified version of the three-stage inventory-sharing game introduced in G&S
(2003). We consider two retailers who sell an identical product, and assume that they face random
demands Di and manage their own inventories. In the first stage, before demand is realized, each
retailer makes its stocking decision, Xi. The decision is made independently of the other retailers, and
it depends on the allocation rules used in the third stage. In the second stage, after demand realization,
each retailer decides how much of its leftover inventory or unsatisfied demand she wants to share with
others in the third, cooperative stage. Let H¯i denote the leftover inventory and let E¯i denote the
unsatisfied demand for retailer i. Thus,
H¯i = max{Xi −Di, 0}, E¯i = max{Di −Xi, 0}.
We denote by Hi ∈ [0, H¯i] and Ei ∈ [0, E¯i] the amount of residual that retailer i is sharing with
others in the second stage. This decision is made independently of the other retailers, and it depends
on agreements used in the third stage. In the third stage, leftover inventories are shipped to meet
unsatisfied demands, and the profit from inventory sharing is allocated among the retailers.
Let ri, ci, and vi denote, respectively, the unit retail price, cost, and salvage value for retailer i, Yij
and tij denote the amount of stock shipped and the unit cost of transshipment from retailer i to retailer
j. We will use bold letters to denote vectors and matrices.
Let R(X,D,H,E,Y) denote the profit from transshipments for given inventory decisions, X, de-
mand realizations, D, shared residuals, H and E, and shipping pattern Y, and let R∗(X,D,H,E)
27
denote the maximal corresponding profit,
R∗(X,D,H,E) := max
Y
∑
i,j
(rj − vi − tij)Yij (4a)
subject to :
∑
j Yij ≤ Hi, i = 1, 2 (4b)∑
i Yji ≤ Ei, i = 1, 2 (4c)
Yij ≥ 0, i, j = 1, 2. (4d)
The profit function for retailer i can be written as Pi(X,D,H,E) = Pni (Xi, Di)+ϕi(X,D,H,E), where
Pni (Xi, Di) denotes the noncooperative profit that retailer i can generate on its own,
Pni (Xi, Di) = rimin{Xi, Di}+ viH¯i − ciXi,
and ϕi(X,D,H,E) is the allocation of the maximal profit from inventory sharing, R∗(X,D,H,E). We
let Jni (Xi) = E[P
n
i (Xi, Di)], and we denote i’s inventory decision that maximizes J
n
i (Xi) by X
n
i .
We assume that the retailers share the profit from transshipments according to dual allocations, as
follows. Let λi and µi be dual prices corresponding to (4b) and (4c). Then, dual allocation to retailer
i can be written as ϕdi (X,D,H,E) = λiHi + µiEi. The dual prices under different demand realization
are given by
Hi > E3−i > 0 ⇒ λ1 = λ2 = µi = 0, µ3−i = r3−i − vi − ti,3−i,
Ei > H3−i > 0 ⇒ µ1 = µ2 = λi = 0, λ3−i = ri − v3−i − t3−i,i.
In other words, when dual allocations are used, the entire profit from transshipment is allocated to the
retailer who shares less residuals.
After demand realization, for givenX,D, each retailer makes its residual-sharing decisions according
to Nash equilibrium (NE). Let us denote this NE by (HX,D,EX,D), and let Jdi (X) = E[P
d
i (X,D,H
X,D,EX,D),
where superscript d denotes the use of dual allocations. Let us further denote by Xd NE stocking de-
cisions that the retailers make in the first stage. Anupindi et al. (1999) show the uniqueness of a pure
strategy NE for the game with two retailers under dual allocations.
We also use as a benchmark the model where a single decision maker optimizes the performance of
the entire system. We will denote the profit in this, centralized model, by
P c(X,D) =
n∑
i=1
[
rimin{Xi, Di}+ viH¯i − ciXi
]
+R∗(X,D, H¯, E¯),
its expected value by Jc(X) = E[P c(X,D)], and the optimal inventory decision by Xc. It will also be
referred as a first-best solution.
The repeated inventory-sharing game
G&S show that dual allocations in a single-shot game lead to an equilibrium in which each retailers
shares zero residuals with the other retailer. We now consider a more realistic framework, in which
the retailers interact repeatedly. In each period, after demand is realized and local demand satisfied
28
from inventories on hand, leftover inventories/demands can be shared among the retailers. Unsold
inventories at the end of the period can be salvaged, and the new period begins. In this period, the
retailers again place their inventory orders, fulfill their demands, and so on. We assume that the retailers
in every period know the decisions that all retailers have made in the past. Thus, each retailer knows
if the other retailers have shared all of their residuals, or if they withheld some of them. All future
payoffs are discounted by a factor δ ∈ [0, 1), and each retailer maximizes the discounted value of its
profits,
∑
t δ
t−1Pit, where Pit is the profit that retailer i receives in period t. Retailer i’s strategy
specifies the stocking quantity, Xit, for period t, and portion of its residuals, Hit and Eit, that will be
shared in period t when the residuals are H¯it and E¯it. These decisions are based on previous histories,
ht−1 = {Xτ ,Hτ ,Eτ}t−1τ=1. An equilibrium strategy for retailer i in a single-shot game with two retailers is
to chooseHi = Ei = 0. It is, however, clear that one of the firms would benefit if they share their leftover
inventory/demand. In a repeated game, the retailers can choose from a menu of different strategies,
and commonly used methods rely on retaliation. In our framework, a retaliation strategy could be
described as follows. Each firm agrees to share all of its residuals in every period, H = H¯,E = E¯. If a
firm deviates and withholds some residuals in period t, the other firm does not share any residuals in
subsequent periods. The period of retaliation can be limited to a fixed length, or could extend until the
end of the game. The commonly used concept in repeated games is subgame perfect Nash equilibrium
(SPNE), which requires the equilibrium strategy to induce a NE in every subgame of the original game.
Hereafter, the word “game” will denote the inventory-sharing game with two retailers
Let us first consider a game which is repeated a finite number of times.
Proposition 2 If the game is repeated a finite number of times, no inventory is shared among the
retailers.
Next, we suppose that the game will be repeated an infinite number of times. Clearly, if δ = 0,
the game corresponds to the one-shot game, so we assume δ > 0. In the first period, retailer i orders
inventory Xdi and shares residuals Hi = H¯i, Ei = E¯i. This strategy is repeated until retailer j = 3 − i
deviates. From that period onwards, retailer i orders Xni and shares residuals Hi = 0, Ei = 0. Thus, a
deviation by one retailer triggers a permanent retaliation. This strategy can be written as follows:
(Xit,Hit, Eit)(ht−1) =
{
(Xdi , H¯it, E¯it), t = 1 or all elements of ht−1 equal (X
d, H¯, E¯)
(Xni , 0, 0), otherwise,
(5)
and leads to the following result.
Theorem 4 There is always δ∗ ∈ (0, 1) such that the strategies (5) constitute a SPNE of the infinitely
repeated game whenever δ ≥ δ∗.
If Jdefi (Xi, X
d
j , ε) denotes the profit that i generates when it defects by sharing ε less residuals than j
(e.g., Hi = Ej − ε), and we let Xεi = argmax Jdefi (Xi, Xdj , ε), then the value of δ∗ can be calculated as
δ∗ = max{δ1(0), δ2(0)}, where
δi(ε) =
Jc(Xεi , X
d
j )− Jdi (Xd)− Jnj (Xdj )
Jc(Xεi , X
d
j )− Jni (Xni )− Jnj (Xdj )
.
29
Note that permanent retaliation may be considered a non-credible threat, as the punisher punishes
itself as well as the other retailer. However, it is easy to show that, for any set of parameters, we can
always find k and δ(k) such that the strategies (5) constitute a SPNE whenever the model implements
k-period punishment and δ ≥ δ(k). It can be evaluated that lower values of k result in higher value of
δ(k), which is bounded from below by δ∗.
We have shown that the zero-sharing equilibrium from a finitely repeated game may be avoided if the
retailers assume that they will be engaged in an infinitely repeated cooperation. In this environment,
each retailer takes into account both one-period benefits obtained as a result of defection, and lost
profits due to retaliation. The discount factor measures the weight that a retailer puts on its future
losses compared to the present gain. Sharing of all residuals is an equilibrium only if the discounted
present value of future losses exceeds the one-period benefit from defection. Therefore, there is no need
for an additional mechanism to induce the retailers to share all of their residuals, providing that the
discounting factor is high enough. Note that the discounting factor δ can also be interpreted as the
probability that the retailers’ cooperation will continue in each period. Thus, larger value of δ imply
that it is more likely that inventory sharing will continue. When the discounting factor is small, the
only equilibrium solution will be the one from the one-shot inventory sharing game.
Proposition 3 There is always δ∗ ∈ (0, 1) such that every SPNE of the infinitely repeated game has
both retailers ordering Xn and sharing zero residuals in every period whenever δ ≤ δ∗.
We illustrate Theorem 4 and Proposition 3 with the following example.
Example 1. Suppose that both retailers face demand uniformly distributed over [0, 100], and that
c1 = c2 = 3.7, r1 = r2 = 10, v1 = v2 = 1, t12 = 1, t21 = 3. Then, without inventory sharing, the retailers
order Xn1 = X
n
2 = 70, with the corresponding expected profit J
n
1 (X
n
1 ) = J
n
2 (X
n
2 ) = 221. In a model with
inventory sharing and dual allocations, Xd1 = 64, X
d
2 = 61, with J
d
1 (X
d) = 241, Jd2 (X
d) = 245. In addi-
tion, Jn1 (X
d
1 ) = 219, J
n
2 (X
d
2 ) = 217. Finally, limε→0Xε1 = 67, limε→0Xε2 = 58, and limε→0 Jc1(Xε1 , Xd2 ) =
limε→0 Jc1(Xε1 , Xd2 ) = 486. Now, δ1(0) = 0.57, δ2(0) = 0.48, and (5) is a SPNE whenever δ ≥ 0.57. It is
also easy to evaluate that δ∗ = 0.09. That is, no residual sharing is a unique SPNE whenever δ ≤ 0.09. ♦
It can also be shown that there are multiple equilibria in the infinitely repeated game whenever the
discounting factor is large enough. As the discounting factor δ increases, the set of SPNEs becomes
larger. It may, therefore, be difficult to determine which one of the equilibrium behaviors will occur in
practice. For the purpose of this analysis, we assume that the retailers will select the most profitable
SPNE, that is, they will share all of their residuals in every period.
Achieving a first-best solution
We now compare the profits and inventory decisions obtained in the decentralized system with dual
allocations with a first-best solution, in which a single decision maker optimizes the performance of both
retailers. We assume that δ > δ∗, so it is an equilibrium for the retailers to share their entire residuals.
30
First, suppose that the retailers are symmetric. In other words, c1 = c2 = c, v1 = v2 = v, r1 = r2 =
r, t12 = t21 = t, and the retailers face identical demand distributions. Then, the following result holds.
Theorem 5 If the retailers in the infinitely repeated game are symmetric and δ > δ∗, dual allocations
induce a first-best solution.
Even if the retailers are not symmetric, a first-best solution can be achieved with dual allocations,
as we show in our next result.
Theorem 6 If the retailers in the infinitely repeated game are not symmetric and δ > δ∗, then:
1. dual allocations induce a first-best solution whenever
(rj−vi−tij)
∫ Xci
0
(Xci −u)fj(Xc1+Xc2−u)dFj(u) = (ri−vj−tji)
∫ Xcj
0
(Xcj−u)fi(Xc1+Xc2−u)dFi(u);
2. if, on the other hand,
(rj−vi−tij)
∫ Xci
0
(Xci −u)fj(Xc1+Xc2−u)dFj(u) < (ri−vj−tji)
∫ Xcj
0
(Xcj−u)fi(Xc1+Xc2−u)dFi(u),
then Xdi > X
c
i , X
d
j < X
c
j in the equilibrium solution with dual allocations.
Example 2. Suppose that both retailers face demand uniformly distributed over [0, 100], and that
c1 = c2 = 6.4, r1 = r2 = 10, v1 = v2 = 1, t12 = t21 = 1. In both the centralized model and the model
with inventory sharing and dual allocations, each retailer orders 44 units, with the corresponding total
expected profit of 206.
Now, suppose that retailer 2 faces demand uniformly distributed over [0, 125] and that t21 = 1.424,
while the remaining parameters have the same values as above. In both the centralized model and the
model with inventory sharing and dual allocations, retailer 1 orders 49 units, retailer 2 orders 50 units,
with the corresponding total expected profit of 229.
Next, suppose that t21 = 3, that is, shipping cost from 2 to 1 increases. Then, in the centralized
model retailer 1 orders 59, retailer 2 orders 40, for a total expected profit of 226. In the model with
inventory sharing and dual allocations, retailer 1 orders 49 units, retailer 2 orders 50 units, with the
corresponding total expected profit of 224. ♦
As a special case of the above result, suppose that the retailers are symmetric, except for the trans-
shipment cost. Without loss of generality, suppose t12 < t21. Then, it is easy to verify that equilibrium
stocking quantity at retailer 1 exceeds equilibrium stocking quantity at retailer 2.
Example 3. Suppose that both retailers face demand uniformly distributed over [0, 100], and that
c1 = c2 = 6.4, r1 = r2 = 10, v1 = v2 = 1, t12 = 1, t21 = 3. Then, in the centralized model retailer 1
orders 57, retailer 2 orders 31, for a total expected profit of 202. In the model with inventory sharing
and dual allocations, retailer 1 orders 45 units, retailer 2 orders 43 units, with the corresponding total
31
expected profit of 199. Thus, Xd1 < X
c
1, X
d
2 > X
c
2. ♦
Thus, while the stocking quantity at the retailer from whom the transshipment is less expensive al-
ways exceeds the stocking quantity at the other retailer, the difference between two inventory decisions
is larger in the centralized model. In the decentralized model, the retailers increase their respective ex-
pected profits by ordering quantities that are less apart, so that their expected profits are less dependent
on their share of the profit from transshipments.
G&S show that the Shapley value induces retailers to share all of their residuals in a single-shot
game, but lacks stability because, in general, it does not belong to the core. In the model with only
two retailers the Shapley value assigns a half of the profit from transshipments to each retailer, and
thus satisfies core requirements. Despite this, in infinitely repeated games, dual allocations can lead to
better results than Shapley value, as we show bellow.
Proposition 4 Shapley allocations do not induce a first-best solution in the infinitely repeated inventory-
sharing game with two retailers, even when the retailers are identical.
So far, we have shown that a first-best outcome can be achieved under some special conditions. To
achieve a first-best solution for a general case, one may construct a contract that imposes a penalty on
deviating retailers and removes them from further cooperation. Let us denote by ςt the system’s status
at period t. ςt can have two values: c, which denotes cooperative agreement with inventory sharing,
and n, which denotes no inventory sharing. We assume that, if players are in state c in period t − 1
and order the quantity prescribed by the contract, then in period t they are in state c again. In all
other cases, they move to state n. Thus, if any of the retailers orders anything other than what the
contract prescribes, there will be no inventory sharing in the future periods. Given ordering decisions
X1,X2, . . ., let us denote a retailer’s i infinite horizon discounted payoff by
pii(X1,X2, . . . , ς1, ς2, . . .) = E
[ ∞∑
t=1
δt−1P ςti (Xt,Dt)
]
, pidi (X1,X2, . . .) = E
[ ∞∑
t=1
δt−1P di (Xt,Dt)
]
.
The contract prescribes the ordering decisions for every period, Xςtt , a vector of initial transfer payments
s0 (negative for the retailer who is better off if a first-best order order quantity is used instead of the
individually optimal quantities, positive for the other retailer, s10 = −s20), and vector of per-period
transfer payments, st, for every period t (the retailer that forfeits the contract pays the other retailer,
s1t = −s2t). Let us define
Xςtit =
{
Xci , for ςt = c
Xni , otherwise
si0 = pidi (X
d
1,X
d
2, . . .)− pidi (Xc1,Xc2, . . .), for pidi (Xd1,Xd2, . . .) > pidi (Xc1,Xc2, . . .)
sit(X) = pii(Xς11 , . . . ,X
ςt−1
t−1 ,X,X
ςt+1
t+1 , . . .)− pii(Xς11 , . . . ,Xςt−1t−1 ,Xςtt ,Xςt+1t+1 , . . .),
for pii(Xς11 , . . . ,X
ςt−1
t−1 ,X,X
ςt+1
t+1 , . . .) > pii(X
ς1
1 , . . . ,X
ςt−1
t−1 ,X
ςt
t ,X
ςt+1
t+1 , . . .)
Then, it is easy to evaluate that both retailers benefit from adopting the contract from the first period
and not defecting from it. s0 insures that neither retailer is worse off if they order first-best quantity.
32
Side payments st are executed only if a retailer defects and orders quantity different from the one
prescribed in the contract. Their amount ensures that neither retailer benefits from defection. Thus,
the following result holds.
Theorem 7 Contract (Xςtt , s0, st, t = 1, 2, . . .) induces a first-best outcome in the infinitely repeated
game with δ ≥ δ∗ for arbitrary values of the model’s parameters.
References
Anupindi, R., Y. Bassok, E. Zemel. 2001. A General Framework for the Study of Decentralized
Distribution Systems, M&SOM 3, 349-368.
Anupindi, R., Y. Bassok, E. Zemel. 1999. Study of Decentralized Distribution Systems: Part II -
Applications, Working paper, Northwestern U., Evanston, IL.
Arrow, K. 1965. Aspects of the Theory of Risk Bearing, in Essays in the Theory of Risk Bearing,
Chicago; Markham.
Aumann, R.J. 1959. Acceptable Points in General Cooperative n-person Games, in Contributions to
the Theory of Games IV, A.W. Tucker and R.D. Luce eds., Princeton U. Press, N.J., 287-324.
Aumann, R.J., J.H. Dreze. 1974. Cooperative Games with Coalition Structures, Internat. J. Game
Theory, 3 217-237.
Bacharach, S.B., E.J. Lawler. 1981. Bargaining, Power, Tactics and Outcomes, Jossey-Bass, San
Francisco.
Bajari, P., R. McMillan, S. Tadelis. 2002. Auctions versus Negotiations in Procurement. An
Empirical Analysis, Working Paper, Stanford U., Stanford, CA
Ben-Zvi, N. 2004. Inventory Centralization when Shortage Costs Differ: Priorities and Cost Alloca-
tions, M.Sc. Thesis, Tel-Aviv U., Tel-Aviv, Israel.
Ben-Zvi, N., Y. Gerchak. 2006. Inventory Centralization when Shortage Costs Differ: Priorities
and Cost Allocations, Working paper, Tel-Aviv U., Tel-Aviv, Israel.
Bernheim, B.D., B. Peleg, M.D. Whinston. 1987. Coalition-Proof Nash Equilibria, I. Concepts,
J. Econ. Theory, 42 1-12.
Bernstein, F., L. Marx. 2005. Reservation Profit Levels and the Division of Supply Chain Profit,
Working paper, Duke U., Durham, NC.
Bonaccorsi, A., T.P. Lyon, F. Pammolli, G.Turchetti. 2000. Auctions versus Bargaining: An
Empirical Analysis of Medical Device Procurement, LEM working paper series, Sant’ Anna school
of advanced study.
Brandenburger A., B.J. Nalebuff. 1996. Coopetition, Currency Doubleday, New York.
Brandenburger, A., H.W. Stuart Jr. 2004. Biform Games, to appear in Management Sci.
Cachon, G.P, M.A. Lariviere. 2004. Supply Chain Coordination with Revenue Sharing Contracts,
Management Sci. 51, 30-44.
Cachon, G., S. Netessine. 2004. Game Theory in Supply Chain Analysis, in Supply Chain Analysis
in the eBusiness Era, D. Simchi-Levi, S. D. Wu, and M. Shen eds., Kluwer.
Chacko, G.K. 1961. Bargaining Strategy in a Production and Distribution System, Oper. Res. 9,
33
811-827.
Chen, X., J. Zhang. 2006. A Stochastic Programming Duality Approach to Inventory Centralization
Games, Working paper, U. of Illinois, Urbana-Champaign, IL.
Chod, J., N. Rudi. 2003. Strategic Investments, Trading and Pricing Under Forecast Updating,
Working paper, U. of Rochester, Rochester, NY.
Chwe, M. S.-Y. 1994. Farsighted Coalitional Stability, J. Econ. Theory, 63 299-325.
Cutcher-Gershenfeld, J., R.B. McKersie, R.E. Walton. 1995. Pathways to Change: Case
Studies of Strategic Negotiations, W.E. Upjohn Inst. for Employment Res., Kalamazoo, MI.
Eliashberg, J. 1986. Arbitrating a Dispute. A Decision Analytic Approach, Management Sci. 32,
963-974.
Elyakime, B., J.J. Laffont, P. Loisel, Q. Vuong. 1997. Auction and Bargaining: An Econometric
Study of Timber Auctions with Secret Reservation Prices, J. Bus. Econ. Stat. 15, 209-220.
Gerchak, Y., D. Gupta. 1991. On Apportioning Costs to Customers in Centralized Continuous
Review Systems, J. Oper. Management 10, 546551.
Gillies, D.B. 1959. Solutions to General Non-zero Sum Games, in Contributions to the Theory of
Games IV, A.W. Tucker and R.D. Luce eds., Princeton U. Press, Princeton, N.J. 47-83.
Granot, D., G. Sosˇic´. 2003. A Three Stage Model for a Decentralized Distribution System of
Retailers, Oper. Res. 51, 771-784.
Granot, D., G. Sosˇic´. 2005. Formation of Alliances in Internet-Based Supply Exchanges, Manage-
ment Sci. 51, 92-105.
Granot, D., S. Yin. 2004. Competition and Cooperation in a Multi-Supplier Single-Assembler Supply
Chain with Complementary Products, Working Paper, U. of British Columbia, Vancouver, Canada.
Greenberg, J. 1994. Coalition Structures, in Handbook of Game Theory Vol.2, R.J. Aumann and S.
Hart eds., Elsevier Sci. B.V., 1305-1337.
Greene, D. 2002. JVS, Alliances, Consortia on Path to Survival for Many, Semi Conductor magazine,
June 2002.
Gurnani, H., M. Shi. 2005. A Business to Business Bargaining Model with Supply Uncertainty, to
appear in Management Sci.
Harsanyi, J.C., R.Selten. 1972. A Generalized Solution for Two-Person Bargaining Games with
Incomplete Information, Management Sci. 18, 80-106.
Hartman, B.C., M. Dror. 1996. Cost Allocation in Continuous-Review Inventory Models, Naval
Res. Logistics 43, 549561.
Hartman, B.C., M. Dror. 2003. Optimizing Centralized Inventory Operations in a Cooperative
Game Theory Setting, IIE Transactions 35, 243257.
Hartman, B.C., M. Dror. 2004. Shipment Consolidation: Who Pays for It and How Much, Working
Paper, The U. of Arizona, AZ.
Hartman, B.C., M. Dror. 2005. Allocation of Gains from Inventory Centralization in Newsvendor
Environments, IIE Transactions 37, 93-107.
Hartman, B.C., M. Dror, M. Shaked. 2000. Cores of Inventory Centralization Games, Games and
Econ. Behavior 31, 2649.
Heuth, B. P. Marcoul. 2003. An Essay on Cooperative Bargaining in U.S. Agricultural Markets,
34
J. Agri. & Food Indust. Org. 1, Article 10.
Iskow, J., R. Sexton. 1992. Bargaining Associations in Grower-Processor Markets for Fruits and
Vegetables, Technical report 104, Agricultural cooperative service, U.S. Dept. of Agriculture.
Kalai, E., M. Smorodinsky. 1975. Other Solutions to Nash’s Bargaining Problem. Econometrica
43, 513-518.
Kemahlıog˘lu Ziya, E. 2004. Formal Methods of Value Sharing in Supply Chains, Ph.D. Thesis, Sch.
of Ind. and Systems Eng., Georgia Inst. of Tech., Atlanta, GA.
Kihlstrom, R., A. E. Roth. 1982. Risk Aversion and the Negotiation of Insurance Contracts.J.
Risk and Insurance 49 p. 372-387.
Khilstrom, R., A.E. Roth, D. Schmeidler. 1981. Risk aversion and Nash’s solution to the
Bargaining Problem, in Game Theory and Math. Econ., O. Moeschlin and D. Pallaschke eds.,
Amsterdam: North Holland, 65-71.
Klijn, F., M. Slikker. 2005. Distribution Center Consolidation Games, Oper. Res. Letters 33,
285-288.
Kohli, R., H.Park 1989. A Cooperative Game Theory Model of Quantity Discounts. Management
Sci. 35, 693-707.
Konishi, H., D. Ray. 2003. Coalition Formation as a Dynamic Process, J. Econ. Theory 110, 1-41.
Krasner, S.D. 1974. Trade in Raw Materials: The Benefits of Capitalist Alliances, in Testing Theories
of Economic Imperialism, S. Rosen and J.R. Kurth eds, D.C. Heath.
Lass, D.A., M.Adanu, P.G.Allen. 2001. Impact of the Northeast Dairy Compact on Retail prices,
Agricultural and Resources Econ. Review.
Leng, M., M. Parlar. 2005. Allocation of Cost Savings in a Three-Level Supply Chain with Demand
Information Sharing: A Cooperative-Game Approach, Working Paper, McMaster U., Hamilton, ON.
Mauleon, A., V. Vannetelbosch. 2004. Farsightedness and Cautiousness in Coalition Formation
Games with Positive Spillovers, Theory and Decision 56, 291-324.
Meca, A., J. Timmer, I. Garcia-Jurado, P.E.M. Borm. 2004. Inventory Games, European J.
Oper. Res. 156, 127-139.
Muthoo, A. 1996. A Bargaining Model Based on the Commitment Tactic, J. Econ. Theory 69,
134-152.
Muthoo, A. 1999. Bargaining Theory with Applications, Cambridge U. Press.
Mu¨ller, A., M. Scarsini, M. Shaked M. 2002. The Newsvendor Game Has a Nonempty Core,
Games and Econ. Behavior 38, 118-126.
Nagarajan, M., Y. Bassok. 2004. A Bargaining Framework in Supply Chains (The Assembly
Problem), Working paper, U. of So. Cal., Los Angeles, CA.
Nagarajan, M., G. Sosˇic´. 2005. Stable Farsighted Coalitions in Competitive Markets, Working
paper, U. of So. Cal., Los Angeles, CA.
Nagarajan, M., G. Sosˇic´. 2006. Coalition Stability in Assembly Models, Working paper, U. of So.
Cal., Los Angeles, CA.
Nash, J.F. 1950. The Bargaining Game, Econometrica 18, 155-162.
Nash, J.F. 1951. Noncooperative Games, The Annals of Math. 54, 286-295.
O¨zen, U., J. Fransoo, H. Norde, M. Slikker. 2004. Cooperation Between Multiple Newsvendors
35
with Warehouses, Working paper, TUE, Eindhoven, The Netherlands.
O¨zen, U., H. Norde, M. Slikker 2005. On the Convexity of Newsvendor Games, Working paper,
TUE, Eindhoven, The Netherlands.
O¨zen, U., G. Sosˇic´. 2006. A Multi-Retailer Decentralized Distribution System with Updated Demand
Information, Working paper, TUE, Eindhoven, The Netherlands.
Pasternack. B.A. 1985. Optimal Pricing and Return Policies for Perishable Commodities, Marketing
Sci. 4, 81-87.
Plambeck, E., T. Taylor. 2005. Sell the Plant? The Impact of Contract Manufacturing on Innova-
tion, Capacity and Profitability, Management Sci. 51, 133-150.
Plambeck, E., T. Taylor. 2004a. Implications of Renegotiation for Optimal Contract Flexibility
and Investment, Working Paper, Stanford U., Stanford, CA.
Plambeck, E.L., T.A. Taylor. 2004b. Implications of Breach Remedy and Renegotiation for Design
of Supply Contracts, Working paper, Columbia U., New York, NY.
Plambeck, E., T. Taylor. 2004c. Partnership in a Dynamic Production System, Working Paper,
Stanford U., Stanford, CA.
Pratt, J.W. 1964. Risk Aversion in the Small and Large, Econometrica 32, 122-136.
Raghunathan, S. 2003. Impact of Demand Correlation in the Value of and Incentives for Information
Sharing in a Supply Chain, European J. Oper. Res. 146, 634649.
Reinhardt, G., M. Dada 2005. Allocating the Gains from Resource Pooling with the Shapley Value,
J. Oper. Res. Society 56, 997-1000.
Reyniers, D.J., C.S. Tapiero. 1995. The Delivery and Control of Quality in Suplier-Producer
Contracts. Management Sci. 41, 1581-1589.
Robinson, L. 1993. A Comment on Gerchak and Guptas “On Apportioning Costs to Customers in
Centralized Continuous Review Systems”, J. Oper. Management 11, 99102.
Roth, A. 1979. Axiomatic Models in Bargaining, Springer-Verlag.
Roth, A. 1995. Handbook of Experimental Economics, Princeton U. Press.
Roth, A. E., U. Rothblum. 1982. Risk Aversion and Nash’s Solution for Bargaining Games with
Risky Outcomes, Econometrica 50, 639-647.
Rubinstein, A. 1982. Perfect Equilibrium in a Bargaining Model, Econometrica 50, 97-110.
Schelling, T. 1960. The Strategy of Conflict, Harvard U. Press.
Schmeidler, D. 1969. The Nucleolus of a Characteristic Function Game, SIAM J. Applied Math. 17,
1163-1170.
Shapley, L.S. 1953. A Value for N-Person Games, Contribution to the Theory of Games vol.2, Prince-
ton U. Press, Princeton, N.J. 307-317.
Slikker, M., J. Fransoo, M. Wouters. 2005. Cooperation Between Multiple News-vendors with
Transshipments, European J. Oper. Res. 167, 370-380.
Slikker, M., A. van den Nouweland. 2001. Social and Economic Networks in Cooperative Game
Theory, Kluwer Academic Publishers, Boston.
Sosˇic´, G. 2004. Transshipment of Inventories Among the Retailers: Myopic vs. Farsighted Stability,
to appear in Management Sci.
Sosˇic´, G. 2005. Stability of Information-Sharing Alliances in a Three-Level Supply Chain, Working
36
paper, U. of So. Cal., Los Angeles, CA.
Stallkamp, T.T. 2001. Fixing a Broken Economic Model: A Case for Supplier Alliances, Management
briefing seminars, MSX international, Traverse city, MI.
Stuart Jr., H.W. 2005. Biform Analysis of Inventory Competition, M&SOM 7, 3479-359.
van Mieghem, J. 1999. Coordinating Investment, Production and Subcontracting, Management Sci.
45, 954-971.
von Neumann, J., O. Morgenstern. 1944. Theory of Games and Econ. Behavior, Princeton U.
Press, Princeton, N.J.
Worley, T., R. Folwell, J. Foltz, A. Jacqua. 2000. Management of a Cooperative Bargaining
Association: A Case in the Pacific Northwest Asparagus Industry, Review of Agricultural Econ. 22,
548-565.
Xue, L. 1998. Coalitional Stability Under Perfect Foresight, Econ. Theory, 11 603-627.
Yaari, M.E. 1969. Some Remarks of Risk Aversion and Their Use, J. Econ. Theory 1, 315-329.
Yi, S.-S. 1997. Stable Coalition Structures with Externalities, Games and Econ. Behavior, 20 201-237.
Young, H.P. 1985. Monotonic Solutions of Cooperative Games, Internat. J. Game Theory 14 65-72.
37
